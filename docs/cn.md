# x-crawl Â· [![npm](https://img.shields.io/npm/v/x-crawl.svg)](https://www.npmjs.com/package/x-crawl) [![GitHub license](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/coder-hxl/x-crawl/blob/main/LICENSE)

[English](https://github.com/coder-hxl/x-crawl#x-crawl) | ç®€ä½“ä¸­æ–‡

x-crawl æ˜¯ä¸€ä¸ªçµæ´»çš„ Node.js å¤šåŠŸèƒ½çˆ¬è™«åº“ã€‚çµæ´»çš„ä½¿ç”¨æ–¹å¼å’Œä¼—å¤šçš„åŠŸèƒ½å¯ä»¥å¸®åŠ©æ‚¨å¿«é€Ÿã€å®‰å…¨ã€ç¨³å®šåœ°çˆ¬å–é¡µé¢ã€æ¥å£ä»¥åŠæ–‡ä»¶ã€‚

> å¦‚æœä½ ä¹Ÿå–œæ¬¢ x-crawl ï¼Œå¯ä»¥ç»™ [x-crawl å­˜å‚¨åº“](https://github.com/coder-hxl/x-crawl) ç‚¹ä¸ª star æ”¯æŒä¸€ä¸‹ï¼Œæ„Ÿè°¢å¤§å®¶çš„æ”¯æŒï¼

## ç‰¹å¾

- **ğŸ”¥ å¼‚æ­¥åŒæ­¥** - åªéœ€æ›´æ”¹ä¸€ä¸‹ mode å±æ€§å³å¯åˆ‡æ¢å¼‚æ­¥æˆ–åŒæ­¥çˆ¬å–æ¨¡å¼ã€‚
- **âš™ï¸ å¤šç§ç”¨é€”** - å¯çˆ¬é¡µé¢ã€çˆ¬æ¥å£ã€çˆ¬æ–‡ä»¶ä»¥åŠè½®è¯¢çˆ¬ï¼Œæ»¡è¶³å„ç§åœºæ™¯éœ€æ±‚ã€‚
- **â˜ï¸ çˆ¬å– SPA** - çˆ¬å– SPAï¼ˆå•é¡µåº”ç”¨ç¨‹åºï¼‰ç”Ÿæˆé¢„æ¸²æŸ“å†…å®¹ï¼ˆå³â€œSSRâ€ï¼ˆæœåŠ¡å™¨ç«¯æ¸²æŸ“ï¼‰ï¼‰ã€‚
- **âš’ï¸ æ§åˆ¶é¡µé¢** - è‡ªåŠ¨åŒ–è¡¨å•æäº¤ã€UI æµ‹è¯•ã€é”®ç›˜è¾“å…¥ã€äº‹ä»¶æ“ä½œã€æ‰“å¼€æµè§ˆå™¨ç­‰ã€‚
- **ğŸ–‹ï¸ å†™æ³•çµæ´»** - åŒç§çˆ¬å– API é€‚é…å¤šç§é…ç½®ï¼Œæ¯ç§é…ç½®æ–¹å¼éƒ½éå¸¸ç‹¬ç‰¹ã€‚
- **â±ï¸ é—´éš”çˆ¬å–** - æ— é—´éš”ã€å›ºå®šé—´éš”ä»¥åŠéšæœºé—´éš”ï¼Œäº§ç”Ÿæˆ–é¿å…é«˜å¹¶å‘çˆ¬å–ã€‚
- **ğŸ”„ å¤±è´¥é‡è¯•** - é¿å…å› çŸ­æš‚çš„é—®é¢˜è€Œé€ æˆçˆ¬å–å¤±è´¥ï¼Œè‡ªå®šä¹‰é‡è¯•æ¬¡æ•°ã€‚
- **â¡ï¸ è½®æ¢ä»£ç†** - é…åˆå¤±è´¥é‡è¯•ï¼Œè‡ªå®šä¹‰é”™è¯¯æ¬¡æ•°ä»¥åŠ HTTP çŠ¶æ€ç è‡ªåŠ¨è½®æ¢ä»£ç†ã€‚
- **ğŸ‘€ è®¾å¤‡æŒ‡çº¹** - é›¶é…ç½®æˆ–è‡ªå®šä¹‰é…ç½®ï¼Œé¿å…æŒ‡çº¹è¯†åˆ«ä»ä¸åŒä½ç½®è¯†åˆ«å¹¶è·Ÿè¸ªæˆ‘ä»¬ã€‚
- **ğŸš€ ä¼˜å…ˆé˜Ÿåˆ—** - æ ¹æ®å•ä¸ªçˆ¬å–ç›®æ ‡çš„ä¼˜å…ˆçº§å¯ä»¥ä¼˜å…ˆäºå…¶ä»–ç›®æ ‡æå‰çˆ¬å–ã€‚
- **ğŸ§¾ æ•è·è®°å½•** - å¯¹çˆ¬å–è¿›è¡Œæ•è·è®°å½•ï¼Œå¹¶åœ¨ç»ˆç«¯ä½¿ç”¨å½©è‰²å­—ç¬¦ä¸²æé†’ã€‚
- **ğŸ¦¾ TypeScript** - æ‹¥æœ‰ç±»å‹ï¼Œé€šè¿‡æ³›å‹å®ç°å®Œæ•´çš„ç±»å‹ã€‚

## èµåŠ©

x-crawl æ˜¯é‡‡ç”¨ MIT è®¸å¯çš„å¼€æºé¡¹ç›®ï¼Œä½¿ç”¨å®Œå…¨å…è´¹ã€‚å¦‚æœä½ åœ¨å·¥ä½œä¸­å—ç›Šäºæˆ‘å¼€å‘ç»´æŠ¤çš„é¡¹ç›®ï¼Œè¯·è€ƒè™‘é€šè¿‡ [çˆ±å‘ç”µ](https://afdian.net/a/coderhxl) å¹³å°æ¥æ”¯æŒä¸€ä¸‹æˆ‘çš„å·¥ä½œã€‚

# ç›®å½•

- [å®‰è£…](#å®‰è£…)
- [ç¤ºä¾‹](#ç¤ºä¾‹)
- [æ ¸å¿ƒæ¦‚å¿µ](#æ ¸å¿ƒæ¦‚å¿µ)
  - [åˆ›å»ºåº”ç”¨](#åˆ›å»ºåº”ç”¨)
    - [ä¸€ä¸ªçˆ¬è™«åº”ç”¨å®ä¾‹](#ä¸€ä¸ªçˆ¬è™«åº”ç”¨å®ä¾‹)
    - [çˆ¬å–æ¨¡å¼](#çˆ¬å–æ¨¡å¼)
    - [é»˜è®¤è®¾å¤‡æŒ‡çº¹](#é»˜è®¤è®¾å¤‡æŒ‡çº¹)
    - [å¤šä¸ªçˆ¬è™«åº”ç”¨å®ä¾‹](#å¤šä¸ªçˆ¬è™«åº”ç”¨å®ä¾‹)
  - [çˆ¬å–é¡µé¢](#çˆ¬å–é¡µé¢)
    - [browser å®ä¾‹](#browser-å®ä¾‹)
    - [page å®ä¾‹](#page-å®ä¾‹)
    - [ç”Ÿå‘½å‘¨æœŸ](#ç”Ÿå‘½å‘¨æœŸ)
      - [onCrawlItemComplete](#onCrawlItemComplete)
    - [æ‰“å¼€æµè§ˆå™¨](#æ‰“å¼€æµè§ˆå™¨)
  - [çˆ¬å–æ¥å£](#çˆ¬å–æ¥å£)
    - [ç”Ÿå‘½å‘¨æœŸ](#ç”Ÿå‘½å‘¨æœŸ-1)
      - [onCrawlItemComplete](#onCrawlItemComplete-1)
  - [çˆ¬å–æ–‡ä»¶](#çˆ¬å–æ–‡ä»¶)
    - [ç”Ÿå‘½å‘¨æœŸ](#ç”Ÿå‘½å‘¨æœŸ-2)
      - [onCrawlItemComplete](#onCrawlItemComplete-2)
      - [onBeforeSaveItemFile](#onBeforeSaveItemFile)
  - [å¯åŠ¨è½®è¯¢](#å¯åŠ¨è½®è¯¢)
  - [é…ç½®ä¼˜å…ˆçº§](#é…ç½®ä¼˜å…ˆçº§)
  - [é—´éš”æ—¶é—´](#é—´éš”æ—¶é—´)
  - [å¤±è´¥é‡è¯•](#å¤±è´¥é‡è¯•)
  - [è½®æ¢ä»£ç†](#è½®æ¢ä»£ç†)
  - [è‡ªå®šä¹‰è®¾å¤‡æŒ‡çº¹](#è‡ªå®šä¹‰è®¾å¤‡æŒ‡çº¹)
  - [ä¼˜å…ˆé˜Ÿåˆ—](#ä¼˜å…ˆé˜Ÿåˆ—)
  - [å…³äºç»“æœ](#å…³äºç»“æœ)
  - [TypeScript](#TypeScript)
- [API](#API)
  - [xCrawl](#xCrawl)
    - [ç±»å‹](#ç±»å‹)
    - [ç¤ºä¾‹](#ç¤ºä¾‹-1)
  - [crawlPage](#crawlPage)
    - [ç±»å‹](#ç±»å‹-1)
    - [ç¤ºä¾‹](#ç¤ºä¾‹-2)
    - [é…ç½®](#é…ç½®)
      - [ç®€å•ç›®æ ‡é…ç½® - string](#ç®€å•ç›®æ ‡é…ç½®---string)
      - [è¯¦ç»†ç›®æ ‡é…ç½® - CrawlPageDetailTargetConfig](#è¯¦ç»†ç›®æ ‡é…ç½®---CrawlPageDetailTargetConfig)
      - [æ··åˆç›®æ ‡æ•°ç»„é…ç½® - (string | CrawlPageDetailTargetConfig)[]](#æ··åˆç›®æ ‡æ•°ç»„é…ç½®---string--CrawlPageDetailTargetConfig)
      - [è¿›é˜¶é…ç½® - CrawlPageAdvancedConfig](#è¿›é˜¶é…ç½®---CrawlPageAdvancedConfig)
  - [crawlData](#crawlData)
    - [ç±»å‹](#ç±»å‹-2)
    - [ç¤ºä¾‹](#ç¤ºä¾‹-3)
    - [é…ç½®](#é…ç½®-1)
      - [ç®€å•ç›®æ ‡é…ç½® - string](#ç®€å•ç›®æ ‡é…ç½®---string-1)
      - [è¯¦ç»†ç›®æ ‡é…ç½® - CrawlDataDetailTargetConfig](#è¯¦ç»†ç›®æ ‡é…ç½®---CrawlDataDetailTargetConfig)
      - [æ··åˆç›®æ ‡æ•°ç»„é…ç½® - (string | CrawlDataDetailTargetConfig)[]](#æ··åˆç›®æ ‡æ•°ç»„é…ç½®---string--CrawlDataDetailTargetConfig)
      - [è¿›é˜¶é…ç½® - CrawlDataAdvancedConfig](#è¿›é˜¶é…ç½®---CrawlDataAdvancedConfig)
  - [crawlFile](#crawlFile)
    - [ç±»å‹](#ç±»å‹-3)
    - [ç¤ºä¾‹](#ç¤ºä¾‹-4)
    - [é…ç½®](#é…ç½®-2)
      - [è¯¦ç»†ç›®æ ‡é…ç½® - CrawlFileDetailTargetConfig](#è¯¦ç»†ç›®æ ‡é…ç½®---CrawlFileDetailTargetConfig)
      - [è¯¦ç»†ç›®æ ‡æ•°ç»„é…ç½® - CrawlFileDetailTargetConfig[]](#è¯¦ç»†ç›®æ ‡æ•°ç»„é…ç½®---CrawlFileDetailTargetConfig)
      - [è¿›é˜¶é…ç½® - CrawlFileAdvancedConfig](#è¿›é˜¶é…ç½®---CrawlFileAdvancedConfig)
  - [startPolling](#startPolling)
    - [ç±»å‹](#ç±»å‹-4)
    - [ç¤ºä¾‹](#ç¤ºä¾‹-5)
    - [ç±»å‹](#ç±»å‹-5)
- [ç±»å‹](#ç±»å‹-6)
  - [API Config](#API-config)
    - [XCrawlConfig](#XCrawlConfig)
    - [Detail Target Config](#Detail-Target-Config)
      - [CrawlPageDetailTargetConfig](#CrawlPageDetailTargetConfig)
      - [CrawlDataDetailTargetConfig](#CrawlDataDetailTargetConfig)
      - [CrawlFileDetailTargetConfig](#CrawlFileDetailTargetConfig)
    - [Advanced Config](#Advanced-Config)
      - [CrawlPageAdvancedConfig](#CrawlPageAdvancedConfig)
      - [CrawlDataAdvancedConfig](#CrawlDataAdvancedConfig)
      - [CrawlFileAdvancedConfig](#CrawlFileAdvancedConfig)
    - [StartPollingConfig](#StartPollingConfig)
    - [Crawl Other Config](#Crawl-Other-Config)
      - [CrawlCommonConfig](#CrawlCommonConfig)
      - [DetailTargetFingerprintCommon](#DetailTargetFingerprintCommon)
      - [Mobile](#Mobile)
      - [Platform](#Platform)
      - [PageCookies](#PageCookies)
      - [Method](#Method)
      - [IntervalTime](#IntervalTime)
  - [API Result](#API-Result)
    - [XCrawlInstance](#XCrawlInstance)
    - [CrawlCommonResult](#CrawlCommonResult)
    - [CrawlPageSingleResult](#CrawlPageSingleResult)
    - [CrawlDataSingleResult](#CrawlDataSingleResult)
    - [CrawlFileSingleResult](#CrawlFileSingleResult)
  - [API Other](#API-Other)
    - [AnyObject](#AnyObject)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)
  - [crawlPage API è·Ÿ puppeteer çš„å…³ç³»](#crawlPage-API-è·Ÿ-puppeteer-çš„å…³ç³»)
- [æ›´å¤š](#æ›´å¤š)
  - [ç¤¾åŒº](#ç¤¾åŒº)
  - [Issues](#Issues)
  - [èµåŠ©](#èµåŠ©-1)

## å®‰è£…

ä»¥ NPM ä¸ºä¾‹:

```shell
npm install x-crawl
```

## ç¤ºä¾‹

ä»¥æ¯å¤©è‡ªåŠ¨è·å–ä¸–ç•Œå„åœ°çš„ç»å†å’Œæˆ¿é—´çš„ä¸€äº›ç…§ç‰‡ä¸ºä¾‹ï¼š

```js
// 1.å¯¼å…¥æ¨¡å— ES/CJS
import xCrawl from 'x-crawl'

// 2.åˆ›å»ºä¸€ä¸ªçˆ¬è™«å®ä¾‹
const myXCrawl = xCrawl({ maxRetry: 3, intervalTime: { max: 2000, min: 1000 } })

// 3.è®¾ç½®çˆ¬å–ä»»åŠ¡
// è°ƒç”¨ startPolling API å¼€å§‹è½®è¯¢åŠŸèƒ½ï¼Œæ¯éš”ä¸€å¤©ä¼šè°ƒç”¨å›è°ƒå‡½æ•°
myXCrawl.startPolling({ d: 1 }, async (count, stopPolling) => {
  // è°ƒç”¨ crawlPage API æ¥çˆ¬å–é¡µé¢
  const pageResults = await myXCrawl.crawlPage({
    targets: [
      'https://www.airbnb.cn/s/*/experiences',
      'https://www.airbnb.cn/s/plus_homes'
    ],
    viewport: { width: 1920, height: 1080 }
  })

  // é€šè¿‡éå†çˆ¬å–é¡µé¢ç»“æœè·å–å›¾ç‰‡ URL
  const imgUrls = []
  for (const item of pageResults) {
    const { id } = item
    const { page } = item.data
    const elSelector = id === 1 ? '.i9cqrtb' : '.c4mnd7m'

    // ç­‰å¾…é¡µé¢å…ƒç´ å‡ºç°
    await page.waitForSelector(elSelector)

    // è·å–é¡µé¢å›¾ç‰‡çš„ URL
    const urls = await page.$$eval(`${elSelector} picture img`, (imgEls) =>
      imgEls.map((item) => item.src)
    )
    imgUrls.push(...urls.slice(0, 8))

    // å…³é—­é¡µé¢
    page.close()
  }

  // è°ƒç”¨ crawlFile API çˆ¬å–å›¾ç‰‡
  await myXCrawl.crawlFile({ targets: imgUrls, storeDirs: './upload' })
})
```

è¿è¡Œæ•ˆæœ:

<div align="center">
  <img src="https://raw.githubusercontent.com/coder-hxl/x-crawl/main/assets/run-example-gif.gif" />
</div>

**æ³¨æ„:** è¯·å‹¿éšæ„çˆ¬å–ï¼Œçˆ¬å–å‰å¯æŸ¥çœ‹ **robots.txt** åè®®ã€‚ç½‘ç«™çš„ç±»åå¯èƒ½ä¼šæœ‰å˜æ›´ï¼Œè¿™é‡Œåªæ˜¯ä¸ºäº†æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ x-crawl ã€‚

## æ ¸å¿ƒæ¦‚å¿µ

### åˆ›å»ºåº”ç”¨

#### ä¸€ä¸ªçˆ¬è™«åº”ç”¨å®ä¾‹

é€šè¿‡ [xCrawl()](#xCrawl) åˆ›å»ºä¸€ä¸ªæ–°çš„ **åº”ç”¨å®ä¾‹:**

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl({
  // é€‰é¡¹
})
```

ç›¸å…³çš„ **é€‰é¡¹** å¯å‚è€ƒ [XCrawlBaseConfig](#XCrawlBaseConfig) ã€‚

#### çˆ¬å–æ¨¡å¼

ä¸€ä¸ªçˆ¬è™«åº”ç”¨å®ä¾‹æœ‰ä¸¤ç§çˆ¬å–æ¨¡å¼: å¼‚æ­¥/åŒæ­¥ï¼Œæ¯ä¸ªçˆ¬è™«å®ä¾‹åªèƒ½é€‰æ‹©å…¶ä¸­ä¸€ç§ã€‚

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl({
  mode: 'async'
})
```

mode é€‰é¡¹é»˜è®¤ä¸º async ã€‚

- async: å¼‚æ­¥çˆ¬å–ç›®æ ‡ï¼Œæ— éœ€ç­‰å½“å‰çˆ¬å–ç›®æ ‡å®Œæˆï¼Œå°±è¿›è¡Œä¸‹æ¬¡çˆ¬å–ç›®æ ‡
- sync: åŒæ­¥çˆ¬å–ç›®æ ‡ï¼Œéœ€è¦ç­‰è¿™æ¬¡çˆ¬å–ç›®æ ‡å®Œæˆï¼Œæ‰ä¼šè¿›è¡Œä¸‹æ¬¡çˆ¬å–ç›®æ ‡

è‹¥æœ‰è®¾ç½®é—´éš”æ—¶é—´ï¼Œåˆ™éƒ½éœ€è¦ç­‰é—´éš”æ—¶é—´ç»“æŸæ‰ä¼šçˆ¬å–ä¸‹æ¬¡ç›®æ ‡ã€‚

**æ³¨æ„:** çˆ¬å– API çš„çˆ¬å–è¿‡ç¨‹éƒ½æ˜¯å•ç‹¬è¿›è¡Œçš„ï¼Œè¯¥æ¨¡å¼å¯¹æ‰¹é‡çˆ¬å–ç›®æ ‡æ‰æœ‰æ•ˆã€‚

#### é»˜è®¤è®¾å¤‡æŒ‡çº¹

å¯ä»¥é€šè¿‡ä¸€ä¸ªå±æ€§æ§åˆ¶æ˜¯å¦ä½¿ç”¨é»˜è®¤çš„éšæœºæŒ‡çº¹ï¼Œæ‚¨ä¹Ÿå¯ä»¥é€šè¿‡åç»­çš„çˆ¬å–é…ç½®è‡ªå®šä¹‰æŒ‡çº¹ã€‚

è®¾ç½®è®¾å¤‡æŒ‡çº¹æ˜¯ä¸ºäº†é¿å…é€šè¿‡æŒ‡çº¹è¯†åˆ«ä»ä¸åŒä½ç½®è¯†åˆ«å¹¶è·Ÿè¸ªæˆ‘ä»¬ã€‚

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl({
  enableRandomFingerprint: true
})
```

enableRandomFingerprint é€‰é¡¹é»˜è®¤ä¸º trueã€‚

- true: å¯åŠ¨éšæœºè®¾å¤‡æŒ‡çº¹ã€‚å¯é€šè¿‡è¿›é˜¶é…ç½®æˆ–è¯¦ç»†ç›®æ ‡é…ç½®æŒ‡å®šç›®æ ‡çš„æŒ‡çº¹é…ç½®ã€‚
- false: å…³é—­éšæœºè®¾å¤‡æŒ‡çº¹ï¼Œä¸å½±å“è¿›é˜¶é…ç½®æˆ–è¯¦ç»†ç›®æ ‡é…ç½®ä¸ºç›®æ ‡æŒ‡å®šçš„æŒ‡çº¹é…ç½®ã€‚

#### å¤šä¸ªçˆ¬è™«åº”ç”¨å®ä¾‹

```js
import xCrawl from 'x-crawl'

const myXCrawl1 = xCrawl({
  // é€‰é¡¹
})

const myXCrawl2 = xCrawl({
  // é€‰é¡¹
})
```

### çˆ¬å–é¡µé¢

é€šè¿‡ [crawlPage()](#crawlPage) çˆ¬å–ä¸€ä¸ªé¡µé¢ã€‚

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl()

myXCrawl.crawlPage('https://www.example.com').then((res) => {
  const { browser, page } = res.data

  // å…³é—­æµè§ˆå™¨
  browser.close()
})
```

#### browser å®ä¾‹

å½“ä½ åœ¨åŒä¸ªçˆ¬è™«å®ä¾‹è°ƒç”¨ crawlPage API è¿›è¡Œçˆ¬å–é¡µé¢æ—¶ï¼Œæ‰€ç”¨çš„ browser å®ä¾‹éƒ½æ˜¯åŒä¸€ä¸ªï¼Œå› ä¸º browser å®ä¾‹åœ¨åŒä¸ªçˆ¬è™«å®ä¾‹ä¸­çš„ crawlPage API æ˜¯å…±äº«çš„ã€‚å…·ä½“ä½¿ç”¨å¯ä»¥å‚è€ƒ [Browser](https://pptr.dev/api/puppeteer.browser) ã€‚

**æ³¨æ„ï¼š** browser ä¼šä¸€ç›´ä¿æŒç€è¿è¡Œï¼Œé€ æˆæ–‡ä»¶ä¸ä¼šç»ˆæ­¢ï¼Œå¦‚æœæƒ³åœæ­¢å¯ä»¥æ‰§è¡Œ browser.close() å…³é—­ã€‚å¦‚æœåé¢è¿˜éœ€è¦ç”¨åˆ° [crawlPage](#crawlPage) æˆ–è€… [page](#page) è¯·å‹¿è°ƒç”¨ã€‚å› ä¸º browser å®ä¾‹åœ¨åŒä¸ªçˆ¬è™«å®ä¾‹ä¸­çš„ crawlPage API æ˜¯å…±äº«çš„ã€‚

#### page å®ä¾‹

å½“ä½ åœ¨åŒä¸ªçˆ¬è™«å®ä¾‹è°ƒç”¨ crawlPage API è¿›è¡Œçˆ¬å–é¡µé¢æ—¶ï¼Œéƒ½ä¼šä» browser å®ä¾‹ä¸­äº§ç”Ÿä¸€ä¸ªæ–°çš„ page å®ä¾‹ã€‚å…·ä½“ä½¿ç”¨å¯ä»¥å‚è€ƒ [Page](https://pptr.dev/api/puppeteer.page) ã€‚

browser å®ä¾‹å†…éƒ¨ä¼šä¿ç•™ç€å¯¹ page å®ä¾‹çš„å¼•ç”¨ï¼Œå¦‚æœåç»­ä¸å†ä½¿ç”¨éœ€è¦è‡ªè¡Œå…³é—­ page å®ä¾‹ï¼Œå¦åˆ™ä¼šé€ æˆå†…å­˜æ³„éœ²ã€‚

**è·å–å±å¹•æˆªå›¾**

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl()

myXCrawl.crawlPage('https://www.example.com').then(async (res) => {
  const { browser, page } = res.data

  // è·å–é¡µé¢æ¸²æŸ“åçš„æˆªå›¾
  await page.screenshot({ path: './upload/page.png' })

  console.log('è·å–å±å¹•æˆªå›¾å®Œæ¯•')

  browser.close()
})
```

#### ç”Ÿå‘½å‘¨æœŸ

crawlPage API æ‹¥æœ‰çš„å£°æ˜å‘¨æœŸå‡½æ•°:

- onCrawlItemComplete: å½“æ¯ä¸ªçˆ¬å–ç›®æ ‡å®Œæˆåä¼šå›è°ƒ

##### onCrawlItemComplete

åœ¨ onCrawlItemComplete å‡½æ•°ä¸­ä½ å¯ä»¥æå‰æ‹¿åˆ°æ¯æ¬¡çˆ¬å–ç›®æ ‡çš„ç»“æœã€‚

**æ³¨æ„:** å¦‚æœä½ éœ€è¦ä¸€æ¬¡æ€§çˆ¬å–å¾ˆå¤šé¡µé¢ï¼Œå°±éœ€è¦åœ¨æ¯ä¸ªé¡µé¢çˆ¬ä¸‹æ¥åï¼Œç”¨è¿™ä¸ªç”Ÿå‘½å‘¨æœŸå‡½æ•°æ¥å¤„ç†æ¯ä¸ªç›®æ ‡çš„ç»“æœå¹¶å…³é—­ page å®ä¾‹ï¼Œå¦‚æœä¸è¿›è¡Œå…³é—­æ“ä½œï¼Œåˆ™ä¼šå› å¼€å¯çš„ page è¿‡å¤šè€Œé€ æˆç¨‹åºå´©æºƒã€‚

#### æ‰“å¼€æµè§ˆå™¨

å–æ¶ˆä»¥æ— å¤´æ¨¡å¼è¿è¡Œæµè§ˆå™¨ã€‚

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl({
  maxRetry: 3,
  // å–æ¶ˆä»¥æ— å¤´æ¨¡å¼è¿è¡Œæµè§ˆå™¨
  crawlPage: { puppeteerLaunch: { headless: false } }
})

myXCrawl.crawlPage('https://www.example.com').then((res) => {})
```

### çˆ¬å–æ¥å£

é€šè¿‡ [crawlData()](#crawlData) çˆ¬å–æ¥å£æ•°æ®ã€‚

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl({ intervalTime: { max: 3000, min: 1000 } })

const targets = [
  'https://www.example.com/api-1',
  'https://www.example.com/api-2',
  {
    url: 'https://www.example.com/api-3',
    method: 'POST',
    data: { name: 'coderhxl' }
  }
]

myXCrawl.crawlData({ targets }).then((res) => {
  // å¤„ç†
})
```

#### ç”Ÿå‘½å‘¨æœŸ

crawlData API æ‹¥æœ‰çš„å£°æ˜å‘¨æœŸå‡½æ•°:

- onCrawlItemComplete: å½“æ¯ä¸ªçˆ¬å–ç›®æ ‡å®Œæˆåä¼šå›è°ƒ

##### onCrawlItemComplete

åœ¨ onCrawlItemComplete å‡½æ•°ä¸­ä½ å¯ä»¥æå‰æ‹¿åˆ°æ¯æ¬¡çˆ¬å–ç›®æ ‡çš„ç»“æœã€‚

### çˆ¬å–æ–‡ä»¶

é€šè¿‡ [crawlFile()](#crawlFile) çˆ¬å–æ–‡ä»¶æ•°æ®ã€‚

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl({ intervalTime: { max: 3000, min: 1000 } })

myXCrawl
  .crawlFile({
    targets: [
      'https://www.example.com/file-1',
      'https://www.example.com/file-2'
    ],
    storeDirs: './upload' // å­˜æ”¾æ–‡ä»¶å¤¹
  })
  .then((res) => {})
```

#### ç”Ÿå‘½å‘¨æœŸ

crawlFile API æ‹¥æœ‰çš„å£°æ˜å‘¨æœŸå‡½æ•°:

- onCrawlItemComplete: å½“æ¯ä¸ªçˆ¬å–ç›®æ ‡å®Œæˆåä¼šå›è°ƒ

- onBeforeSaveItemFile: ä¼šåœ¨ä¿å­˜æ–‡ä»¶å‰å›è°ƒ

##### onCrawlItemComplete

åœ¨ onCrawlItemComplete å‡½æ•°ä¸­ä½ å¯ä»¥æå‰æ‹¿åˆ°æ¯æ¬¡çˆ¬å–ç›®æ ‡çš„ç»“æœã€‚

##### onBeforeSaveItemFile

åœ¨ onBeforeSaveItemFile å‡½æ•°ä¸­ä½ å¯ä»¥æ‹¿åˆ° Buffer ç±»å‹çš„æ–‡ä»¶ï¼Œä½ å¯ä»¥å¯¹è¯¥ Buffer è¿›è¡Œå¤„ç†ï¼Œç„¶åéœ€è¦è¿”å›ä¸€ä¸ª Promise ï¼Œå¹¶ä¸” resolve æ˜¯ Buffer ï¼Œè¯¥ Buffer ä¼šæ›¿æ¢æ‰æ‹¿åˆ°çš„ Buffer å­˜å‚¨åˆ°æ–‡ä»¶ä¸­ã€‚

**è°ƒæ•´å›¾ç‰‡å¤§å°**

ä½¿ç”¨ sharp åº“å¯¹éœ€è¦çˆ¬å–çš„å›¾ç‰‡è¿›è¡Œè°ƒæ•´å¤§å°æ“ä½œ:

```js
import xCrawl from 'x-crawl'
import sharp from 'sharp'

const myXCrawl = xCrawl()

myXCrawl
  .crawlFile({
    targets: [
      'https://www.example.com/file-1.jpg',
      'https://www.example.com/file-2.jpg'
    ],
    onBeforeSaveItemFile(info) {
      return sharp(info.data).resize(200).toBuffer()
    }
  })
  .then((res) => {
    res.forEach((item) => {
      console.log(item.data?.data.isSuccess)
    })
  })
```

### å¯åŠ¨è½®è¯¢

é€šè¿‡ [startPolling()](#startPolling) å¯åŠ¨ä¸€ä¸ªè½®è¯¢çˆ¬å–ã€‚

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl({
  timeout: 10000
})

myXCrawl.startPolling({ h: 2, m: 30 }, async (count, stopPolling) => {
  // æ¯éš”ä¸¤ä¸ªåŠå°æ—¶ä¼šæ‰§è¡Œä¸€æ¬¡
  // crawlPage/crawlData/crawlFile
  const res = await myXCrawl.crawlPage('https://www.example.com')
  res.data.page.close()
})
```

**åœ¨è½®è¯¢ä¸­ä½¿ç”¨ crawlPage æ³¨æ„ï¼š** browser å®ä¾‹å†…éƒ¨ä¼šä¿ç•™ç€å¯¹ page å®ä¾‹çš„å¼•ç”¨ï¼Œå¦‚æœåç»­ä¸å†ä½¿ç”¨éœ€è¦è‡ªè¡Œå…³é—­ page å®ä¾‹ï¼Œå¦åˆ™ä¼šé€ æˆå†…å­˜æ³„éœ²ã€‚

å›è°ƒå‡½æ•°å‚æ•°ï¼š

- count å±æ€§è®°å½•å½“å‰æ˜¯ç¬¬å‡ æ¬¡è½®è¯¢æ“ä½œã€‚
- stopPolling æ˜¯ä¸€ä¸ªå›è°ƒå‡½æ•°ï¼Œè°ƒç”¨å…¶å¯ä»¥ç»ˆæ­¢åé¢çš„è½®è¯¢æ“ä½œã€‚

### é…ç½®ä¼˜å…ˆçº§

ä¸€äº›é€šç”¨çš„é…ç½®å¯ä»¥é€šè¿‡åœ¨è¿™ä¸‰ä¸ªåœ°æ–¹è®¾ç½®ï¼š

- åº”ç”¨å®ä¾‹é…ç½®ï¼ˆå…¨å±€ï¼‰
- è¿›é˜¶é…ç½®ï¼ˆå±€éƒ¨ï¼‰
- è¯¦ç»†ç›®æ ‡é…ç½®ï¼ˆå•ç‹¬ï¼‰

ä¼˜å…ˆçº§ä¸ºï¼šè¯¦ç»†ç›®æ ‡é…ç½® > è¿›é˜¶é…ç½® > åº”ç”¨å®ä¾‹é…ç½®

ä»¥ crawlPage çˆ¬å–ä¸¤ä¸ªé¡µé¢ä¸ºä¾‹ï¼š

```js
import xCrawl from 'x-crawl'

// åº”ç”¨å®ä¾‹é…ç½®
const testXCrawl = xCrawl({
  proxy: {
    urls: [
      'https://www.example.com/proxy-1',
      'https://www.example.com/proxy-2',
      'https://www.example.com/proxy-3'
    ],
    switchByErrorCount: 3,
    switchByHttpStatus: [401, 403]
  }
})

// è¿›é˜¶é…ç½®
testXCrawl
  .crawlPage({
    targets: [
      'https://www.example.com/page-1',
      'https://www.example.com/page-2',
      // è¯¦ç»†ç›®æ ‡é…ç½®
      {
        url: 'https://www.example.com/page-3',
        proxy: { urls: ['https://www.example.com/proxy-5'] }
      }
    ],
    maxRetry: 10,
    proxy: {
      urls: [
        'https://www.example.com/proxy-3',
        'https://www.example.com/proxy-4'
      ],
      switchByErrorCount: 3,
      switchByHttpStatus: [401, 403]
    }
  })
  .then((res) => {})
```

åœ¨ä¸Šé¢çš„å®ä¾‹ä¸­ï¼Œ**åº”ç”¨å®ä¾‹é…ç½®**ã€**è¿›é˜¶é…ç½®**ä»¥åŠ**è¯¦ç»†ç›®æ ‡é…ç½®**ä¸­éƒ½è®¾ç½®äº†**ä»£ç†**ï¼Œpage3 å°†ä¼šé‡‡ç”¨è‡ªå·±çš„ä»£ç†é…ç½®ï¼Œpage1 å’Œ page2 å°†é‡‡ç”¨è¿›é˜¶é…ç½®çš„ä»£ç†é…ç½®ã€‚

### é—´éš”æ—¶é—´

é—´éš”æ—¶é—´å¯ä»¥é˜²æ­¢å¹¶å‘é‡å¤ªå¤§ï¼Œé¿å…ç»™æœåŠ¡å™¨é€ æˆå¤ªå¤§çš„å‹åŠ›ã€‚

çˆ¬å–é—´éš”æ—¶é—´æ˜¯ç”±çˆ¬å– API å†…éƒ¨è‡ªå·±æ§åˆ¶çš„ï¼Œå¹¶éç”±çˆ¬è™«å®ä¾‹æ§åˆ¶çˆ¬å– API çš„é—´éš”æ—¶é—´ã€‚

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl()

myXCrawl
  .crawlData({
    targets: ['https://www.example.com/api-1', 'https://www.example.com/api-2'],
    intervalTime: { max: 2000, min: 1000 }
  })
  .then((res) => {})
```

intervalTime é€‰é¡¹é»˜è®¤ä¸º undefined ã€‚è‹¥æœ‰è®¾ç½®å€¼ï¼Œåˆ™ä¼šåœ¨çˆ¬å–ç›®æ ‡å‰ç­‰å¾…ä¸€æ®µæ—¶é—´ï¼Œå¯ä»¥é˜²æ­¢å¹¶å‘é‡å¤ªå¤§ï¼Œé¿å…ç»™æœåŠ¡å™¨é€ æˆå¤ªå¤§çš„å‹åŠ›ã€‚

- number: å›ºå®šæ¯æ¬¡çˆ¬å–ç›®æ ‡å‰å¿…é¡»ç­‰å¾…çš„æ—¶é—´
- IntervalTime: åœ¨ max å’Œ min ä¸­éšæœºå–ä¸€ä¸ªå€¼

**æ³¨æ„:** ç¬¬ä¸€æ¬¡çˆ¬å–ç›®æ ‡æ˜¯ä¸ä¼šè§¦å‘é—´éš”æ—¶é—´ã€‚

### å¤±è´¥é‡è¯•

å¯é¿å…å› ä¸€æ—¶é—®é¢˜è€Œé€ æˆçˆ¬å–å¤±è´¥ï¼Œå°†ä¼šç­‰å¾…è¿™ä¸€è½®çˆ¬å–ç›®æ ‡ç»“æŸåé‡æ–°çˆ¬å–ç›®æ ‡ã€‚

å¯ä»¥åœ¨ åˆ›å»ºçˆ¬è™«åº”ç”¨å®ä¾‹ã€è¿›é˜¶ç”¨æ³•ã€è¯¦ç»†ç›®æ ‡ è¿™ä¸‰ä¸ªåœ°æ–¹è®¾ç½®ã€‚

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl()

myXCrawl
  .crawlData({ url: 'https://www.example.com/api', maxRetry: 9 })
  .then((res) => {})
```

maxRetry å±æ€§å†³å®šè¦é‡è¯•å‡ æ¬¡ã€‚

### è½®æ¢ä»£ç†

é…åˆå¤±è´¥é‡è¯•ï¼Œè‡ªå®šä¹‰é”™è¯¯æ¬¡æ•°ä»¥åŠ HTTP çŠ¶æ€ç ä¸ºçˆ¬å–ç›®æ ‡è‡ªåŠ¨è½®æ¢ä»£ç†ã€‚

å¯ä»¥åœ¨ åˆ›å»ºçˆ¬è™«åº”ç”¨å®ä¾‹ã€è¿›é˜¶ç”¨æ³•ã€è¯¦ç»†ç›®æ ‡ è¿™ä¸‰ä¸ªåœ°æ–¹è®¾ç½®ã€‚

ä»¥ crawlPage ä¸ºä¾‹ï¼š

```js
import xCrawl from 'x-crawl'

const testXCrawl = xCrawl()

testXCrawl
  .crawlPage({
    targets: [
      'https://www.example.com/page-1',
      'https://www.example.com/page-2',
      'https://www.example.com/page-3',
      'https://www.example.com/page-4',
      // ä¸ºæ­¤ç›®æ ‡å–æ¶ˆä»£ç†
      { url: 'https://www.example.com/page-6', proxy: null },
      // ä¸ºæ­¤ç›®æ ‡å•ç‹¬è®¾ç½®ä»£ç†
      {
        url: 'https://www.example.com/page-6',
        proxy: {
          urls: [
            'https://www.example.com/proxy-4',
            'https://www.example.com/proxy-5'
          ],
          switchByErrorCount: 3
        }
      }
    ],
    maxRetry: 10,
    // ä¸ºæ­¤æ¬¡çš„ç›®æ ‡ç»Ÿä¸€è®¾ç½®ä»£ç†
    proxy: {
      urls: [
        'https://www.example.com/proxy-1',
        'https://www.example.com/proxy-2',
        'https://www.example.com/proxy-3'
      ],
      switchByErrorCount: 3,
      switchByHttpStatus: [401, 403]
    }
  })
  .then((res) => {})
```

**æ³¨æ„:** è¯¥åŠŸèƒ½éœ€è¦é…åˆå¤±è´¥é‡è¯•æ‰èƒ½æ­£å¸¸ä½¿ç”¨ã€‚

### è‡ªå®šä¹‰è®¾å¤‡æŒ‡çº¹

è‡ªå®šä¹‰é…ç½®è®¾å¤‡æŒ‡çº¹ï¼Œå¯é¿å…é€šè¿‡æŒ‡çº¹è¯†åˆ«ä»ä¸åŒä½ç½®è¯†åˆ«å¹¶è·Ÿè¸ªæˆ‘ä»¬ã€‚

å¯ä»¥é€šè¿‡è¿›é˜¶ç”¨æ³•åœ¨ fingerprints ä¼ å…¥å¤šä¸ªä¿¡æ¯ï¼Œå†…éƒ¨ä¼šå¸®åŠ©æ‚¨éšæœºåˆ†é…ç»™ targets çš„æ¯ä¸ªç›®æ ‡ã€‚ä¹Ÿå¯ä»¥ç›´æ¥ç”¨è¯¦ç»†ç›®æ ‡é…ç½®ä¸ºç›®æ ‡è®¾ç½®ç‰¹å®šçš„æŒ‡çº¹ã€‚

ä»¥ crawlPage ä¸ºä¾‹ï¼š

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl({ intervalTime: { max: 5000, min: 3000 } })

myXCrawl.crawlPage({
  targets: [
    'https://www.example.com/page-1',
    'https://www.example.com/page-2',
    'https://www.example.com/page-3',
    // ä¸ºæ­¤ç›®æ ‡å–æ¶ˆæŒ‡çº¹
    { url: 'https://www.example.com/page-4', fingerprint: null },
    // ä¸ºæ­¤ç›®æ ‡å•ç‹¬è®¾ç½®æŒ‡çº¹
    {
      url: 'https://www.example.com/page-5',
      fingerprint: {
        mobile: 'random',
        platform: 'Windows',
        acceptLanguage: `zh-CN,zh;q=0.9,en;q=0.8`,
        userAgent: {
          value:
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36',
          versions: [
            { name: 'Chrome', maxMinorVersion: 10, maxPatchVersion: 5615 },
            { name: 'Safari', maxMinorVersion: 36, maxPatchVersion: 2333 }
          ]
        }
      }
    }
  ],
  // ä¸ºæ­¤æ¬¡çš„ç›®æ ‡ç»Ÿä¸€è®¾ç½®æŒ‡çº¹
  fingerprints: [
    // è®¾å¤‡æŒ‡çº¹ 1
    {
      maxWidth: 1024,
      maxHeight: 800,
      platform: 'Windows',
      mobile: 'random',
      userAgent: {
        value:
          'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36',
        versions: [
          {
            name: 'Chrome',
            // æµè§ˆå™¨ç‰ˆæœ¬
            maxMajorVersion: 112,
            minMajorVersion: 100,
            maxMinorVersion: 20,
            maxPatchVersion: 5000
          },
          {
            name: 'Safari',
            maxMajorVersion: 537,
            minMajorVersion: 500,
            maxMinorVersion: 36,
            maxPatchVersion: 5000
          }
        ]
      }
    },
    // è®¾å¤‡æŒ‡çº¹ 2
    {
      platform: 'Windows',
      mobile: 'random',
      userAgent: {
        value:
          'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36 Edg/91.0.864.59',
        versions: [
          {
            name: 'Chrome',
            maxMajorVersion: 91,
            minMajorVersion: 88,
            maxMinorVersion: 10,
            maxPatchVersion: 5615
          },
          { name: 'Safari', maxMinorVersion: 36, maxPatchVersion: 2333 },
          { name: 'Edg', maxMinorVersion: 10, maxPatchVersion: 864 }
        ]
      }
    },
    // è®¾å¤‡æŒ‡çº¹ 3
    {
      platform: 'Windows',
      mobile: 'random',
      userAgent: {
        value:
          'Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:47.0) Gecko/20100101 Firefox/47.0',
        versions: [
          {
            name: 'Firefox',
            maxMajorVersion: 47,
            minMajorVersion: 43,
            maxMinorVersion: 10,
            maxPatchVersion: 5000
          }
        ]
      }
    }
  ]
})
```

æ›´å¤šæŒ‡çº¹é€‰é¡¹å¯ä»¥å‰å¾€å¯¹åº”çš„é…ç½®æŸ¥çœ‹ã€‚

### ä¼˜å…ˆé˜Ÿåˆ—

ä¼˜å…ˆé˜Ÿåˆ—å¯ä»¥è®©æŸä¸ªçˆ¬å–ç›®æ ‡ä¼˜å…ˆå‘é€ã€‚

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl()

myXCrawl
  .crawlData([
    { url: 'https://www.example.com/api-1', priority: 1 },
    { url: 'https://www.example.com/api-2', priority: 10 },
    { url: 'https://www.example.com/api-3', priority: 8 }
  ])
  .then((res) => {})
```

priority å±æ€§çš„å€¼è¶Šå¤§å°±åœ¨å½“å‰çˆ¬å–é˜Ÿåˆ—ä¸­è¶Šä¼˜å…ˆã€‚

### å…³äºç»“æœ

æ¯ä¸ªçˆ¬å–ç›®æ ‡éƒ½ä¼šäº§ç”Ÿä¸€ä¸ªè¯¦æƒ…å¯¹è±¡ï¼Œè¯¥è¯¦æƒ…å¯¹è±¡ä¼šåŒ…å«ä»¥ä¸‹å±æ€§ï¼š

- idï¼šæ ¹æ®çˆ¬å–ç›®æ ‡çš„é¡ºåºç”Ÿæˆçš„ï¼Œå¦‚æœæœ‰ä¼˜å…ˆçº§ï¼Œåˆ™ä¼šæ ¹æ®ä¼˜å…ˆçº§ç”Ÿæˆ
- isSuccessï¼šæ˜¯å¦æˆåŠŸçˆ¬å–
- maxRetryï¼šè¯¥æ¬¡çˆ¬å–ç›®æ ‡çš„æœ€å¤§é‡è¯•æ¬¡æ•°
- retryCountï¼šè¯¥æ¬¡çˆ¬å–ç›®æ ‡å·²ç»é‡è¯•çš„æ¬¡æ•°
- proxyDetailsï¼šè®°å½•ä»£ç†æƒ…å†µ
- crawlErrorQueueï¼šè¯¥æ¬¡çˆ¬å–ç›®æ ‡çš„æŠ¥é”™æ”¶é›†
- dataï¼šè¯¥æ¬¡çˆ¬å–ç›®æ ‡çš„çˆ¬å–æ•°æ®

å¦‚æœæ˜¯ç‰¹å®šçš„é…ç½®ï¼Œä¼šè‡ªåŠ¨æ ¹æ®ä½ é€‰ç”¨çš„é…ç½®æ–¹å¼å†³å®šè¯¦æƒ…å¯¹è±¡æ˜¯å¦å­˜æ”¾åœ¨ä¸€ä¸ªæ•°ç»„ä¸­ï¼Œå¹¶æŠŠè¯¥æ•°ç»„è¿”å›ï¼Œå¦åˆ™è¿”å›è¯¦æƒ…å¯¹è±¡ã€‚å·²ç»åœ¨ TypeScript ä¸­ç±»å‹å®Œç¾é€‚é…ã€‚

ç›¸å…³çš„é…ç½®æ–¹å¼å’Œç»“æœè¯¦æƒ…æŸ¥çœ‹ï¼š[crawlPage é…ç½®](#é…ç½®)ã€[crawlData é…ç½®](#é…ç½®-1)ã€[crawlFile é…ç½®](#é…ç½®-2) ã€‚

### TypeScript

åƒ TypeScript è¿™æ ·çš„ç±»å‹ç³»ç»Ÿå¯ä»¥åœ¨ç¼–è¯‘æ—¶é€šè¿‡é™æ€åˆ†ææ£€æµ‹å‡ºå¾ˆå¤šå¸¸è§é”™è¯¯ã€‚è¿™å‡å°‘äº†è¿è¡Œæ—¶é”™è¯¯ï¼Œä¹Ÿè®©æˆ‘ä»¬åœ¨é‡æ„å¤§å‹é¡¹ç›®çš„æ—¶å€™æ›´æœ‰ä¿¡å¿ƒã€‚é€šè¿‡ IDE ä¸­åŸºäºç±»å‹çš„è‡ªåŠ¨è¡¥å…¨ï¼ŒTypeScript è¿˜æ”¹å–„äº†å¼€å‘ä½“éªŒå’Œæ•ˆç‡ã€‚

x-crawl æœ¬èº«å°±æ˜¯ç”¨ TypeScript ç¼–å†™çš„ï¼Œå¹¶å¯¹ TypeScript æä¾›äº†æ”¯æŒã€‚è‡ªå¸¦ç±»å‹å£°æ˜æ–‡ä»¶ï¼Œå¼€ç®±å³ç”¨ã€‚

## API

### xCrawl

é€šè¿‡è°ƒç”¨ xCrawl åˆ›å»ºä¸€ä¸ªçˆ¬è™«å®ä¾‹ã€‚çˆ¬å–ç›®æ ‡æ˜¯ç”±å®ä¾‹æ–¹æ³•å†…éƒ¨è‡ªå·±ç»´æŠ¤ï¼Œå¹¶éç”±å®ä¾‹è‡ªå·±ç»´æŠ¤ã€‚

#### ç±»å‹

xCrawl API æ˜¯ä¸€ä¸ªå‡½æ•°ã€‚

```ts
function xCrawl(baseConfig?: XCrawlBaseConfig): XCrawlInstance
```

**å‚æ•°ç±»å‹ï¼š**

- æŸ¥çœ‹ [XCrawlBaseConfig](#XCrawlBaseConfig) ç±»å‹

**è¿”å›å€¼ç±»å‹ï¼š**

- æŸ¥çœ‹ [XCrawlInstance](#XCrawlInstance)ç±»å‹

#### ç¤ºä¾‹

```js
import xCrawl from 'x-crawl'

// xCrawl API
const myXCrawl = xCrawl({
  baseUrl: 'https://www.example.com',
  timeout: 10000,
  intervalTime: { max: 2000, min: 1000 }
})
```

### crawlPage

crawlPage æ˜¯çˆ¬è™«å®ä¾‹çš„æ–¹æ³•ï¼Œé€šå¸¸ç”¨äºçˆ¬å–é¡µé¢ã€‚

#### ç±»å‹

crawlPage API æ˜¯ä¸€ä¸ªå‡½æ•°ã€‚ç±»å‹æ˜¯ [é‡è½½å‡½æ•°](https://www.typescriptlang.org/docs/handbook/2/functions.html#function-overloads) å¯ä»¥é€šè¿‡ä¸åŒçš„é…ç½®å‚æ•°è°ƒç”¨è¯¥å‡½æ•°ï¼ˆåœ¨ç±»å‹æ–¹é¢ï¼‰ã€‚

```ts
type crawlPage = {
  (
    config: string,
    callback?: (res: CrawlPageSingleResult) => void
  ): Promise<CrawlPageSingleResult>

  (
    config: CrawlPageDetailTargetConfig,
    callback?: (res: CrawlPageSingleResult) => void
  ): Promise<CrawlPageSingleResult>

  (
    config: (string | CrawlPageDetailTargetConfig)[],
    callback?: (res: CrawlPageSingleResult[]) => void
  ): Promise<CrawlPageSingleResult[]>

  (
    config: CrawlPageAdvancedConfig,
    callback?: (res: CrawlPageSingleResult[]) => void
  ): Promise<CrawlPageSingleResult[]>
}
```

**å‚æ•°ç±»å‹ï¼š**

- æŸ¥çœ‹ [CrawlPageDetailTargetConfig](#CrawlPageDetailTargetConfig) ç±»å‹
- æŸ¥çœ‹ [CrawlPageAdvancedConfig](#CrawlPageAdvancedConfig) ç±»å‹

**è¿”å›å€¼ç±»å‹ï¼š**

- æŸ¥çœ‹ [CrawlPageSingleResult](#CrawlPageSingleResult) ç±»å‹

#### ç¤ºä¾‹

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl()

// crawlPage API
myXCrawl.crawlPage('https://www.example.com').then((res) => {
  const { browser, page } = res.data

  // å…³é—­æµè§ˆå™¨
  browser.close()
})
```

#### é…ç½®

ä¸€å…±æœ‰ 4 ç§:

- ç®€å•ç›®æ ‡é…ç½® - string
- è¯¦ç»†ç›®æ ‡é…ç½® - CrawlPageDetailTargetConfig
- æ··åˆç›®æ ‡æ•°ç»„é…ç½® - (string | CrawlPageDetailTargetConfig)[]
- è¿›é˜¶é…ç½® - CrawlPageAdvancedConfig

##### ç®€å•ç›®æ ‡é…ç½® - string

è¿™æ˜¯ç®€å•ç›®æ ‡é…ç½®ã€‚å¦‚æœä½ åªæƒ³å•çº¯çˆ¬ä¸€ä¸‹è¿™ä¸ªé¡µé¢ï¼Œå¯ä»¥è¯•è¯•è¿™ç§å†™æ³•ï¼š

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl()

myXCrawl.crawlPage('https://www.example.com').then((res) => {})
```

æ‹¿åˆ°çš„ res å°†æ˜¯ä¸€ä¸ªå¯¹è±¡ã€‚

##### è¯¦ç»†ç›®æ ‡é…ç½® - CrawlPageDetailTargetConfig

è¿™æ˜¯è¯¦ç»†ç›®æ ‡é…ç½®ã€‚å¦‚æœä½ æƒ³çˆ¬ä¸€ä¸‹è¿™ä¸ªé¡µé¢ï¼Œå¹¶ä¸”éœ€è¦å¤±è´¥é‡è¯•ä¹‹ç±»çš„ï¼Œå¯ä»¥è¯•è¯•è¿™ç§å†™æ³•ï¼š

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl()

myXCrawl
  .crawlPage({
    url: 'https://www.example.com',
    proxy: 'xxx',
    maxRetry: 1
  })
  .then((res) => {})
```

æ‹¿åˆ°çš„ res å°†æ˜¯ä¸€ä¸ªå¯¹è±¡ã€‚

æ›´å¤šé…ç½®é€‰é¡¹å¯ä»¥æŸ¥çœ‹ [CrawlPageDetailTargetConfig](#CrawlPageDetailTargetConfig) ã€‚

##### æ··åˆç›®æ ‡æ•°ç»„é…ç½® - (string | CrawlPageDetailTargetConfig)[]

è¿™æ˜¯æ··åˆç›®æ ‡æ•°ç»„é…ç½®ã€‚å¦‚æœä½ æƒ³çˆ¬å–å¤šä¸ªé¡µé¢ï¼Œå¹¶ä¸”æœ‰äº›é¡µé¢éœ€è¦å¤±è´¥é‡è¯•ä¹‹ç±»çš„ï¼Œå¯ä»¥è¯•è¯•è¿™ç§å†™æ³•ï¼š

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl()

myXCrawl
  .crawlPage([
    'https://www.example.com/page-1',
    { url: 'https://www.example.com/page-2', maxRetry: 2 }
  ])
  .then((res) => {})
```

æ‹¿åˆ°çš„ res å°†æ˜¯ä¸€ä¸ªæ•°ç»„ï¼Œé‡Œé¢æ˜¯å¯¹è±¡ã€‚

æ›´å¤šé…ç½®é€‰é¡¹å¯ä»¥æŸ¥çœ‹ [CrawlPageDetailTargetConfig](#CrawlPageDetailTargetConfig) ã€‚

##### è¿›é˜¶é…ç½® - CrawlPageAdvancedConfig

è¿™æ˜¯è¿›é˜¶é…ç½®ï¼Œtargets æ˜¯æ··åˆç›®æ ‡æ•°ç»„é…ç½®ã€‚å¦‚æœä½ æƒ³çˆ¬å–å¤šä¸ªé¡µé¢ï¼Œå¹¶ä¸”çˆ¬å–ç›®æ ‡é…ç½®ï¼ˆproxyã€cookiesã€é‡è¯•ç­‰ç­‰ï¼‰ä¸æƒ³é‡å¤å†™ï¼Œè¿˜éœ€è¦é—´éš”æ—¶é—´ã€è®¾å¤‡æŒ‡çº¹ä»¥åŠç”Ÿå‘½å‘¨æœŸç­‰ç­‰ï¼Œå¯ä»¥è¯•è¯•è¿™ç§å†™æ³•ï¼š

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl()

myXCrawl
  .crawlPage({
    targets: [
      'https://www.example.com/page-1',
      { url: 'https://www.example.com/page-2', maxRetry: 6 }
    ],
    intervalTime: { max: 3000, min: 1000 },
    cookies: 'xxx',
    maxRetry: 1
  })
  .then((res) => {})
```

æ‹¿åˆ°çš„ res å°†æ˜¯ä¸€ä¸ªæ•°ç»„ï¼Œé‡Œé¢æ˜¯å¯¹è±¡ã€‚

æ›´å¤šé…ç½®é€‰é¡¹å¯ä»¥æŸ¥çœ‹ [CrawlPageAdvancedConfig](#CrawlPageAdvancedConfig) ã€‚

å…³äºç»“æœçš„æ›´å¤šä¿¡æ¯å¯æŸ¥çœ‹ [å…³äºç»“æœ](#å…³äºç»“æœ) ï¼Œå¯ä»¥æ ¹æ®å®é™…æƒ…å†µé€‰ç”¨å³å¯ã€‚

### crawlData

crawl æ˜¯çˆ¬è™«å®ä¾‹çš„æ–¹æ³•ï¼Œé€šå¸¸ç”¨äºçˆ¬å– API ï¼Œå¯è·å– JSON æ•°æ®ç­‰ç­‰ã€‚

#### ç±»å‹

crawlData API æ˜¯ä¸€ä¸ªå‡½æ•°ã€‚ç±»å‹æ˜¯ [é‡è½½å‡½æ•°](https://www.typescriptlang.org/docs/handbook/2/functions.html#function-overloads) å¯ä»¥é€šè¿‡ä¸åŒçš„é…ç½®å‚æ•°è°ƒç”¨è¯¥å‡½æ•°ï¼ˆåœ¨ç±»å‹æ–¹é¢ï¼‰ã€‚

```ts
type crawlData = {
  <T = any>(
    config: CrawlDataDetailTargetConfig,
    callback?: (res: CrawlDataSingleResult<T>) => void
  ): Promise<CrawlDataSingleResult<T>>

  <T = any>(
    config: string,
    callback?: (res: CrawlDataSingleResult<T>) => void
  ): Promise<CrawlDataSingleResult<T>>

  <T = any>(
    config: (string | CrawlDataDetailTargetConfig)[],
    callback?: (res: CrawlDataSingleResult<T>[]) => void
  ): Promise<CrawlDataSingleResult<T>[]>

  <T = any>(
    config: CrawlDataAdvancedConfig<T>,
    callback?: (res: CrawlDataSingleResult<T>[]) => void
  ): Promise<CrawlDataSingleResult<T>[]>
}
```

**å‚æ•°ç±»å‹ï¼š**

- æŸ¥çœ‹ [CrawlDataDetailTargetConfig](#CrawlDataDetailTargetConfig) ç±»å‹
- æŸ¥çœ‹ [CrawlDataAdvancedConfig](#CrawlDataAdvancedConfig) ç±»å‹

**è¿”å›å€¼ç±»å‹ï¼š**

- æŸ¥çœ‹ [CrawlDataSingleResult](#CrawlDataSingleResult) ç±»å‹

#### ç¤ºä¾‹

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl({
  timeout: 10000,
  intervalTime: { max: 2000, min: 1000 }
})

// crawlData API
myXCrawl
  .crawlData({
    targets: ['https://www.example.com/api-1', 'https://www.example.com/api-2'],
    intervalTime: { max: 3000, min: 1000 },
    cookies: 'xxx',
    maxRetry: 1
  })
  .then((res) => {
    console.log(res)
  })
```

#### é…ç½®

ä¸€å…±æœ‰ 4 ç§:

- ç®€å•ç›®æ ‡é…ç½® - string
- è¯¦ç»†ç›®æ ‡é…ç½® - CrawlDataDetailTargetConfig
- æ··åˆç›®æ ‡æ•°ç»„é…ç½® - (string | CrawlDataDetailTargetConfig)[]
- è¿›é˜¶é…ç½® - CrawlDataAdvancedConfig

##### ç®€å•ç›®æ ‡é…ç½® - string

è¿™æ˜¯ç®€å•ç›®æ ‡é…ç½®ã€‚å¦‚æœä½ åªæƒ³å•çº¯çˆ¬ä¸€ä¸‹è¿™ä¸ªæ•°æ®ï¼Œå¹¶ä¸”è¯¥æ¥å£æ˜¯ GET æ–¹å¼çš„ï¼Œå¯ä»¥è¯•è¯•è¿™ç§å†™æ³•ï¼š

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl()

myXCrawl.crawlData('https://www.example.com/api').then((res) => {})
```

æ‹¿åˆ°çš„ res å°†æ˜¯ä¸€ä¸ªå¯¹è±¡ã€‚

##### è¯¦ç»†ç›®æ ‡é…ç½® - CrawlDataDetailTargetConfig

è¿™æ˜¯è¯¦ç»†ç›®æ ‡é…ç½®ã€‚å¦‚æœä½ æƒ³çˆ¬ä¸€ä¸‹è¿™ä¸ªæ•°æ®ï¼Œå¹¶ä¸”éœ€è¦å¤±è´¥é‡è¯•ä¹‹ç±»çš„ï¼Œå¯ä»¥è¯•è¯•è¿™ç§å†™æ³•ï¼š

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl()

myXCrawl
  .crawlData({
    url: 'https://www.example.com/api',
    proxy: 'xxx',
    maxRetry: 1
  })
  .then((res) => {})
```

æ‹¿åˆ°çš„ res å°†æ˜¯ä¸€ä¸ªå¯¹è±¡ã€‚

æ›´å¤šé…ç½®é€‰é¡¹å¯ä»¥æŸ¥çœ‹ [CrawlDataDetailTargetConfig](#CrawlDataDetailTargetConfig) ã€‚

##### æ··åˆç›®æ ‡æ•°ç»„é…ç½® - (string | CrawlDataDetailTargetConfig)[]

è¿™æ˜¯æ··åˆç›®æ ‡æ•°ç»„é…ç½®ã€‚å¦‚æœä½ æƒ³çˆ¬å–å¤šä¸ªæ•°æ®ï¼Œå¹¶ä¸”æœ‰äº›æ•°æ®éœ€è¦å¤±è´¥é‡è¯•ä¹‹ç±»çš„ï¼Œå¯ä»¥è¯•è¯•è¿™ç§å†™æ³•ï¼š

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl()

myXCrawl
  .crawlData([
    'https://www.example.com/api-1',
    { url: 'https://www.example.com/api-2', maxRetry: 2 }
  ])
  .then((res) => {})
```

æ‹¿åˆ°çš„ res å°†æ˜¯ä¸€ä¸ªæ•°ç»„ï¼Œé‡Œé¢æ˜¯å¯¹è±¡ã€‚

æ›´å¤šé…ç½®é€‰é¡¹å¯ä»¥æŸ¥çœ‹ [CrawlDataDetailTargetConfig](#CrawlDataDetailTargetConfig) ã€‚

##### è¿›é˜¶é…ç½® - CrawlDataAdvancedConfig

è¿™æ˜¯è¿›é˜¶é…ç½®ï¼Œtargets æ˜¯æ··åˆç›®æ ‡æ•°ç»„é…ç½®ã€‚å¦‚æœä½ æƒ³çˆ¬å–å¤šä¸ªæ•°æ®ï¼Œå¹¶ä¸”çˆ¬å–ç›®æ ‡é…ç½®ï¼ˆproxyã€cookiesã€é‡è¯•ç­‰ç­‰ï¼‰ä¸æƒ³é‡å¤å†™ï¼Œè¿˜éœ€è¦é—´éš”æ—¶é—´ã€è®¾å¤‡æŒ‡çº¹ä»¥åŠç”Ÿå‘½å‘¨æœŸç­‰ç­‰ï¼Œå¯ä»¥è¯•è¯•è¿™ç§å†™æ³•ï¼š

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl()

myXCrawl
  .crawlData({
    targets: [
      'https://www.example.com/api-1',
      { url: 'https://www.example.com/api-2', maxRetry: 6 }
    ],
    intervalTime: { max: 3000, min: 1000 },
    cookies: 'xxx',
    maxRetry: 1
  })
  .then((res) => {})
```

æ‹¿åˆ°çš„ res å°†æ˜¯ä¸€ä¸ªæ•°ç»„ï¼Œé‡Œé¢æ˜¯å¯¹è±¡ã€‚

æ›´å¤šé…ç½®é€‰é¡¹å¯ä»¥æŸ¥çœ‹ [CrawlPageAdvancedConfig](#CrawlPageAdvancedConfig) ã€‚

å…³äºç»“æœçš„æ›´å¤šä¿¡æ¯å¯æŸ¥çœ‹ [å…³äºç»“æœ](#å…³äºç»“æœ) ï¼Œå¯ä»¥æ ¹æ®å®é™…æƒ…å†µé€‰ç”¨å³å¯ã€‚

### crawlFile

crawlFile æ˜¯çˆ¬è™«å®ä¾‹çš„æ–¹æ³•ï¼Œé€šå¸¸ç”¨äºçˆ¬å–æ–‡ä»¶ï¼Œå¯è·å–å›¾ç‰‡ã€pdf æ–‡ä»¶ç­‰ç­‰ã€‚

#### ç±»å‹

crawlFile API æ˜¯ä¸€ä¸ªå‡½æ•°ã€‚ç±»å‹æ˜¯ [é‡è½½å‡½æ•°](https://www.typescriptlang.org/docs/handbook/2/functions.html#function-overloads) å¯ä»¥é€šè¿‡ä¸åŒçš„é…ç½®å‚æ•°è°ƒç”¨è¯¥å‡½æ•°ï¼ˆåœ¨ç±»å‹æ–¹é¢ï¼‰ã€‚

```ts
type crawlFile = {
  (
    config: CrawlFileDetailTargetConfig,
    callback?: (res: CrawlFileSingleResult) => void
  ): Promise<CrawlFileSingleResult>

  (
    config: CrawlFileDetailTargetConfig[],
    callback?: (res: CrawlFileSingleResult[]) => void
  ): Promise<CrawlFileSingleResult[]>

  (
    config: CrawlFileAdvancedConfig,
    callback?: (res: CrawlFileSingleResult[]) => void
  ): Promise<CrawlFileSingleResult[]>
}
```

**å‚æ•°ç±»å‹ï¼š**

- æŸ¥çœ‹ [CrawlFileDetailTargetConfig](#CrawlFileDetailTargetConfig) ç±»å‹
- æŸ¥çœ‹ [CrawlFileAdvancedConfig](#CrawlFileAdvancedConfig) ç±»å‹

**è¿”å›å€¼ç±»å‹ï¼š**

- æŸ¥çœ‹ [CrawlFileSingleResult](#CrawlFileSingleResult) ç±»å‹

#### ç¤ºä¾‹

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl({
  timeout: 10000,
  intervalTime: { max: 2000, min: 1000 }
})

// crawlFile API
myXCrawl
  .crawlFile({
    targets: [
      'https://www.example.com/file-1',
      'https://www.example.com/file-2'
    ],
    storeDirs: './upload',
    intervalTime: { max: 3000, min: 1000 },
    maxRetry: 1
  })
  .then((res) => {})
```

#### é…ç½®

ä¸€å…±æœ‰ 3 ç§:

- è¯¦ç»†ç›®æ ‡é…ç½® - CrawlFileDetailTargetConfig
- è¯¦ç»†ç›®æ ‡æ•°ç»„é…ç½® - CrawlFileDetailTargetConfig[]
- è¿›é˜¶é…ç½® - CrawlFileAdvancedConfig

##### è¯¦ç»†ç›®æ ‡é…ç½® - CrawlFileDetailTargetConfig

è¿™æ˜¯è¯¦ç»†ç›®æ ‡é…ç½®ã€‚å¦‚æœä½ æƒ³çˆ¬ä¸€ä¸‹è¿™ä¸ªæ–‡ä»¶ï¼Œå¹¶ä¸”éœ€è¦å¤±è´¥é‡è¯•ä¹‹ç±»çš„ï¼Œå¯ä»¥è¯•è¯•è¿™ç§å†™æ³•ï¼š

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl()

myXCrawl
  .crawlFile({
    url: 'https://www.example.com/file',
    proxy: 'xxx',
    maxRetry: 1,
    storeDir: './upload',
    fileName: 'xxx'
  })
  .then((res) => {})
```

æ‹¿åˆ°çš„ res å°†æ˜¯ä¸€ä¸ªå¯¹è±¡ã€‚

æ›´å¤šé…ç½®é€‰é¡¹å¯ä»¥æŸ¥çœ‹ [CrawlFileDetailTargetConfig](#CrawlFileDetailTargetConfig) ã€‚

##### è¯¦ç»†ç›®æ ‡æ•°ç»„é…ç½® - CrawlFileDetailTargetConfig[]

è¿™æ˜¯è¯¦ç»†ç›®æ ‡æ•°ç»„é…ç½®ã€‚å¦‚æœä½ æƒ³çˆ¬å–å¤šä¸ªæ–‡ä»¶ï¼Œå¹¶ä¸”æœ‰äº›æ•°æ®éœ€è¦å¤±è´¥é‡è¯•ä¹‹ç±»çš„ï¼Œå¯ä»¥è¯•è¯•è¿™ç§å†™æ³•ï¼š

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl()

myXCrawl
  .crawlFile([
    { url: 'https://www.example.com/file-1', storeDir: './upload' },
    { url: 'https://www.example.com/file-2', storeDir: './upload', maxRetry: 2 }
  ])
  .then((res) => {})
```

æ‹¿åˆ°çš„ res å°†æ˜¯ä¸€ä¸ªæ•°ç»„ï¼Œé‡Œé¢æ˜¯å¯¹è±¡ã€‚

æ›´å¤šé…ç½®é€‰é¡¹å¯ä»¥æŸ¥çœ‹ [CrawlFileDetailTargetConfig](#CrawlFileDetailTargetConfig) ã€‚

##### è¿›é˜¶é…ç½® - CrawlFileAdvancedConfig

è¿™æ˜¯è¿›é˜¶é…ç½®ï¼Œtargets æ˜¯æ··åˆç›®æ ‡æ•°ç»„é…ç½®ã€‚å¦‚æœä½ æƒ³çˆ¬å–å¤šä¸ªæ•°æ®ï¼Œå¹¶ä¸”çˆ¬å–ç›®æ ‡é…ç½®ï¼ˆproxyã€storeDirã€é‡è¯•ç­‰ç­‰ï¼‰ä¸æƒ³é‡å¤å†™ï¼Œè¿˜éœ€è¦é—´éš”æ—¶é—´ã€è®¾å¤‡æŒ‡çº¹ä»¥åŠç”Ÿå‘½å‘¨æœŸç­‰ç­‰ï¼Œå¯ä»¥è¯•è¯•è¿™ç§å†™æ³•ï¼š

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl()

myXCrawl
  .crawlFile({
    targets: [
      'https://www.example.com/file-1',
      { url: 'https://www.example.com/file-2', storeDir: './upload/file2' }
    ],
    storeDirs: './upload',
    intervalTime: { max: 3000, min: 1000 },
    maxRetry: 1
  })
  .then((res) => {})
```

æ‹¿åˆ°çš„ res å°†æ˜¯ä¸€ä¸ªæ•°ç»„ï¼Œé‡Œé¢æ˜¯å¯¹è±¡ã€‚

æ›´å¤šé…ç½®é€‰é¡¹å¯ä»¥æŸ¥çœ‹ [CrawlFileAdvancedConfig](#CrawlFileAdvancedConfig) ã€‚

å…³äºç»“æœçš„æ›´å¤šä¿¡æ¯å¯æŸ¥çœ‹ [å…³äºç»“æœ](#å…³äºç»“æœ) ï¼Œå¯ä»¥æ ¹æ®å®é™…æƒ…å†µé€‰ç”¨å³å¯ã€‚

### startPolling

crawlPolling æ˜¯çˆ¬è™«å®ä¾‹çš„æ–¹æ³•ï¼Œé€šå¸¸ç”¨äºè¿›è¡Œè½®è¯¢æ“ä½œï¼Œæ¯”å¦‚æ¯éš”ä¸€æ®µæ—¶é—´è·å–æ–°é—»ä¹‹ç±»çš„ã€‚

#### ç±»å‹

- æŸ¥çœ‹ [StartPollingConfig](#StartPollingConfig) ç±»å‹

```ts
function startPolling: (
  config: StartPollingConfig,
  callback: (count: number, stopPolling: () => void) => void
) => void
```

#### ç¤ºä¾‹

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl({
  timeout: 10000,
  intervalTime: { max: 2000, min: 1000 }
})

// startPolling API
myXCrawl.startPolling({ h: 2, m: 30 }, (count, stopPolling) => {
  // æ¯éš”ä¸¤ä¸ªåŠå°æ—¶ä¼šæ‰§è¡Œä¸€æ¬¡
  // crawlPage/crawlData/crawlFile
})
```

## ç±»å‹

### API Config

#### XCrawlConfig

```ts
export interface XCrawlConfig extends CrawlCommonConfig {
  mode?: 'async' | 'sync'
  enableRandomFingerprint?: boolean
  baseUrl?: string
  intervalTime?: IntervalTime
  crawlPage?: {
    puppeteerLaunch?: PuppeteerLaunchOptions // puppeteer
  }
}
```

**é»˜è®¤å€¼**

- mode: 'async'
- enableRandomFingerprint: true
- baseUrl: undefined
- intervalTime: undefined
- crawlPage: undefined

#### Detail Target Config

##### CrawlPageDetailTargetConfig

```ts
export interface CrawlPageDetailTargetConfig extends CrawlCommonConfig {
  url: string
  headers?: AnyObject | null
  cookies?: PageCookies | null
  priority?: number
  viewport?: Viewport | null // puppeteer
  fingerprint?:
    | (DetailTargetFingerprintCommon & {
        maxWidth?: number
        minWidth?: number
        maxHeight?: number
        minHidth?: number
      })
    | null
}
```

**é»˜è®¤å€¼**

- url: undefined
- headers: undefined
- cookies: undefined
- priority: undefined
- viewport: undefined
- fingerprint: undefined

##### CrawlDataDetailTargetConfig

```ts
export interface CrawlDataDetailTargetConfig extends CrawlCommonConfig {
  url: string
  method?: Method
  headers?: AnyObject | null
  params?: AnyObject
  data?: any
  priority?: number
  fingerprint?: DetailTargetFingerprintCommon | null
}
```

**é»˜è®¤å€¼**

- url: undefined
- method: 'GET'
- headers: undefined
- params: undefined
- data: undefined
- priority: undefined
- fingerprint: undefined

##### CrawlFileDetailTargetConfig

```ts
export interface CrawlFileDetailTargetConfig extends CrawlCommonConfig {
  url: string
  headers?: AnyObject | null
  priority?: number
  storeDir?: string | null
  fileName?: string | null
  extension?: string | null
  fingerprint?: DetailTargetFingerprintCommon | null
}
```

**é»˜è®¤å€¼**

- url: undefined
- headers: undefined
- priority: undefined
- storeDir: \_\_dirname
- fileName: string
- extension: string
- fingerprint: undefined

#### Advanced Config

##### CrawlPageAdvancedConfig

```ts
export interface CrawlPageAdvancedConfig extends CrawlCommonConfig {
  targets: (string | CrawlPageDetailTargetConfig)[]
  intervalTime?: IntervalTime
  fingerprints?: (DetailTargetFingerprintCommon & {
    maxWidth?: number
    minWidth?: number
    maxHeight?: number
    minHidth?: number
  })[]

  headers?: AnyObject
  cookies?: PageCookies
  viewport?: Viewport

  onCrawlItemComplete?: (crawlPageSingleResult: CrawlPageSingleResult) => void
}
```

**é»˜è®¤å€¼**

- targets: undefined
- intervalTime: undefined
- fingerprints: undefined
- headers: undefined
- cookies: undefined
- viewport: undefined
- onCrawlItemComplete: undefined

##### CrawlDataAdvancedConfig

```ts
export interface CrawlDataAdvancedConfig<T> extends CrawlCommonConfig {
  targets: (string | CrawlDataDetailTargetConfig)[]
  intervalTime?: IntervalTime
  fingerprints?: DetailTargetFingerprintCommon[]

  headers?: AnyObject

  onCrawlItemComplete?: (
    crawlDataSingleResult: CrawlDataSingleResult<T>
  ) => void
}
```

**é»˜è®¤å€¼**

- targets: undefined
- intervalTime: undefined
- fingerprints: undefined
- headers: undefined
- onCrawlItemComplete: undefined

##### CrawlFileAdvancedConfig

```ts
export interface CrawlFileAdvancedConfig extends CrawlCommonConfig {
  targets: (string | CrawlFileDetailTargetConfig)[]
  intervalTime?: IntervalTime
  fingerprints?: DetailTargetFingerprintCommon[]
  storeDirs?: string | (string | null)[]
  extensions?: string | (string | null)[]
  fileNames?: (string | null)[]

  headers?: AnyObject

  onCrawlItemComplete?: (crawlFileSingleResult: CrawlFileSingleResult) => void
  onBeforeSaveItemFile?: (info: {
    id: number
    fileName: string
    filePath: string
    data: Buffer
  }) => Promise<Buffer>
}
```

**é»˜è®¤å€¼**

- targets: undefined
- intervalTime: undefined
- fingerprints: undefined
- storeDirs: \_\_dirname
- extensions: string
- fileNames: undefined
- headers: undefined
- onCrawlItemComplete: undefined
- onBeforeSaveItemFile: undefined

#### StartPollingConfig

```ts
export interface StartPollingConfig {
  d?: number
  h?: number
  m?: number
}
```

**é»˜è®¤å€¼**

- d: undefined
- h: undefined
- m: undefined

#### Crawl Other Config

##### CrawlCommonConfig

```ts
export interface CrawlCommonConfig {
  timeout?: number | null
  proxy?: {
    urls: string[]
    switchByHttpStatus?: number[]
    switchByErrorCount?: number
  } | null
  maxRetry?: number | null
}
```

**é»˜è®¤å€¼**

- timeout: 10000
- proxy: undefined
- maxRetry: 0

##### DetailTargetFingerprintCommon

```ts
export interface DetailTargetFingerprintCommon {
  ua?: string
  mobile?: '?0' | '?1' | 'random'
  platform?: Platform
  platformVersion?: string
  acceptLanguage?: string
  userAgent?: {
    value: string
    versions?: {
      name: string
      maxMajorVersion?: number
      minMajorVersion?: number
      maxMinorVersion?: number
      minMinorVersion?: number
      maxPatchVersion?: number
      minPatchVersion?: number
    }[]
  }
}
```

**é»˜è®¤å€¼**

- ua: undefined
- mobile: undefined
- platform: undefined
- platformVersion: undefined
- acceptLanguage: undefined
- userAgent: undefined

##### Mobile

```ts
export type Mobile = '?0' | '?1'
```

##### Platform

```ts
export type Platform =
  | 'Android'
  | 'Chrome OS'
  | 'Chromium OS'
  | 'iOS'
  | 'Linux'
  | 'macOS'
  | 'Windows'
  | 'Unknown'
```

##### PageCookies

```ts
export type PageCookies =
  | string
  | Protocol.Network.CookieParam // puppeteer
  | Protocol.Network.CookieParam[] // puppeteer
```

##### Method

```ts
export type Method =
  | 'get'
  | 'GET'
  | 'delete'
  | 'DELETE'
  | 'head'
  | 'HEAD'
  | 'options'
  | 'OPTIONS'
  | 'post'
  | 'POST'
  | 'put'
  | 'PUT'
  | 'patch'
  | 'PATCH'
  | 'purge'
  | 'PURGE'
  | 'link'
  | 'LINK'
  | 'unlink'
  | 'UNLINK'
```

##### IntervalTime

```ts
export type IntervalTime = number | { max: number; min?: number }
```

### API Result

#### XCrawlInstance

```ts
export interface XCrawlInstance {
  crawlPage: {
    (
      config: string,
      callback?: (res: CrawlPageSingleResult) => void
    ): Promise<CrawlPageSingleResult>

    (
      config: CrawlPageDetailTargetConfig,
      callback?: (res: CrawlPageSingleResult) => void
    ): Promise<CrawlPageSingleResult>

    (
      config: (string | CrawlPageDetailTargetConfig)[],
      callback?: (res: CrawlPageSingleResult[]) => void
    ): Promise<CrawlPageSingleResult[]>

    (
      config: CrawlPageAdvancedConfig,
      callback?: (res: CrawlPageSingleResult[]) => void
    ): Promise<CrawlPageSingleResult[]>
  }

  crawlData: {
    <T = any>(
      config: CrawlDataDetailTargetConfig,
      callback?: (res: CrawlDataSingleResult<T>) => void
    ): Promise<CrawlDataSingleResult<T>>

    <T = any>(
      config: string,
      callback?: (res: CrawlDataSingleResult<T>) => void
    ): Promise<CrawlDataSingleResult<T>>

    <T = any>(
      config: (string | CrawlDataDetailTargetConfig)[],
      callback?: (res: CrawlDataSingleResult<T>[]) => void
    ): Promise<CrawlDataSingleResult<T>[]>

    <T = any>(
      config: CrawlDataAdvancedConfig<T>,
      callback?: (res: CrawlDataSingleResult<T>[]) => void
    ): Promise<CrawlDataSingleResult<T>[]>
  }

  crawlFile: {
    (
      config: CrawlFileDetailTargetConfig,
      callback?: (res: CrawlFileSingleResult) => void
    ): Promise<CrawlFileSingleResult>

    (
      config: CrawlFileDetailTargetConfig[],
      callback?: (res: CrawlFileSingleResult[]) => void
    ): Promise<CrawlFileSingleResult[]>

    (
      config: CrawlFileAdvancedConfig,
      callback?: (res: CrawlFileSingleResult[]) => void
    ): Promise<CrawlFileSingleResult[]>
  }

  startPolling: (
    config: StartPollingConfig,
    callback: (count: number, stopPolling: () => void) => void
  ) => void
}
```

#### CrawlCommonResult

```ts
export interface CrawlCommonResult {
  id: number
  isSuccess: boolean
  maxRetry: number
  retryCount: number
  proxyDetails: ProxyDetails
  crawlErrorQueue: Error[]
}
```

- idï¼šæ ¹æ®çˆ¬å–ç›®æ ‡çš„é¡ºåºç”Ÿæˆçš„ï¼Œå¦‚æœæœ‰ä¼˜å…ˆçº§ï¼Œåˆ™ä¼šæ ¹æ®ä¼˜å…ˆçº§ç”Ÿæˆ
- isSuccessï¼šæ˜¯å¦æˆåŠŸçˆ¬å–
- maxRetryï¼šè¯¥æ¬¡çˆ¬å–ç›®æ ‡çš„æœ€å¤§é‡è¯•æ¬¡æ•°
- retryCountï¼šè¯¥æ¬¡çˆ¬å–ç›®æ ‡å·²ç»é‡è¯•çš„æ¬¡æ•°
- proxyDetailsï¼šè®°å½•ä»£ç†æƒ…å†µ
- crawlErrorQueueï¼šè¯¥æ¬¡çˆ¬å–ç›®æ ‡çš„æŠ¥é”™æ”¶é›†

#### CrawlPageSingleResult

```ts
export interface CrawlPageSingleResult extends CrawlCommonResult {
  data: {
    browser: Browser // puppeteer
    response: HTTPResponse | null // puppeteer
    page: Page // puppeteer
  }
}
```

#### CrawlDataSingleResult

```ts
export interface CrawlDataSingleResult<D> extends CrawlCommonResult {
  data: {
    statusCode: number | undefined
    headers: IncomingHttpHeaders // nodejs http
    data: D
  } | null
}
```

#### CrawlFileSingleResult

```ts
export interface CrawlFileSingleResult extends CrawlCommonResult {
  data: {
    statusCode: number | undefined
    headers: IncomingHttpHeaders // nodejs http
    data: {
      isSuccess: boolean
      fileName: string
      fileExtension: string
      mimeType: string
      size: number
      filePath: string
    }
  } | null
}
```

### API Other

#### AnyObject

```ts
export interface AnyObject extends Object {
  [key: string | number | symbol]: any
}
```

## å¸¸è§é—®é¢˜

### crawlPage API è·Ÿ puppeteer çš„å…³ç³»

crawlPage API å†…ç½®äº† [puppeteer](https://github.com/puppeteer/puppeteer) ï¼Œæ‚¨åªéœ€è¦ä¼ å…¥ä¸€äº›é…ç½®é€‰é¡¹å³å¯è®© x-crawl å¸®åŠ©æ‚¨ç®€åŒ–æ“ä½œï¼Œå¹¶æ‹¿åˆ°å®Œå¥½çš„ Brower å®ä¾‹å’Œ Page å®ä¾‹ï¼Œx-crawl å¹¶ä¸ä¼šå¯¹å…¶é‡å†™ã€‚

## æ›´å¤š

### ç¤¾åŒº

- **Discord èŠå¤©:** é€šè¿‡ [Discord](https://discord.gg/SF7aaebg4E) ä¸å…¶ä»– x-crawl ç”¨æˆ·å®æ—¶æé—®å’Œè®¨è®ºã€‚

- **GitHub è®¨è®º:** ä½¿ç”¨ [GitHub è®¨è®º](https://github.com/coder-hxl/x-crawl/discussions) æ¥è¿›è¡Œç•™è¨€æ¿å¼çš„é—®é¢˜å’Œè®¨è®ºã€‚

### Issues

å¦‚æœæ‚¨æœ‰ **é—®é¢˜ ã€éœ€æ±‚ã€å¥½çš„å»ºè®®** å¯ä»¥åœ¨ [GitHub Issues](https://github.com/coder-hxl/x-crawl/issues) ä¸­æ **Issues** ã€‚

### èµåŠ©

x-crawl æ˜¯é‡‡ç”¨ MIT è®¸å¯çš„å¼€æºé¡¹ç›®ï¼Œä½¿ç”¨å®Œå…¨å…è´¹ã€‚å¦‚æœä½ åœ¨å·¥ä½œä¸­å—ç›Šäºæˆ‘å¼€å‘ç»´æŠ¤çš„é¡¹ç›®ï¼Œè¯·è€ƒè™‘é€šè¿‡ [çˆ±å‘ç”µ](https://afdian.net/a/coderhxl) å¹³å°æ¥æ”¯æŒä¸€ä¸‹æˆ‘çš„å·¥ä½œã€‚
