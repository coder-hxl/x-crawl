# x-crawl [![npm](https://img.shields.io/npm/v/x-crawl.svg)](https://www.npmjs.com/package/x-crawl) [![GitHub license](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/coder-hxl/x-crawl/blob/main/LICENSE)

[English](https://github.com/coder-hxl/x-crawl#x-crawl) | ç®€ä½“ä¸­æ–‡

x-crawl æ˜¯ä¸€ä¸ªçµæ´»çš„ Node.js å¤šåŠŸèƒ½çˆ¬è™«åº“ã€‚ç”¨äºçˆ¬é¡µé¢ã€çˆ¬æ¥å£ã€çˆ¬æ–‡ä»¶ä»¥åŠè½®è¯¢çˆ¬ã€‚

> å¦‚æœä½ ä¹Ÿå–œæ¬¢ x-crawl ï¼Œå¯ä»¥ç»™ [x-crawl å­˜å‚¨åº“](https://github.com/coder-hxl/x-crawl) ç‚¹ä¸ª star æ”¯æŒä¸€ä¸‹ï¼Œæ„Ÿè°¢å¤§å®¶çš„æ”¯æŒï¼

## ç‰¹å¾

- **ğŸ”¥ å¼‚æ­¥/åŒæ­¥** - åªéœ€æ›´æ”¹ä¸€ä¸‹ mode å±æ€§å³å¯åˆ‡æ¢ å¼‚æ­¥/åŒæ­¥ çˆ¬å–æ¨¡å¼ã€‚
- **âš™ï¸ å¤šç§åŠŸèƒ½** - å¯çˆ¬é¡µé¢ã€çˆ¬æ¥å£ã€çˆ¬æ–‡ä»¶ä»¥åŠè½®è¯¢çˆ¬ã€‚å¹¶ä¸”æ”¯æŒçˆ¬å–å•ä¸ªæˆ–å¤šä¸ªã€‚
- **ğŸ–‹ï¸ å†™æ³•çµæ´»** - ä¸€ç§åŠŸèƒ½é€‚é…å¤šç§çˆ¬å–é…ç½®ã€è·å–çˆ¬å–ç»“æœçš„å†™æ³•ï¼Œå†™æ³•éå¸¸çµæ´»ã€‚
- **ğŸ‘€ è®¾å¤‡æŒ‡çº¹** - é›¶é…ç½®/è‡ªå®šä¹‰é…ç½®ï¼Œå³å¯é¿å…é€šè¿‡æŒ‡çº¹è¯†åˆ«ä»ä¸åŒä½ç½®è¯†åˆ«å¹¶è·Ÿè¸ªæˆ‘ä»¬ã€‚
- **â±ï¸ é—´éš”çˆ¬å–** - æ— é—´éš”/å›ºå®šé—´éš”/éšæœºé—´éš”ï¼Œå¯ä»¥æœ‰æ•ˆ ä½¿ç”¨/é¿å… é«˜å¹¶å‘çˆ¬å–ã€‚
- **ğŸ”„ å¤±è´¥é‡è¯•** - å¯é’ˆå¯¹æ‰€æœ‰çˆ¬å–çš„è¯·æ±‚è®¾ç½®ï¼Œé’ˆå¯¹å•æ¬¡çˆ¬å–çš„è¯·æ±‚è®¾ç½®ï¼Œé’ˆå¯¹å•ä¸ªè¯·æ±‚è®¾ç½®è¿›è¡Œå¤±è´¥é‡è¯•ã€‚
- **ğŸš€ ä¼˜å…ˆé˜Ÿåˆ—** - æ ¹æ®å•ä¸ªè¯·æ±‚çš„ä¼˜å…ˆçº§ä½¿ç”¨ä¼˜å…ˆçˆ¬å–ã€‚
- **â˜ï¸ çˆ¬å– SPA** - æ‰¹é‡çˆ¬å– SPAï¼ˆå•é¡µåº”ç”¨ç¨‹åºï¼‰ç”Ÿæˆé¢„æ¸²æŸ“å†…å®¹ï¼ˆå³â€œSSRâ€ï¼ˆæœåŠ¡å™¨ç«¯æ¸²æŸ“ï¼‰ï¼‰ã€‚
- **âš’ï¸ æ§åˆ¶é¡µé¢** - æ— å¤´æµè§ˆå™¨å¯ä»¥è¡¨å•æäº¤ã€é”®ç›˜è¾“å…¥ã€äº‹ä»¶æ“ä½œã€ç”Ÿæˆé¡µé¢çš„å±å¹•æˆªå›¾ç­‰ã€‚
- **ğŸ§¾ æ•è·è®°å½•** - å¯¹çˆ¬å–çš„ç»“æœè¿›è¡Œæ•è·è®°å½•ï¼Œå¹¶åœ¨æ§åˆ¶å°è¿›è¡Œé«˜äº®çš„æé†’ã€‚
- **ğŸ¦¾ TypeScript** - æ‹¥æœ‰ç±»å‹ï¼Œé€šè¿‡æ³›å‹å®ç°å®Œæ•´çš„ç±»å‹ã€‚

## è·Ÿ puppeteer çš„å…³ç³»

crawlPage API å†…ç½®äº† [puppeteer](https://github.com/puppeteer/puppeteer) ï¼Œæ‚¨åªéœ€è¦ä¼ å…¥ä¸€äº›é…ç½®é€‰é¡¹å³å¯å®Œæˆä¸€äº›æ“ä½œï¼Œç»“æœä¼šå°† Brower å®ä¾‹å’Œ Page å®ä¾‹æš´éœ²å‡ºæ¥ã€‚

# ç›®å½•

- [å®‰è£…](#å®‰è£…)
- [ç¤ºä¾‹](#ç¤ºä¾‹)
- [æ ¸å¿ƒæ¦‚å¿µ](#æ ¸å¿ƒæ¦‚å¿µ)
  - [åˆ›å»ºåº”ç”¨](#åˆ›å»ºåº”ç”¨)
    - [ä¸€ä¸ªçˆ¬è™«åº”ç”¨å®ä¾‹](#ä¸€ä¸ªçˆ¬è™«åº”ç”¨å®ä¾‹)
    - [çˆ¬å–æ¨¡å¼](#çˆ¬å–æ¨¡å¼)
    - [è®¾å¤‡æŒ‡çº¹](#è®¾å¤‡æŒ‡çº¹)
    - [å¤šä¸ªçˆ¬è™«åº”ç”¨å®ä¾‹](#å¤šä¸ªçˆ¬è™«åº”ç”¨å®ä¾‹)
  - [çˆ¬å–é¡µé¢](#çˆ¬å–é¡µé¢)
    - [browser å®ä¾‹](#browser-å®ä¾‹)
    - [page å®ä¾‹](#page-å®ä¾‹)
    - [ç”Ÿå‘½å‘¨æœŸ](#ç”Ÿå‘½å‘¨æœŸ)
      - [onCrawlItemComplete](#onCrawlItemComplete)
  - [çˆ¬å–æ¥å£](#çˆ¬å–æ¥å£)
    - [ç”Ÿå‘½å‘¨æœŸ](#ç”Ÿå‘½å‘¨æœŸ-1)
      - [onCrawlItemComplete](#onCrawlItemComplete-1)
  - [çˆ¬å–æ–‡ä»¶](#çˆ¬å–æ–‡ä»¶)
    - [ç”Ÿå‘½å‘¨æœŸ](#ç”Ÿå‘½å‘¨æœŸ-2)
      - [onCrawlItemComplete](#onCrawlItemComplete-2)
      - [onBeforeSaveItemFile](#onBeforeSaveItemFile)
  - [å¯åŠ¨è½®è¯¢](#å¯åŠ¨è½®è¯¢)
  - [é…ç½®ä¼˜å…ˆçº§](#é…ç½®ä¼˜å…ˆçº§)
  - [è®¾å¤‡æŒ‡çº¹](#è®¾å¤‡æŒ‡çº¹-1)
  - [é—´éš”æ—¶é—´](#é—´éš”æ—¶é—´)
  - [å¤±è´¥é‡è¯•](#å¤±è´¥é‡è¯•)
  - [ä¼˜å…ˆé˜Ÿåˆ—](#ä¼˜å…ˆé˜Ÿåˆ—)
  - [å…³äºç»“æœ](#å…³äºç»“æœ)
  - [TypeScript](#TypeScript)
- [API](#API)
  - [xCrawl](#xCrawl)
    - [ç±»å‹](#ç±»å‹)
    - [ç¤ºä¾‹](#ç¤ºä¾‹-1)
  - [crawlPage](#crawlPage)
    - [ç±»å‹](#ç±»å‹-1)
    - [ç¤ºä¾‹](#ç¤ºä¾‹-2)
    - [é…ç½®](#é…ç½®)
  - [crawlData](#crawlData)
    - [ç±»å‹](#ç±»å‹-2)
    - [ç¤ºä¾‹](#ç¤ºä¾‹-3)
    - [é…ç½®](#é…ç½®-1)
  - [crawlFile](#crawlFile)
    - [ç±»å‹](#ç±»å‹-3)
    - [ç¤ºä¾‹](#ç¤ºä¾‹-4)
    - [é…ç½®](#é…ç½®-2)
  - [startPolling](#startPolling)
    - [ç±»å‹](#ç±»å‹-4)
    - [ç¤ºä¾‹](#ç¤ºä¾‹-5)
    - [ç±»å‹](#ç±»å‹-5)
- [ç±»å‹](#ç±»å‹-6)
  - [API Config](#API-config)
    - [XCrawlConfig](#XCrawlConfig)
    - [Detail target config](#Detail-target-config)
      - [CrawlPageDetailTargetConfig](#CrawlPageDetailTargetConfig)
      - [CrawlDataDetailTargetConfig](#CrawlDataDetailTargetConfig)
      - [CrawlFileDetailTargetConfig](#CrawlFileDetailTargetConfig)
    - [Advanced config](#Advanced-config)
      - [CrawlPageAdvancedConfig](#CrawlPageAdvancedConfig)
      - [CrawlDataAdvancedConfig](#CrawlDataAdvancedConfig)
      - [CrawlFileAdvancedConfig](#CrawlFileAdvancedConfig)
    - [StartPollingConfig](#StartPollingConfig)
    - [Crawl other config](#Crawl-other-config)
      - [CrawlCommonConfig](#CrawlCommonConfig)
      - [DetailTargetFingerprintCommon](#DetailTargetFingerprintCommon)
      - [AdvancedFingerprintCommon](#AdvancedFingerprintCommon)
      - [Mobile](#Mobile)
      - [Platform](#Platform)
      - [PageCookies](#PageCookies)
      - [Method](#Method)
      - [IntervalTime](#IntervalTime)
  - [API Result](#API-Result)
    - [XCrawlInstance](#XCrawlInstance)
    - [CrawlCommonRes](#CrawlCommonRes)
    - [CrawlPageSingleRes](#CrawlPageSingleRes)
    - [CrawlDataSingleRes](#CrawlDataSingleRes)
    - [CrawlFileSingleRes](#CrawlFileSingleRes)
  - [API Other](#API-Other)
    - [AnyObject](#AnyObject)
- [æ›´å¤š](#æ›´å¤š)

## å®‰è£…

ä»¥ NPM ä¸ºä¾‹:

```shell
npm install x-crawl
```

## ç¤ºä¾‹

æ¯å¤©è‡ªåŠ¨è·å– bilibili é¦–é¡µã€å›½æ¼«ã€ç”µå½±è¿™ä¸‰ä¸ªé¡µé¢çš„è½®æ’­å›¾ç‰‡ä¸ºä¾‹:

```js
// 1.å¯¼å…¥æ¨¡å— ES/CJS
import xCrawl from 'x-crawl'

// 2.åˆ›å»ºä¸€ä¸ªçˆ¬è™«å®ä¾‹
const myXCrawl = xCrawl({ maxRetry: 3, intervalTime: { max: 3000, min: 2000 } })

// 3.è®¾ç½®çˆ¬å–ä»»åŠ¡
// è°ƒç”¨ startPolling API å¼€å§‹è½®è¯¢åŠŸèƒ½ï¼Œæ¯éš”ä¸€å¤©ä¼šè°ƒç”¨å›è°ƒå‡½æ•°
myXCrawl.startPolling({ d: 1 }, async (count, stopPolling) => {
  // è°ƒç”¨ crawlPage API çˆ¬å– é¦–é¡µã€å›½æ¼«ã€ç”µå½± è¿™ä¸‰ä¸ªé¡µé¢
  const res = await myXCrawl.crawlPage([
    'https://www.bilibili.com',
    'https://www.bilibili.com/guochuang',
    'https://www.bilibili.com/movie'
  ])

  // å­˜æ”¾å›¾ç‰‡ URL åˆ° targets
  const targets = []
  const elSelectorMap = ['.carousel-inner', '.chief-recom-item', '.bg-item']
  for (const item of res) {
    const { id } = item
    const { page } = item.data

    // è·å–é¡µé¢è½®æ’­å›¾ç‰‡å…ƒç´ çš„ URL
    const urls = await page.$$eval(`${elSelectorMap[id - 1]} img`, (imgEls) =>
      imgEls.map((item) => item.src)
    )
    targets.push(...urls)

    // å…³é—­é¡µé¢
    page.close()
  }

  // è°ƒç”¨ crawlFile API çˆ¬å–å›¾ç‰‡
  await myXCrawl.crawlFile({ targets, storeDir: './upload' })
})
```

è¿è¡Œæ•ˆæœ:

<div align="center">
  <img src="https://raw.githubusercontent.com/coder-hxl/x-crawl/main/assets/cn/crawler.png" />
</div>

<div align="center">
  <img src="https://raw.githubusercontent.com/coder-hxl/x-crawl/main/assets/cn/crawler-result.png" />
</div>

**æ³¨æ„:** è¯·å‹¿éšæ„çˆ¬å–ï¼Œçˆ¬å–å‰å¯æŸ¥çœ‹ **robots.txt** åè®®ã€‚è¿™é‡Œåªæ˜¯ä¸ºäº†æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ x-crawl ã€‚

## æ ¸å¿ƒæ¦‚å¿µ

### åˆ›å»ºåº”ç”¨

#### ä¸€ä¸ªçˆ¬è™«åº”ç”¨å®ä¾‹

é€šè¿‡ [xCrawl()](#xCrawl) åˆ›å»ºä¸€ä¸ªæ–°çš„ **åº”ç”¨å®ä¾‹:**

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl({
  // é€‰é¡¹
})
```

ç›¸å…³çš„ **é€‰é¡¹** å¯å‚è€ƒ [XCrawlBaseConfig](#XCrawlBaseConfig) ã€‚

#### çˆ¬å–æ¨¡å¼

ä¸€ä¸ªçˆ¬è™«åº”ç”¨å®ä¾‹æœ‰ä¸¤ç§çˆ¬å–æ¨¡å¼: å¼‚æ­¥/åŒæ­¥ï¼Œæ¯ä¸ªçˆ¬è™«å®ä¾‹åªèƒ½é€‰æ‹©å…¶ä¸­ä¸€ç§ã€‚

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl({
  mode: 'async'
})
```

mode é€‰é¡¹é»˜è®¤ä¸º async ã€‚

- async: å¼‚æ­¥è¯·æ±‚ï¼Œåœ¨æ‰¹é‡è¯·æ±‚æ—¶ï¼Œæ— éœ€ç­‰å½“å‰è¯·æ±‚å®Œæˆï¼Œå°±è¿›è¡Œä¸‹æ¬¡è¯·æ±‚
- sync: åŒæ­¥è¯·æ±‚ï¼Œåœ¨æ‰¹é‡è¯·æ±‚æ—¶ï¼Œéœ€è¦ç­‰è¿™æ¬¡è¯·æ±‚å®Œæˆï¼Œæ‰ä¼šè¿›è¡Œä¸‹æ¬¡è¯·æ±‚

è‹¥æœ‰è®¾ç½®é—´éš”æ—¶é—´ï¼Œåˆ™éƒ½éœ€è¦ç­‰é—´éš”æ—¶é—´ç»“æŸæ‰èƒ½å‘é€è¯·æ±‚ã€‚

#### è®¾å¤‡æŒ‡çº¹

å¯ä»¥é€šè¿‡ä¸€ä¸ªå±æ€§æ§åˆ¶æ˜¯å¦ä½¿ç”¨é»˜è®¤çš„éšæœºæŒ‡çº¹ï¼Œæ‚¨ä¹Ÿå¯ä»¥é€šè¿‡åç»­çš„çˆ¬å–é…ç½®è‡ªå®šä¹‰æŒ‡çº¹ã€‚

è®¾ç½®è®¾å¤‡æŒ‡çº¹æ˜¯ä¸ºäº†é¿å…é€šè¿‡æŒ‡çº¹è¯†åˆ«ä»ä¸åŒä½ç½®è¯†åˆ«å¹¶è·Ÿè¸ªæˆ‘ä»¬ã€‚

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl({
  enableRandomFingerprint: true
})
```

enableRandomFingerprint é€‰é¡¹é»˜è®¤ä¸º trueã€‚

- true: å¯åŠ¨éšæœºè®¾å¤‡æŒ‡çº¹ã€‚å¯é€šè¿‡è¿›é˜¶ç‰ˆé…ç½®æˆ–è¯¦ç»†ç›®æ ‡ç‰ˆé…ç½®æŒ‡å®šç›®æ ‡çš„æŒ‡çº¹é…ç½®ã€‚
- false: å…³é—­éšæœºè®¾å¤‡æŒ‡çº¹ï¼Œä¸å½±å“è¿›é˜¶ç‰ˆé…ç½®æˆ–è¯¦ç»†ç‰ˆé…ç½®ä¸ºç›®æ ‡æŒ‡å®šçš„æŒ‡çº¹é…ç½®ã€‚

#### å¤šä¸ªçˆ¬è™«åº”ç”¨å®ä¾‹

```js
import xCrawl from 'x-crawl'

const myXCrawl1 = xCrawl({
  // é€‰é¡¹
})

const myXCrawl2 = xCrawl({
  // é€‰é¡¹
})
```

### çˆ¬å–é¡µé¢

é€šè¿‡ [crawlPage()](#crawlPage) çˆ¬å–ä¸€ä¸ªé¡µé¢ã€‚

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl()

myXCrawl.crawlPage('https://www.example.com').then((res) => {
  const { browser, page } = res.data

  // å…³é—­æµè§ˆå™¨
  browser.close()
})
```

#### browser å®ä¾‹

å®ƒæ˜¯ [Browser](https://pptr.dev/api/puppeteer.browser) çš„å®ä¾‹å¯¹è±¡ï¼Œå…·ä½“ä½¿ç”¨å¯ä»¥å‚è€ƒ [Browser](https://pptr.dev/api/puppeteer.browser) ã€‚

browser å®ä¾‹ä»–æ˜¯ä¸ªæ— å¤´æµè§ˆå™¨ï¼Œå¹¶æ—  UI å¤–å£³ï¼Œä»–åšçš„æ˜¯å°†æµè§ˆå™¨æ¸²æŸ“å¼•æ“æä¾›çš„**æ‰€æœ‰ç°ä»£ç½‘ç»œå¹³å°åŠŸèƒ½**å¸¦åˆ°ä»£ç ä¸­ã€‚

**æ³¨æ„ï¼š** browser ä¼šä¸€ç›´ä¿æŒç€è¿è¡Œï¼Œé€ æˆæ–‡ä»¶ä¸ä¼šç»ˆæ­¢ï¼Œå¦‚æœæƒ³åœæ­¢å¯ä»¥æ‰§è¡Œ browser.close() å…³é—­ã€‚å¦‚æœåé¢è¿˜éœ€è¦ç”¨åˆ° [crawlPage](#crawlPage) æˆ–è€… [page](#page) è¯·å‹¿è°ƒç”¨ã€‚å› ä¸ºå½“æ‚¨ä¿®æ”¹ browser å®ä¾‹çš„å±æ€§æ—¶ï¼Œä¼šå¯¹è¯¥çˆ¬è™«å®ä¾‹ crawlPage API å†…éƒ¨çš„ browser å®ä¾‹å’Œè¿”å›ç»“æœçš„ page å®ä¾‹ä»¥åŠ browser å®ä¾‹é€ æˆå½±å“ï¼Œå› ä¸º browser å®ä¾‹åœ¨åŒä¸€ä¸ªçˆ¬è™«å®ä¾‹çš„ crawlPage API å†…æ˜¯å…±äº«çš„ã€‚

#### page å®ä¾‹

å®ƒæ˜¯ [Page](https://pptr.dev/api/puppeteer.page) çš„å®ä¾‹å¯¹è±¡ï¼Œå®ä¾‹è¿˜å¯ä»¥åšäº‹ä»¶ä¹‹ç±»çš„äº¤äº’æ“ä½œï¼Œå…·ä½“ä½¿ç”¨å¯ä»¥å‚è€ƒ [page](https://pptr.dev/api/puppeteer.page) ã€‚

browser å®ä¾‹å†…éƒ¨ä¼šä¿ç•™ç€å¯¹ page å®ä¾‹çš„å¼•ç”¨ï¼Œå¦‚æœåç»­ä¸å†ä½¿ç”¨éœ€è¦è‡ªè¡Œå…³é—­ page å®ä¾‹ï¼Œå¦åˆ™ä¼šé€ æˆå†…å­˜æ³„éœ²ã€‚

**è·å–å±å¹•æˆªå›¾**

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl()

myXCrawl.crawlPage('https://www.example.com').then(async (res) => {
  const { browser, page } = res.data

  // è·å–é¡µé¢æ¸²æŸ“åçš„æˆªå›¾
  await page.screenshot({ path: './upload/page.png' })

  console.log('è·å–å±å¹•æˆªå›¾å®Œæ¯•')

  browser.close()
})
```

#### ç”Ÿå‘½å‘¨æœŸ

crawlPageAPI æ‹¥æœ‰çš„å£°æ˜å‘¨æœŸå‡½æ•°:

- onCrawlItemComplete: å½“æ¯ä¸ªçˆ¬å–ç›®æ ‡ç»“æŸå¹¶å¤„ç†åæ‰§è¡Œ

##### onCrawlItemComplete

åœ¨ onCrawlItemComplete å‡½æ•°ä¸­ä½ å¯ä»¥æ‹¿åˆ°æ¯ä¸ªçˆ¬å–ç›®æ ‡çš„ç»“æœã€‚

**æ³¨æ„:** å¦‚æœä½ éœ€è¦ä¸€æ¬¡æ€§çˆ¬å–å¾ˆå¤šé¡µé¢ï¼Œå°±éœ€è¦åœ¨æ¯ä¸ªé¡µé¢çˆ¬ä¸‹æ¥åï¼Œç”¨è¿™ä¸ªç”Ÿå‘½å‘¨æœŸå‡½æ•°æ¥å¤„ç†æ¯ä¸ªç›®æ ‡çš„ç»“æœå¹¶å…³é—­ page å®ä¾‹ï¼Œå¦‚æœä¸è¿›è¡Œå…³é—­æ“ä½œï¼Œåˆ™ä¼šå› å¼€å¯çš„ page è¿‡å¤šè€Œé€ æˆç¨‹åºå´©æºƒã€‚

### çˆ¬å–æ¥å£

é€šè¿‡ [crawlData()](#crawlData) çˆ¬å–æ¥å£æ•°æ®ã€‚

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl({ intervalTime: { max: 3000, min: 1000 } })

const targets = [
  'https://www.example.com/api-1',
  'https://www.example.com/api-2',
  {
    url: 'https://www.example.com/api-3',
    method: 'POST',
    data: { name: 'coderhxl' }
  }
]

myXCrawl.crawlData({ targets }).then((res) => {
  // å¤„ç†
})
```

#### ç”Ÿå‘½å‘¨æœŸ

crawlData API æ‹¥æœ‰çš„å£°æ˜å‘¨æœŸå‡½æ•°:

- onCrawlItemComplete: å½“æ¯ä¸ªçˆ¬å–ç›®æ ‡ç»“æŸå¹¶å¤„ç†åæ‰§è¡Œ

##### onCrawlItemComplete

åœ¨ onCrawlItemComplete å‡½æ•°ä¸­ä½ å¯ä»¥æ‹¿åˆ°æ¯ä¸ªçˆ¬å–ç›®æ ‡çš„ç»“æœã€‚

### çˆ¬å–æ–‡ä»¶

é€šè¿‡ [crawlFile()](#crawlFile) çˆ¬å–æ–‡ä»¶æ•°æ®ã€‚

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl({ intervalTime: { max: 3000, min: 1000 } })

myXCrawl
  .crawlFile({
    targets: [
      'https://www.example.com/file-1',
      'https://www.example.com/file-2'
    ],
    storeDir: './upload' // å­˜æ”¾æ–‡ä»¶å¤¹
  })
  .then((res) => {})
```

#### ç”Ÿå‘½å‘¨æœŸ

crawlFile API æ‹¥æœ‰çš„å£°æ˜å‘¨æœŸå‡½æ•°:

- onCrawlItemComplete: å½“æ¯ä¸ªçˆ¬å–ç›®æ ‡ç»“æŸå¹¶å¤„ç†åæ‰§è¡Œ

- onBeforeSaveItemFile: åœ¨ä¿å­˜æ–‡ä»¶å‰æ‰§è¡Œ

##### onCrawlItemComplete

åœ¨ onCrawlItemComplete å‡½æ•°ä¸­ä½ å¯ä»¥æ‹¿åˆ°æ¯ä¸ªçˆ¬å–ç›®æ ‡çš„ç»“æœã€‚

##### onBeforeSaveItemFile

åœ¨ onBeforeSaveItemFile å‡½æ•°ä¸­ä½ å¯ä»¥æ‹¿åˆ° Buffer ç±»å‹çš„æ–‡ä»¶ï¼Œä½ å¯ä»¥å¯¹è¯¥ Buffer è¿›è¡Œå¤„ç†ï¼Œç„¶åéœ€è¦è¿”å›ä¸€ä¸ª Promise ï¼Œå¹¶ä¸” resolve æ˜¯ Buffer ã€‚

**è°ƒæ•´å›¾ç‰‡å¤§å°**

ä½¿ç”¨ sharp åº“å¯¹éœ€è¦çˆ¬å–çš„å›¾ç‰‡è¿›è¡Œè°ƒæ•´å¤§å°æ“ä½œ:

```js
import xCrawl from 'x-crawl'
import sharp from 'sharp'

const myXCrawl = xCrawl()

myXCrawl
  .crawlFile({
    targets: [
      'https://www.example.com/file-1.jpg',
      'https://www.example.com/file-2.jpg'
    ],
    onBeforeSaveItemFile(info) {
      return sharp(info.data).resize(200).toBuffer()
    }
  })
  .then((res) => {
    res.forEach((item) => {
      console.log(item.data?.data.isSuccess)
    })
  })
```

### å¯åŠ¨è½®è¯¢

é€šè¿‡ [startPolling()](#startPolling) å¯åŠ¨ä¸€ä¸ªè½®è¯¢çˆ¬å–ã€‚

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl({
  timeout: 10000
})

myXCrawl.startPolling({ h: 2, m: 30 }, async (count, stopPolling) => {
  // æ¯éš”ä¸¤ä¸ªåŠå°æ—¶ä¼šæ‰§è¡Œä¸€æ¬¡
  // crawlPage/crawlData/crawlFile
  const res = await myXCrawl.crawlPage('https://www.example.com')
  res.data.page.close()
})
```

**åœ¨è½®è¯¢ä¸­ä½¿ç”¨ crawlPage æ³¨æ„ï¼š** è°ƒç”¨ page.close() æ˜¯ä¸ºäº†é˜²æ­¢ browser å®ä¾‹å†…éƒ¨è¿˜ä¿ç•™ç€å¯¹ page å®ä¾‹çš„å¼•ç”¨ï¼Œå¦‚æœåç»­ä¸å†ä½¿ç”¨å½“å‰ page éœ€è¦è‡ªè¡Œå…³é—­ï¼Œå¦åˆ™ä¼šé€ æˆå†…å­˜æ³„éœ²ã€‚

å›è°ƒå‡½æ•°å‚æ•°ï¼š

- count å±æ€§è®°å½•å½“å‰æ˜¯ç¬¬å‡ æ¬¡è½®è¯¢æ“ä½œã€‚
- stopPolling æ˜¯ä¸€ä¸ªå›è°ƒå‡½æ•°ï¼Œè°ƒç”¨å…¶å¯ä»¥ç»ˆæ­¢åé¢çš„è½®è¯¢æ“ä½œã€‚

### é…ç½®ä¼˜å…ˆçº§

ä¸€äº›é€šç”¨çš„é…ç½®å¯ä»¥é€šè¿‡åœ¨è¿™ä¸‰ä¸ªåœ°æ–¹è®¾ç½®ï¼š

- åº”ç”¨å®ä¾‹é…ç½®ï¼ˆå…¨å±€ï¼‰
- è¿›é˜¶é…ç½®ï¼ˆå±€éƒ¨ï¼‰
- è¯¦ç»†ç›®æ ‡é…ç½®ï¼ˆå•ç‹¬ï¼‰

ä¼˜å…ˆçº§ä¸ºï¼šè¯¦ç»†ç›®æ ‡é…ç½® > è¿›é˜¶é…ç½® > åº”ç”¨å®ä¾‹é…ç½®

ä»¥ crawlPage çˆ¬å–ä¸¤ä¸ªé¡µé¢ä¸ºä¾‹ï¼š

```js
import xCrawl from 'x-crawl'

// åº”ç”¨å®ä¾‹é…ç½®
const myXCrawl = xCrawl({
  intervalTime: { max: 3000, min: 1000 }
})

// è¿›é˜¶é…ç½®
myXCrawl.crawlPage({
  targets: [
    'https://www.example.com/page-1',
    {
      // è¯¦ç»†ç›®æ ‡é…ç½®
      url: 'https://www.example.com/page-1',
      viewport: { width: 1920, height: 1080 }
    }
  ],
  intervalTime: 1000,
  viewport: { width: 800, height: 600 }
})
```

åœ¨ä¸Šé¢çš„å®ä¾‹ä¸­ï¼Œ**åº”ç”¨å®ä¾‹é…ç½®**å’Œ**è¿›é˜¶é…ç½®**ä¸­éƒ½è®¾ç½®äº†é—´éš”æ—¶é—´ï¼Œé‚£ä¹ˆå°†ä¼šä»¥**è¿›é˜¶é…ç½®**çš„é—´éš”æ—¶é—´ä¸ºå‡†ã€‚åœ¨**è¿›é˜¶é…ç½®**å’Œ**è¯¦ç»†ç›®æ ‡é…ç½®**ä¸­è®¾ç½®äº†è§†å£ï¼Œé‚£ä¹ˆç¬¬äºŒä¸ªç›®æ ‡æ˜¯è®¾ç½®äº†è§†å£ï¼Œå…¶å°†ä¼šä»¥**è¯¦ç»†ç›®æ ‡é…ç½®**çš„è§†å£ä¸ºå‡†ã€‚

### è®¾å¤‡æŒ‡çº¹

è‡ªå®šä¹‰é…ç½®ï¼Œå³å¯é¿å…é€šè¿‡æŒ‡çº¹è¯†åˆ«ä»ä¸åŒä½ç½®è¯†åˆ«å¹¶è·Ÿè¸ªæˆ‘ä»¬ã€‚

å¯ä»¥é€šè¿‡è¿›é˜¶ç”¨æ³•åœ¨ fingerprint ä¼ å…¥å¤šä¸ªä¿¡æ¯ï¼Œå†…éƒ¨ä¼šå¸®åŠ©æ‚¨éšæœºåˆ†é…ç»™ targets çš„æ¯ä¸ªç›®æ ‡ã€‚ä¹Ÿå¯ä»¥ç›´æ¥ç”¨è¯¦ç»†ç›®æ ‡é…ç½®ä¸ºç›®æ ‡è®¾ç½®ç‰¹å®šçš„æŒ‡çº¹ã€‚

ä»¥ crawlPage ä¸ºä¾‹ï¼š

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl({ intervalTime: { max: 5000, min: 3000 } })

myXCrawl
  .crawlPage({
    targets: [
      'https://www.example.com/page-1',
      {
        // æŒ‡å®šæŒ‡çº¹
        url: 'https://www.example.com/page-2',
        fingerprint: {
          maxWidth: 1980,
          minWidth: 1980,
          maxHeight: 1080,
          minHidth: 1080,
          platform: 'Android'
        }
      }
    ],
    fingerprint: {
      // ä¸º targets é‡Œçš„æ¯ä¸ªç›®æ ‡è®¾ç½®æŒ‡çº¹
      maxWidth: 1980,
      maxHeight: 1080,
      userAgents: [
        'Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:47.0) Gecko/20100101 Firefox/47.0',
        'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36',
        'Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:47.0) Gecko/20100101 Firefox/47.0'
      ],
      platforms: ['Chromium OS', 'iOS', 'Linux', 'macOS', 'Windows']
    }
  })
  .then((res) => {})
```

æ›´å¤šæŒ‡çº¹é€‰é¡¹å¯ä»¥å‰å¾€å¯¹åº”çš„é…ç½®æŸ¥çœ‹ã€‚

### é—´éš”æ—¶é—´

é—´éš”æ—¶é—´å¯ä»¥é˜²æ­¢å¹¶å‘é‡å¤ªå¤§ï¼Œé¿å…ç»™æœåŠ¡å™¨é€ æˆå¤ªå¤§çš„å‹åŠ›ã€‚

çˆ¬å–é—´éš”æ—¶é—´æ˜¯ç”±å®ä¾‹æ–¹æ³•å†…éƒ¨æ§åˆ¶çš„ï¼Œå¹¶éç”±å®ä¾‹æ§åˆ¶æ•´ä¸ªçˆ¬å–é—´éš”æ—¶é—´ã€‚

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl()

myXCrawl
  .crawlData({
    targets: ['https://www.example.com/api-1', 'https://www.example.com/api-2'],
    intervalTime: { max: 2000, min: 1000 }
  })
  .then((res) => {})
```

intervalTime é€‰é¡¹é»˜è®¤ä¸º undefined ã€‚è‹¥æœ‰è®¾ç½®å€¼ï¼Œåˆ™ä¼šåœ¨è¯·æ±‚å‰ç­‰å¾…ä¸€æ®µæ—¶é—´ï¼Œå¯ä»¥é˜²æ­¢å¹¶å‘é‡å¤ªå¤§ï¼Œé¿å…ç»™æœåŠ¡å™¨é€ æˆå¤ªå¤§çš„å‹åŠ›ã€‚

- number: å›ºå®šæ¯æ¬¡è¯·æ±‚å‰å¿…é¡»ç­‰å¾…çš„æ—¶é—´
- Object: åœ¨ max å’Œ min ä¸­éšæœºå–ä¸€ä¸ªå€¼ï¼Œæ›´åŠ æ‹ŸäººåŒ–

**æ³¨æ„:** ç¬¬ä¸€æ¬¡è¯·æ±‚æ˜¯ä¸ä¼šè§¦å‘é—´éš”æ—¶é—´ã€‚

### å¤±è´¥é‡è¯•

å¤±è´¥é‡è¯•åœ¨è¶…æ—¶ä¹‹ç±»çš„é”™è¯¯å‘ç”Ÿæ—¶ï¼Œå°†ä¼šç­‰å¾…è¿™ä¸€è½®è¯·æ±‚ç»“æŸåé‡æ–°è¯·æ±‚ã€‚

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl()

myXCrawl
  .crawlData({ url: 'https://www.example.com/api', maxRetry: 1 })
  .then((res) => {})
```

maxRetry å±æ€§å†³å®šè¦é‡è¯•å‡ æ¬¡ã€‚

### ä¼˜å…ˆé˜Ÿåˆ—

ä¼˜å…ˆé˜Ÿåˆ—å¯ä»¥è®©æŸä¸ªè¯·æ±‚ä¼˜å…ˆå‘é€ã€‚

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl()

myXCrawl
  .crawlData([
    { url: 'https://www.example.com/api-1', priority: 1 },
    { url: 'https://www.example.com/api-2', priority: 10 },
    { url: 'https://www.example.com/api-3', priority: 8 }
  ])
  .then((res) => {})
```

priority å±æ€§çš„å€¼è¶Šå¤§å°±åœ¨å½“å‰çˆ¬å–é˜Ÿåˆ—ä¸­è¶Šä¼˜å…ˆã€‚

### å…³äºç»“æœ

å¯¹äºç»“æœï¼Œæ¯ä¸ªè¯·æ±‚çš„ç»“æœå°†ç»Ÿä¸€ä½¿ç”¨å¯¹è±¡åŒ…è£¹ç€ï¼Œè¯¥å¯¹è±¡æä¾›äº†å…³äºè¿™æ¬¡è¯·æ±‚ç»“æœçš„ä¿¡æ¯ï¼Œæ¯”å¦‚ï¼šidã€ç»“æœã€æ˜¯å¦æˆåŠŸã€æœ€å¤§é‡è¯•ã€é‡è¯•æ¬¡æ•°ã€æ”¶é›†åˆ°é”™è¯¯ä¿¡æ¯ç­‰ã€‚è‡ªåŠ¨æ ¹æ®ä½ é€‰ç”¨çš„é…ç½®æ–¹å¼å†³å®šè¿”å›å€¼æ˜¯å¦åŒ…è£¹åœ¨ä¸€ä¸ªæ•°ç»„ä¸­ï¼Œå¹¶ä¸”åœ¨ TS ä¸­ç±»å‹å®Œç¾é€‚é…ã€‚

æ¯ä¸ªå¯¹è±¡çš„ id æ˜¯æ ¹æ®ä½ é…ç½®é‡Œçš„è¯·æ±‚é¡ºåºå†³å®šçš„ï¼Œå¦‚æœæœ‰ä½¿ç”¨ä¼˜å…ˆçº§ï¼Œåˆ™ä¼šæ ¹æ®ä¼˜å…ˆçº§æ’åºã€‚

ç›¸å…³çš„é…ç½®æ–¹å¼å’Œç»“æœè¯¦æƒ…æŸ¥çœ‹ï¼š[crawlPage é…ç½®](#é…ç½®)ã€[crawlData é…ç½®](#é…ç½®-1)ã€[crawlFile é…ç½®](#é…ç½®-2) ã€‚

### TypeScript

åƒ TypeScript è¿™æ ·çš„ç±»å‹ç³»ç»Ÿå¯ä»¥åœ¨ç¼–è¯‘æ—¶é€šè¿‡é™æ€åˆ†ææ£€æµ‹å‡ºå¾ˆå¤šå¸¸è§é”™è¯¯ã€‚è¿™å‡å°‘äº†è¿è¡Œæ—¶é”™è¯¯ï¼Œä¹Ÿè®©æˆ‘ä»¬åœ¨é‡æ„å¤§å‹é¡¹ç›®çš„æ—¶å€™æ›´æœ‰ä¿¡å¿ƒã€‚é€šè¿‡ IDE ä¸­åŸºäºç±»å‹çš„è‡ªåŠ¨è¡¥å…¨ï¼ŒTypeScript è¿˜æ”¹å–„äº†å¼€å‘ä½“éªŒå’Œæ•ˆç‡ã€‚

x-crawl æœ¬èº«å°±æ˜¯ç”¨ TypeScript ç¼–å†™çš„ï¼Œå¹¶å¯¹ TypeScript æä¾›äº†æ”¯æŒã€‚è‡ªå¸¦ç±»å‹å£°æ˜æ–‡ä»¶ï¼Œå¼€ç®±å³ç”¨ã€‚

## API

### xCrawl

é€šè¿‡è°ƒç”¨ xCrawl åˆ›å»ºä¸€ä¸ªçˆ¬è™«å®ä¾‹ã€‚è¯·æ±‚æ˜¯ç”±å®ä¾‹æ–¹æ³•å†…éƒ¨è‡ªå·±ç»´æŠ¤ï¼Œå¹¶éç”±å®ä¾‹è‡ªå·±ç»´æŠ¤ã€‚

#### ç±»å‹

xCrawl API æ˜¯ä¸€ä¸ªå‡½æ•°ã€‚

```ts
function xCrawl(baseConfig?: XCrawlBaseConfig): XCrawlInstance
```

**å‚æ•°ç±»å‹ï¼š**

- æŸ¥çœ‹ [XCrawlBaseConfig](#XCrawlBaseConfig) ç±»å‹

**è¿”å›å€¼ç±»å‹ï¼š**

- æŸ¥çœ‹ [XCrawlInstance](#XCrawlInstance)ç±»å‹

#### ç¤ºä¾‹

```js
import xCrawl from 'x-crawl'

// xCrawl API
const myXCrawl = xCrawl({
  baseUrl: 'https://www.example.com',
  timeout: 10000,
  intervalTime: { max: 2000, min: 1000 }
})
```

### crawlPage

crawlPage æ˜¯çˆ¬è™«å®ä¾‹çš„æ–¹æ³•ï¼Œé€šå¸¸ç”¨äºçˆ¬å–é¡µé¢ã€‚

#### ç±»å‹

crawlPage API æ˜¯ä¸€ä¸ªå‡½æ•°ã€‚ç±»å‹æ˜¯ [é‡è½½å‡½æ•°](https://www.typescriptlang.org/docs/handbook/2/functions.html#function-overloads) å¯ä»¥é€šè¿‡ä¸åŒçš„é…ç½®å‚æ•°è°ƒç”¨è¯¥å‡½æ•°ï¼ˆåœ¨ç±»å‹æ–¹é¢ï¼‰ã€‚

```ts
type crawlPage = {
  (
    config: string,
    callback?: (res: CrawlPageSingleRes) => void
  ): Promise<CrawlPageSingleRes>

  (
    config: CrawlPageDetailTargetConfig,
    callback?: (res: CrawlPageSingleRes) => void
  ): Promise<CrawlPageSingleRes>

  (
    config: (string | CrawlPageDetailTargetConfig)[],
    callback?: (res: CrawlPageSingleRes[]) => void
  ): Promise<CrawlPageSingleRes[]>

  (
    config: CrawlPageAdvancedConfig,
    callback?: (res: CrawlPageSingleRes[]) => void
  ): Promise<CrawlPageSingleRes[]>
}
```

**å‚æ•°ç±»å‹ï¼š**

- æŸ¥çœ‹ [CrawlPageDetailTargetConfig](#CrawlPageDetailTargetConfig) ç±»å‹
- æŸ¥çœ‹ [CrawlPageAdvancedConfig](#CrawlPageAdvancedConfig) ç±»å‹

**è¿”å›å€¼ç±»å‹ï¼š**

- æŸ¥çœ‹ [CrawlPageSingleRes](#CrawlPageSingleRes) ç±»å‹

#### ç¤ºä¾‹

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl()

// crawlPage API
myXCrawl.crawlPage('https://www.example.com').then((res) => {
  const { browser, page } = res.data

  // å…³é—­æµè§ˆå™¨
  browser.close()
})
```

#### é…ç½®

ä¸€å…±æœ‰ 4 ç§:

- string
- CrawlPageDetailTargetConfig
- (string | CrawlPageDetailTargetConfig)[]
- CrawlPageAdvancedConfig

**1.string**

è¿™æ˜¯ç®€å•ç›®æ ‡é…ç½®ã€‚å¦‚æœä½ åªæƒ³å•çº¯çˆ¬ä¸€ä¸‹è¿™ä¸ªé¡µé¢ï¼Œå¯ä»¥è¯•è¯•è¿™ç§å†™æ³•ï¼š

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl()

myXCrawl.crawlPage('https://www.example.com').then((res) => {})
```

æ‹¿åˆ°çš„ res å°†æ˜¯ä¸€ä¸ªå¯¹è±¡ã€‚

**2.CrawlPageDetailTargetConfig**

è¿™æ˜¯è¯¦ç»†ç›®æ ‡é…ç½®ã€‚å¦‚æœä½ æƒ³çˆ¬ä¸€ä¸‹è¿™ä¸ªé¡µé¢ï¼Œå¹¶ä¸”éœ€è¦å¤±è´¥é‡è¯•ä¹‹ç±»çš„ï¼Œå¯ä»¥è¯•è¯•è¿™ç§å†™æ³•ï¼š

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl()

myXCrawl
  .crawlPage({
    url: 'https://www.example.com',
    proxy: 'xxx',
    maxRetry: 1
  })
  .then((res) => {})
```

æ‹¿åˆ°çš„ res å°†æ˜¯ä¸€ä¸ªå¯¹è±¡ã€‚

æ›´å¤šé…ç½®é€‰é¡¹å¯ä»¥æŸ¥çœ‹ [CrawlPageDetailTargetConfig](#CrawlPageDetailTargetConfig) ã€‚

**3.(string | CrawlPageDetailTargetConfig)[]**

è¿™æ˜¯æ··åˆç›®æ ‡æ•°ç»„é…ç½®ã€‚å¦‚æœä½ æƒ³çˆ¬å–å¤šä¸ªé¡µé¢ï¼Œå¹¶ä¸”æœ‰äº›é¡µé¢éœ€è¦å¤±è´¥é‡è¯•ä¹‹ç±»çš„ï¼Œå¯ä»¥è¯•è¯•è¿™ç§å†™æ³•ï¼š

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl()

myXCrawl
  .crawlPage([
    'https://www.example.com/page-1',
    { url: 'https://www.example.com/page-2', maxRetry: 2 }
  ])
  .then((res) => {})
```

æ‹¿åˆ°çš„ res å°†æ˜¯ä¸€ä¸ªæ•°ç»„ï¼Œé‡Œé¢æ˜¯å¯¹è±¡ã€‚

æ›´å¤šé…ç½®é€‰é¡¹å¯ä»¥æŸ¥çœ‹ [CrawlPageDetailTargetConfig](#CrawlPageDetailTargetConfig) ã€‚

**4.CrawlPageAdvancedConfig**

è¿™æ˜¯è¿›é˜¶é…ç½®ï¼Œtargets æ˜¯æ··åˆç›®æ ‡æ•°ç»„é…ç½®ã€‚å¦‚æœä½ æƒ³çˆ¬å–å¤šä¸ªé¡µé¢ï¼Œå¹¶ä¸”è¯·æ±‚é…ç½®ï¼ˆproxyã€cookiesã€é‡è¯•ç­‰ç­‰ï¼‰ä¸æƒ³é‡å¤å†™ï¼Œéœ€è¦é—´éš”æ—¶é—´çš„è¯ï¼Œå¯ä»¥è¯•è¯•è¿™ç§å†™æ³•ï¼š

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl()

myXCrawl
  .crawlPage({
    targets: [
      'https://www.example.com/page-1',
      { url: 'https://www.example.com/page-2', maxRetry: 6 }
    ],
    intervalTime: { max: 3000, min: 1000 },
    cookies: 'xxx',
    maxRetry: 1
  })
  .then((res) => {})
```

æ‹¿åˆ°çš„ res å°†æ˜¯ä¸€ä¸ªæ•°ç»„ï¼Œé‡Œé¢æ˜¯å¯¹è±¡ã€‚

æ›´å¤šé…ç½®é€‰é¡¹å¯ä»¥æŸ¥çœ‹ [CrawlPageAdvancedConfig](#CrawlPageAdvancedConfig) ã€‚

å…³äºç»“æœçš„æ›´å¤šä¿¡æ¯å¯æŸ¥çœ‹ [å…³äºç»“æœ](#å…³äºç»“æœ) ï¼Œå¯ä»¥æ ¹æ®å®é™…æƒ…å†µé€‰ç”¨å³å¯ã€‚

### crawlData

crawl æ˜¯çˆ¬è™«å®ä¾‹çš„æ–¹æ³•ï¼Œé€šå¸¸ç”¨äºçˆ¬å– API ï¼Œå¯è·å– JSON æ•°æ®ç­‰ç­‰ã€‚

#### ç±»å‹

crawlData API æ˜¯ä¸€ä¸ªå‡½æ•°ã€‚ç±»å‹æ˜¯ [é‡è½½å‡½æ•°](https://www.typescriptlang.org/docs/handbook/2/functions.html#function-overloads) å¯ä»¥é€šè¿‡ä¸åŒçš„é…ç½®å‚æ•°è°ƒç”¨è¯¥å‡½æ•°ï¼ˆåœ¨ç±»å‹æ–¹é¢ï¼‰ã€‚

```ts
type crawlData = {
  <T = any>(
    config: CrawlDataDetailTargetConfig,
    callback?: (res: CrawlDataSingleRes<T>) => void
  ): Promise<CrawlDataSingleRes<T>>

  <T = any>(
    config: string,
    callback?: (res: CrawlDataSingleRes<T>) => void
  ): Promise<CrawlDataSingleRes<T>>

  <T = any>(
    config: (string | CrawlDataDetailTargetConfig)[],
    callback?: (res: CrawlDataSingleRes<T>[]) => void
  ): Promise<CrawlDataSingleRes<T>[]>

  <T = any>(
    config: CrawlDataAdvancedConfig<T>,
    callback?: (res: CrawlDataSingleRes<T>[]) => void
  ): Promise<CrawlDataSingleRes<T>[]>
}
```

**å‚æ•°ç±»å‹ï¼š**

- æŸ¥çœ‹ [CrawlDataDetailTargetConfig](#CrawlDataDetailTargetConfig) ç±»å‹
- æŸ¥çœ‹ [CrawlDataAdvancedConfig](#CrawlDataAdvancedConfig) ç±»å‹

**è¿”å›å€¼ç±»å‹ï¼š**

- æŸ¥çœ‹ [CrawlDataSingleRes](#CrawlDataSingleRes) ç±»å‹

#### ç¤ºä¾‹

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl({
  timeout: 10000,
  intervalTime: { max: 2000, min: 1000 }
})

// crawlData API
myXCrawl
  .crawlData({
    targets: ['https://www.example.com/api-1', 'https://www.example.com/api-2'],
    intervalTime: { max: 3000, min: 1000 },
    cookies: 'xxx',
    maxRetry: 1
  })
  .then((res) => {
    console.log(res)
  })
```

#### é…ç½®

ä¸€å…±æœ‰ 4 ç§:

- string
- CrawlDataDetailTargetConfig
- (string | CrawlDataDetailTargetConfig)[]
- CrawlDataAdvancedConfig

**1.string**

è¿™æ˜¯ç®€å•ç›®æ ‡é…ç½®ã€‚å¦‚æœä½ åªæƒ³å•çº¯çˆ¬ä¸€ä¸‹è¿™ä¸ªæ•°æ®ï¼Œå¹¶ä¸”è¯¥æ¥å£æ˜¯ GET æ–¹å¼çš„ï¼Œå¯ä»¥è¯•è¯•è¿™ç§å†™æ³•ï¼š

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl()

myXCrawl.crawlData('https://www.example.com/api').then((res) => {})
```

æ‹¿åˆ°çš„ res å°†æ˜¯ä¸€ä¸ªå¯¹è±¡ã€‚

**2.CrawlDataDetailTargetConfig**

è¿™æ˜¯è¯¦ç»†ç›®æ ‡é…ç½®ã€‚å¦‚æœä½ æƒ³çˆ¬ä¸€ä¸‹è¿™ä¸ªæ•°æ®ï¼Œå¹¶ä¸”éœ€è¦å¤±è´¥é‡è¯•ä¹‹ç±»çš„ï¼Œå¯ä»¥è¯•è¯•è¿™ç§å†™æ³•ï¼š

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl()

myXCrawl
  .crawlData({
    url: 'https://www.example.com/api',
    proxy: 'xxx',
    maxRetry: 1
  })
  .then((res) => {})
```

æ‹¿åˆ°çš„ res å°†æ˜¯ä¸€ä¸ªå¯¹è±¡ã€‚

æ›´å¤šé…ç½®é€‰é¡¹å¯ä»¥æŸ¥çœ‹ [CrawlDataDetailTargetConfig](#CrawlDataDetailTargetConfig) ã€‚

**3.(string | CrawlDataDetailTargetConfig)[]**

è¿™æ˜¯æ··åˆç›®æ ‡æ•°ç»„é…ç½®ã€‚å¦‚æœä½ æƒ³çˆ¬å–å¤šä¸ªæ•°æ®ï¼Œå¹¶ä¸”æœ‰äº›æ•°æ®éœ€è¦å¤±è´¥é‡è¯•ä¹‹ç±»çš„ï¼Œå¯ä»¥è¯•è¯•è¿™ç§å†™æ³•ï¼š

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl()

myXCrawl
  .crawlPage([
    'https://www.example.com/api-1',
    { url: 'https://www.example.com/api-2', maxRetry: 2 }
  ])
  .then((res) => {})
```

æ‹¿åˆ°çš„ res å°†æ˜¯ä¸€ä¸ªæ•°ç»„ï¼Œé‡Œé¢æ˜¯å¯¹è±¡ã€‚

æ›´å¤šé…ç½®é€‰é¡¹å¯ä»¥æŸ¥çœ‹ [CrawlDataDetailTargetConfig](#CrawlDataDetailTargetConfig) ã€‚

**4.CrawlDataAdvancedConfig**

è¿™æ˜¯è¿›é˜¶é…ç½®ï¼Œtargets æ˜¯æ··åˆç›®æ ‡æ•°ç»„é…ç½®ã€‚å¦‚æœä½ æƒ³çˆ¬å–å¤šä¸ªæ•°æ®ï¼Œå¹¶ä¸”è¯·æ±‚é…ç½®ï¼ˆproxyã€cookiesã€é‡è¯•ç­‰ç­‰ï¼‰ä¸æƒ³é‡å¤å†™ï¼Œéœ€è¦é—´éš”æ—¶é—´çš„è¯ï¼Œå¯ä»¥è¯•è¯•è¿™ç§å†™æ³•ï¼š

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl()

myXCrawl
  .crawlData({
    targets: [
      'https://www.example.com/api-1',
      { url: 'https://www.example.com/api-2', maxRetry: 6 }
    ],
    intervalTime: { max: 3000, min: 1000 },
    cookies: 'xxx',
    maxRetry: 1
  })
  .then((res) => {})
```

æ‹¿åˆ°çš„ res å°†æ˜¯ä¸€ä¸ªæ•°ç»„ï¼Œé‡Œé¢æ˜¯å¯¹è±¡ã€‚

æ›´å¤šé…ç½®é€‰é¡¹å¯ä»¥æŸ¥çœ‹ [CrawlPageAdvancedConfig](#CrawlPageAdvancedConfig) ã€‚

å…³äºç»“æœçš„æ›´å¤šä¿¡æ¯å¯æŸ¥çœ‹ [å…³äºç»“æœ](#å…³äºç»“æœ) ï¼Œå¯ä»¥æ ¹æ®å®é™…æƒ…å†µé€‰ç”¨å³å¯ã€‚

### crawlFile

crawlFile æ˜¯çˆ¬è™«å®ä¾‹çš„æ–¹æ³•ï¼Œé€šå¸¸ç”¨äºçˆ¬å–æ–‡ä»¶ï¼Œå¯è·å–å›¾ç‰‡ã€pdf æ–‡ä»¶ç­‰ç­‰ã€‚

#### ç±»å‹

crawlFile API æ˜¯ä¸€ä¸ªå‡½æ•°ã€‚ç±»å‹æ˜¯ [é‡è½½å‡½æ•°](https://www.typescriptlang.org/docs/handbook/2/functions.html#function-overloads) å¯ä»¥é€šè¿‡ä¸åŒçš„é…ç½®å‚æ•°è°ƒç”¨è¯¥å‡½æ•°ï¼ˆåœ¨ç±»å‹æ–¹é¢ï¼‰ã€‚

```ts
type crawlFile = {
  (
    config: CrawlFileDetailTargetConfig,
    callback?: (res: CrawlFileSingleRes) => void
  ): Promise<CrawlFileSingleRes>

  (
    config: CrawlFileDetailTargetConfig[],
    callback?: (res: CrawlFileSingleRes[]) => void
  ): Promise<CrawlFileSingleRes[]>

  (
    config: CrawlFileAdvancedConfig,
    callback?: (res: CrawlFileSingleRes[]) => void
  ): Promise<CrawlFileSingleRes[]>
}
```

**å‚æ•°ç±»å‹ï¼š**

- æŸ¥çœ‹ [CrawlFileDetailTargetConfig](#CrawlFileDetailTargetConfig) ç±»å‹
- æŸ¥çœ‹ [CrawlFileAdvancedConfig](#CrawlFileAdvancedConfig) ç±»å‹

**è¿”å›å€¼ç±»å‹ï¼š**

- æŸ¥çœ‹ [CrawlFileSingleRes](#CrawlFileSingleRes) ç±»å‹

#### ç¤ºä¾‹

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl({
  timeout: 10000,
  intervalTime: { max: 2000, min: 1000 }
})

// crawlFile API
myXCrawl
  .crawlFile({
    targets: [
      'https://www.example.com/file-1',
      'https://www.example.com/file-2'
    ],
    storeDir: './upload',
    intervalTime: { max: 3000, min: 1000 },
    maxRetry: 1
  })
  .then((res) => {})
```

#### é…ç½®

ä¸€å…±æœ‰ 3 ç§:

- CrawlFileDetailTargetConfig
- CrawlFileDetailTargetConfig[]
- CrawlFileAdvancedConfig

**1.CrawlFileDetailTargetConfig**

è¿™æ˜¯è¯¦ç»†ç›®æ ‡é…ç½®ã€‚å¦‚æœä½ æƒ³çˆ¬ä¸€ä¸‹è¿™ä¸ªæ–‡ä»¶ï¼Œå¹¶ä¸”éœ€è¦å¤±è´¥é‡è¯•ä¹‹ç±»çš„ï¼Œå¯ä»¥è¯•è¯•è¿™ç§å†™æ³•ï¼š

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl()

myXCrawl
  .crawlFile({
    url: 'https://www.example.com/file',
    proxy: 'xxx',
    maxRetry: 1,
    storeDir: './upload',
    fileName: 'xxx'
  })
  .then((res) => {})
```

æ‹¿åˆ°çš„ res å°†æ˜¯ä¸€ä¸ªå¯¹è±¡ã€‚

æ›´å¤šé…ç½®é€‰é¡¹å¯ä»¥æŸ¥çœ‹ [CrawlFileDetailTargetConfig](#CrawlFileDetailTargetConfig) ã€‚

**2.CrawlFileDetailTargetConfig[]**

è¿™æ˜¯è¯¦ç»†ç›®æ ‡æ•°ç»„é…ç½®ã€‚å¦‚æœä½ æƒ³çˆ¬å–å¤šä¸ªæ–‡ä»¶ï¼Œå¹¶ä¸”æœ‰äº›æ•°æ®éœ€è¦å¤±è´¥é‡è¯•ä¹‹ç±»çš„ï¼Œå¯ä»¥è¯•è¯•è¿™ç§å†™æ³•ï¼š

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl()

myXCrawl
  .crawlFile([
    { url: 'https://www.example.com/file-1', storeDir: './upload' },
    { url: 'https://www.example.com/file-2', storeDir: './upload', maxRetry: 2 }
  ])
  .then((res) => {})
```

æ‹¿åˆ°çš„ res å°†æ˜¯ä¸€ä¸ªæ•°ç»„ï¼Œé‡Œé¢æ˜¯å¯¹è±¡ã€‚

æ›´å¤šé…ç½®é€‰é¡¹å¯ä»¥æŸ¥çœ‹ [CrawlFileDetailTargetConfig](#CrawlFileDetailTargetConfig) ã€‚

**3.CrawlFileAdvancedConfig**

è¿™æ˜¯è¿›é˜¶é…ç½®ï¼Œtargets æ˜¯æ··åˆç›®æ ‡æ•°ç»„é…ç½®ã€‚å¦‚æœä½ æƒ³çˆ¬å–å¤šä¸ªæ•°æ®ï¼Œå¹¶ä¸”è¯·æ±‚é…ç½®ï¼ˆstoreDirã€proxyã€é‡è¯•ç­‰ç­‰ï¼‰ä¸æƒ³é‡å¤å†™ï¼Œéœ€è¦é—´éš”æ—¶é—´ç­‰ç­‰çš„è¯ï¼Œå¯ä»¥è¯•è¯•è¿™ç§å†™æ³•ï¼š

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl()

myXCrawl
  .crawlFile({
    targets: [
      'https://www.example.com/file-1',
      { url: 'https://www.example.com/file-2', storeDir: './upload/file2' }
    ],
    storeDir: './upload',
    intervalTime: { max: 3000, min: 1000 },
    maxRetry: 1
  })
  .then((res) => {})
```

æ‹¿åˆ°çš„ res å°†æ˜¯ä¸€ä¸ªæ•°ç»„ï¼Œé‡Œé¢æ˜¯å¯¹è±¡ã€‚

æ›´å¤šé…ç½®é€‰é¡¹å¯ä»¥æŸ¥çœ‹ [CrawlFileAdvancedConfig](#CrawlFileAdvancedConfig) ã€‚

å…³äºç»“æœçš„æ›´å¤šä¿¡æ¯å¯æŸ¥çœ‹ [å…³äºç»“æœ](#å…³äºç»“æœ) ï¼Œå¯ä»¥æ ¹æ®å®é™…æƒ…å†µé€‰ç”¨å³å¯ã€‚

### startPolling

crawlPolling æ˜¯çˆ¬è™«å®ä¾‹çš„æ–¹æ³•ï¼Œé€šå¸¸ç”¨äºè¿›è¡Œè½®è¯¢æ“ä½œï¼Œæ¯”å¦‚æ¯éš”ä¸€æ®µæ—¶é—´è·å–æ–°é—»ä¹‹ç±»çš„ã€‚

#### ç±»å‹

- æŸ¥çœ‹ [StartPollingConfig](#StartPollingConfig) ç±»å‹

```ts
function startPolling: (
  config: StartPollingConfig,
  callback: (count: number, stopPolling: () => void) => void
) => void
```

#### ç¤ºä¾‹

```js
import xCrawl from 'x-crawl'

const myXCrawl = xCrawl({
  timeout: 10000,
  intervalTime: { max: 2000, min: 1000 }
})

// startPolling API
myXCrawl.startPolling({ h: 2, m: 30 }, (count, stopPolling) => {
  // æ¯éš”ä¸¤ä¸ªåŠå°æ—¶ä¼šæ‰§è¡Œä¸€æ¬¡
  // crawlPage/crawlData/crawlFile
})
```

## ç±»å‹

### API config

#### XCrawlConfig

```ts
export interface XCrawlConfig extends CrawlCommonConfig {
  mode?: 'async' | 'sync'
  enableRandomFingerprint?: boolean
  baseUrl?: string
  intervalTime?: IntervalTime
  crawlPage?: {
    launchBrowser?: PuppeteerLaunchOptions // puppeteer
  }
}
```

#### Detail target config

##### CrawlPageDetailTargetConfig

```ts
export interface CrawlPageDetailTargetConfig extends CrawlCommonConfig {
  url: string
  headers?: AnyObject | null
  cookies?: PageCookies | null
  priority?: number
  viewport?: Viewport | null // puppeteer
  fingerprint?:
    | (DetailTargetFingerprintCommon & {
        maxWidth: number
        minWidth?: number
        maxHeight: number
        minHidth?: number
      })
    | null
}
```

##### CrawlDataDetailTargetConfig

```ts
export interface CrawlDataDetailTargetConfig extends CrawlCommonConfig {
  url: string
  method?: Method
  headers?: AnyObject | null
  params?: AnyObject
  data?: any
  priority?: number
  fingerprint?: DetailTargetFingerprintCommon | null
}
```

##### CrawlFileDetailTargetConfig

```ts
export interface CrawlFileDetailTargetConfig extends CrawlCommonConfig {
  url: string
  headers?: AnyObject | null
  priority?: number
  storeDir?: string | null
  fileName?: string
  extension?: string | null
  fingerprint?: DetailTargetFingerprintCommon | null
}
```

#### Advanced config

##### CrawlPageAdvancedConfig

```ts
export interface CrawlPageAdvancedConfig extends CrawlCommonConfig {
  targets: (string | CrawlPageDetailTargetConfig)[]
  intervalTime?: IntervalTime
  fingerprint?: AdvancedFingerprintCommon & {
    maxWidth: number
    minWidth?: number
    maxHeight: number
    minHidth?: number
  }

  headers?: AnyObject
  cookies?: PageCookies
  viewport?: Viewport // puppeteer

  onCrawlItemComplete?: (crawlPageSingleRes: CrawlPageSingleRes) => void
}
```

##### CrawlDataAdvancedConfig

```ts
export interface CrawlDataAdvancedConfig<T> extends CrawlCommonConfig {
  targets: (string | CrawlDataDetailTargetConfig)[]
  intervalTime?: IntervalTime
  fingerprint?: AdvancedFingerprintCommon

  headers?: AnyObject

  onCrawlItemComplete?: (crawlDataSingleRes: CrawlDataSingleRes<T>) => void
}
```

##### CrawlFileAdvancedConfig

```ts
export interface CrawlFileAdvancedConfig extends CrawlCommonConfig {
  targets: (string | CrawlFileDetailTargetConfig)[]
  intervalTime?: IntervalTime
  fingerprint?: AdvancedFingerprintCommon

  headers?: AnyObject
  storeDir?: string
  extension?: string

  onCrawlItemComplete?: (crawlFileSingleRes: CrawlFileSingleRes) => void
  onBeforeSaveItemFile?: (info: {
    id: number
    fileName: string
    filePath: string
    data: Buffer
  }) => Promise<Buffer>
}
```

#### StartPollingConfig

```ts
export interface StartPollingConfig {
  d?: number
  h?: number
  m?: number
}
```

#### Crawl other config

##### CrawlCommonConfig

```ts
export interface CrawlCommonConfig {
  timeout?: number
  proxy?: string
  maxRetry?: number
}
```

##### DetailTargetFingerprintCommon

```ts
export interface DetailTargetFingerprintCommon {
  userAgent?: string
  ua?: string
  platform?: Platform
  platformVersion?: string
  mobile?: Mobile
  acceptLanguage?: string
}
```

##### AdvancedFingerprintCommon

```ts
export interface AdvancedFingerprintCommon {
  userAgents?: string[]
  uas?: string[]
  platforms?: Platform[]
  platformVersions?: string[]
  mobiles?: Mobile[]
  acceptLanguages?: string[]
}
```

##### Mobile

```ts
export type Mobile = '?0' | '?1'
```

##### Platform

```ts
export type Platform =
  | 'Android'
  | 'Chrome OS'
  | 'Chromium OS'
  | 'iOS'
  | 'Linux'
  | 'macOS'
  | 'Windows'
  | 'Unknown'
```

##### PageCookies

```ts
export type PageCookies =
  | string
  | Protocol.Network.CookieParam // puppeteer
  | Protocol.Network.CookieParam[] // puppeteer
```

##### Method

```ts
export type Method =
  | 'get'
  | 'GET'
  | 'delete'
  | 'DELETE'
  | 'head'
  | 'HEAD'
  | 'options'
  | 'OPTIONS'
  | 'post'
  | 'POST'
  | 'put'
  | 'PUT'
  | 'patch'
  | 'PATCH'
  | 'purge'
  | 'PURGE'
  | 'link'
  | 'LINK'
  | 'unlink'
  | 'UNLINK'
```

##### IntervalTime

```ts
export type IntervalTime = number | { max: number; min?: number }
```

### API result

#### XCrawlInstance

```ts
export interface XCrawlInstance {
  crawlPage: {
    (
      config: string,
      callback?: (res: CrawlPageSingleRes) => void
    ): Promise<CrawlPageSingleRes>

    (
      config: CrawlPageDetailTargetConfig,
      callback?: (res: CrawlPageSingleRes) => void
    ): Promise<CrawlPageSingleRes>

    (
      config: (string | CrawlPageDetailTargetConfig)[],
      callback?: (res: CrawlPageSingleRes[]) => void
    ): Promise<CrawlPageSingleRes[]>

    (
      config: CrawlPageAdvancedConfig,
      callback?: (res: CrawlPageSingleRes[]) => void
    ): Promise<CrawlPageSingleRes[]>
  }

  crawlData: {
    <T = any>(
      config: CrawlDataDetailTargetConfig,
      callback?: (res: CrawlDataSingleRes<T>) => void
    ): Promise<CrawlDataSingleRes<T>>

    <T = any>(
      config: string,
      callback?: (res: CrawlDataSingleRes<T>) => void
    ): Promise<CrawlDataSingleRes<T>>

    <T = any>(
      config: (string | CrawlDataDetailTargetConfig)[],
      callback?: (res: CrawlDataSingleRes<T>[]) => void
    ): Promise<CrawlDataSingleRes<T>[]>

    <T = any>(
      config: CrawlDataAdvancedConfig<T>,
      callback?: (res: CrawlDataSingleRes<T>[]) => void
    ): Promise<CrawlDataSingleRes<T>[]>
  }

  crawlFile: {
    (
      config: CrawlFileDetailTargetConfig,
      callback?: (res: CrawlFileSingleRes) => void
    ): Promise<CrawlFileSingleRes>

    (
      config: CrawlFileDetailTargetConfig[],
      callback?: (res: CrawlFileSingleRes[]) => void
    ): Promise<CrawlFileSingleRes[]>

    (
      config: CrawlFileAdvancedConfig,
      callback?: (res: CrawlFileSingleRes[]) => void
    ): Promise<CrawlFileSingleRes[]>
  }

  startPolling: (
    config: StartPollingConfig,
    callback: (count: number, stopPolling: () => void) => void
  ) => void
}
```

#### CrawlCommonRes

```ts
export interface CrawlCommonRes {
  id: number
  isSuccess: boolean
  maxRetry: number
  retryCount: number
  crawlErrorQueue: Error[]
}
```

#### CrawlPageSingleRes

```ts
export interface CrawlPageSingleRes extends CrawlCommonRes {
  data: {
    browser: Browser // puppeteer
    response: HTTPResponse | null // puppeteer
    page: Page // puppeteer
  }
}
```

#### CrawlDataSingleRes

```ts
export interface CrawlDataSingleRes<D> extends CrawlCommonRes {
  data: {
    statusCode: number | undefined
    headers: IncomingHttpHeaders // nodejs http
    data: D
  } | null
}
```

#### CrawlFileSingleRes

```ts
export interface CrawlFileSingleRes extends CrawlCommonRes {
  data: {
    statusCode: number | undefined
    headers: IncomingHttpHeaders // nodejs http
    data: {
      isSuccess: boolean
      fileName: string
      fileExtension: string
      mimeType: string
      size: number
      filePath: string
    }
  } | null
}
```

### API Other

#### AnyObject

```ts
export interface AnyObject extends Object {
  [key: string | number | symbol]: any
}
```

## æ›´å¤š

å¦‚æœæ‚¨æœ‰ **é—®é¢˜ ã€éœ€æ±‚ã€å¥½çš„å»ºè®®** è¯·åœ¨ https://github.com/coder-hxl/x-crawl/issues ä¸­æ **Issues** ã€‚

æ„Ÿè°¢å¤§å®¶çš„æ”¯æŒã€‚
