# [v10.1.0](https://github.com/coder-hxl/x-crawl/compare/v10.0.2..v10.1.0) (2025-04-06)

### ğŸš€ Features

- Added ollama
- Change the openai model type to string

### â›“ï¸ Dependencies

- puppeteer from 22.13.1 to 24.6.0
- openai from 4.52.7 to 4.91.1
- upgrade non-major dependencies to the latest version

---

### ğŸš€ ç‰¹å¾

- æ–°å¢ ollama
- openai æ¨¡å‹ç±»å‹æ”¹ä¸º string

### â›“ï¸ ä¾èµ–å…³ç³»

- puppeteer ä» 22.13.1 å‡è‡³ 24.6.0
- openai ä» 4.52.7 å‡è‡³ 4.91.1
- éä¸»è¦ä¾èµ–é¡¹å‡çº§æœ€æ–°ç‰ˆæœ¬

# [v10.0.2](https://github.com/coder-hxl/x-crawl/compare/v10.0.1..v10.0.2) (2024-07-21)

### ğŸš€ Features

- Added 'gpt-4o' | 'gpt-4o-2024-05-13' | 'gpt-4-turbo' | 'gpt-4-turbo-2024-04-09' to OpenAIChatModel type to keep in sync with openai.

### â›“ï¸ Dependencies

- puppeteer from 22.5.0 to 22.13.1
- openai from 4.33.0 to 4.52.7
- https-proxy-agent from 7.0.4 to 7.0.5

---

### ğŸš€ ç‰¹å¾

- OpenAIChatModel ç±»å‹æ–°å¢ 'gpt-4o' | 'gpt-4o-2024-05-13' | 'gpt-4-turbo' | 'gpt-4-turbo-2024-04-09' ï¼Œä¸ openai ä¿æŒåŒæ­¥ã€‚

### â›“ï¸ ä¾èµ–å…³ç³»

- puppeteer ä» 22.5.0 å‡è‡³ 22.13.1
- openai ä» 4.33.0 å‡è‡³ 4.52.7
- https-proxy-agent ä» 7.0.4 å‡è‡³ 7.0.5

# [v10.0.1](https://github.com/coder-hxl/x-crawl/compare/v10.0.0..v10.0.1) (2024-04-10)

### ğŸ Bug fixes

- Fix the wrong export

---

### ğŸ æ¼æ´ä¿®å¤

- ä¿®å¤é”™è¯¯çš„å¯¼å‡º

# [v10.0.0](https://github.com/coder-hxl/x-crawl/compare/v9.0.0..v10.0.0) (2024-04-10)

### ğŸš€ Features

- Introduction to the new AI-assisted features of x-crawl. In the latest version of x-crawl, we have introduced powerful AI-assisted features to make crawler work more efficient, intelligent and convenient. This innovative feature is mainly reflected in the following aspects:
  **1. Intelligent on-demand analysis elements**
  Traditional crawler work often requires manual analysis of the HTML page structure to extract the required element attributes or values. And now, with x-crawlâ€™s AI assistance, you can easily implement intelligent on-demand analysis elements. Just tell AI which element information you want to obtain, and AI will automatically analyze the page structure and extract the corresponding element attributes or values.
  **2. Intelligent generation of element selectors**
  Selectors are an indispensable part of the crawler's work. They can help us quickly locate specific elements on the page. x-crawl's AI assistance can now intelligently generate element selectors for you. Just enter the HTML code into AI, and AI will automatically generate the appropriate selector for you based on the page structure, greatly simplifying the tedious process of determining the selector.
  **3. Intelligent reply to crawler questions**
  In crawler work, we will inevitably encounter various problems and challenges. And x-crawlâ€™s AI assistance can provide you with intelligent answers and suggestions. Whether it is about crawling strategies, anti-crawling techniques or data processing, you can ask AI questions, and AI will provide you with professional answers and suggestions based on its powerful learning and reasoning capabilities to help you complete your tasks better. Reptile task.
  **4. User-defined AI functions**
  In order to meet the personalized needs of different users, x-crawl also provides user-customized AI functions. This means you can tailor and optimize the AI to your needs to better suit your crawling efforts. Whether you are adjusting the AI analysis strategy, optimizing the selector generation algorithm, or adding new functional modules, you can do it through simple operations to make AI more in line with your usage habits and workflow.
- The crawlFile API parameters are newly added string and (string | CrawlFileDetailTargetConfig)[], which is equivalent to the same four writing methods as crawlPage crawlHTML crawlData. The onBeforeSaveItemFile callback function configured by CrawlFileAdvancedConfig is no longer forced to return a Promise whose result is a Buffer, and can be Promise<Buffer | void> | Buffer | void.
- Refactor documents using VitePress, the new version of the document is at: https://coder-hxl.github.io/x-crawl .

### ğŸš¨ Major changes

- CJS is no longer supported, only ESM is exported.
- xCrawl was renamed to createCrawl , and its crawlPage.puppeteerLaunch options were renamed to puppeteerLaunchOptions .
- The export method has been changed. The default export is no longer used, but the two functions createCrawl (original name xCrawl) and createCrawlOpenAI are directly exported.
- Remove startPolling API
- Cancel the second parameter (callback function) of these four APIs: crawlPage crawlHTML crawlData crawlFile
- type:
  - XCrawlConfig renamed to CreateCrawlConfig
  - XCrawlInstance renamed to CrawlApp

### â›“ï¸ Dependencies

- chalk upgraded from 4.1.2 to 5.3.0

---

### ğŸš€ ç‰¹å¾

- x-crawl å…¨æ–° AI è¾…åŠ©ç‰¹æ€§ä»‹ç»ï¼Œåœ¨ x-crawl çš„æœ€æ–°ç‰ˆæœ¬ä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†å¼ºå¤§çš„ AI è¾…åŠ©åŠŸèƒ½ï¼Œä½¿çˆ¬è™«å·¥ä½œå˜å¾—æ›´åŠ é«˜æ•ˆã€æ™ºèƒ½å’Œä¾¿æ·ã€‚è¿™ä¸€åˆ›æ–°ç‰¹æ€§ä¸»è¦ä½“ç°åœ¨ä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š
  **1. æ™ºèƒ½æŒ‰éœ€åˆ†æå…ƒç´ **
  ä¼ ç»Ÿçš„çˆ¬è™«å·¥ä½œå¾€å¾€éœ€è¦æ‰‹åŠ¨åˆ†æ HTML é¡µé¢ç»“æ„ï¼Œæå–æ‰€éœ€çš„å…ƒç´ å±æ€§æˆ–å€¼ã€‚è€Œç°åœ¨ï¼Œå€ŸåŠ© x-crawl çš„ AI è¾…åŠ©ï¼Œæ‚¨å¯ä»¥è½»æ¾å®ç°æ™ºèƒ½æŒ‰éœ€åˆ†æå…ƒç´ ã€‚åªéœ€å‘Šè¯‰AIæ‚¨æƒ³è·å–å“ªäº›å…ƒç´ çš„ä¿¡æ¯ï¼ŒAI ä¾¿ä¼šè‡ªåŠ¨åˆ†æé¡µé¢ç»“æ„ï¼Œæå–å‡ºç›¸åº”çš„å…ƒç´ å±æ€§æˆ–å€¼ã€‚
  **2. æ™ºèƒ½ç”Ÿæˆå…ƒç´ é€‰æ‹©å™¨**
  é€‰æ‹©å™¨æ˜¯çˆ¬è™«å·¥ä½œä¸­ä¸å¯æˆ–ç¼ºçš„ä¸€éƒ¨åˆ†ï¼Œå®ƒèƒ½å¤Ÿå¸®åŠ©æˆ‘ä»¬å¿«é€Ÿå®šä½åˆ°é¡µé¢ä¸­çš„ç‰¹å®šå…ƒç´ ã€‚ç°åœ¨ï¼Œx-crawl çš„ AI è¾…åŠ©å¯ä»¥ä¸ºæ‚¨æ™ºèƒ½ç”Ÿæˆå…ƒç´ é€‰æ‹©å™¨ã€‚åªéœ€å°† HTML ä»£ç è¾“å…¥åˆ° AI ä¸­ï¼ŒAI ä¾¿ä¼šæ ¹æ®é¡µé¢ç»“æ„è‡ªåŠ¨ä¸ºæ‚¨ç”Ÿæˆåˆé€‚çš„é€‰æ‹©å™¨ï¼Œå¤§å¤§ç®€åŒ–äº†ç¡®å®šé€‰æ‹©å™¨çš„ç¹çè¿‡ç¨‹ã€‚
  **3. æ™ºèƒ½å›å¤çˆ¬è™«é—®é¢˜**
  åœ¨çˆ¬è™«å·¥ä½œä¸­ï¼Œæˆ‘ä»¬éš¾å…ä¼šé‡åˆ°å„ç§é—®é¢˜å’ŒæŒ‘æˆ˜ã€‚è€Œ x-crawl çš„ AI è¾…åŠ©å¯ä»¥ä¸ºæ‚¨æä¾›æ™ºèƒ½çš„è§£ç­”å’Œå»ºè®®ã€‚æ— è®ºæ˜¯å…³äºçˆ¬è™«ç­–ç•¥ã€åçˆ¬è™«æŠ€å·§è¿˜æ˜¯æ•°æ®å¤„ç†ç­‰æ–¹é¢çš„é—®é¢˜ï¼Œæ‚¨éƒ½å¯ä»¥å‘AIæé—®ï¼ŒAIä¼šæ ¹æ®å…¶å¼ºå¤§çš„å­¦ä¹ å’Œæ¨ç†èƒ½åŠ›ï¼Œä¸ºæ‚¨æä¾›ä¸“ä¸šçš„è§£ç­”å’Œå»ºè®®ï¼Œå¸®åŠ©æ‚¨æ›´å¥½åœ°å®Œæˆçˆ¬è™«ä»»åŠ¡ã€‚
  **4. ç”¨æˆ·è‡ªå®šä¹‰AIåŠŸèƒ½**
  ä¸ºäº†æ»¡è¶³ä¸åŒç”¨æˆ·çš„ä¸ªæ€§åŒ–éœ€æ±‚ï¼Œx-crawl è¿˜æä¾›äº†ç”¨æˆ·è‡ªå®šä¹‰ AI çš„åŠŸèƒ½ã€‚è¿™æ„å‘³ç€æ‚¨å¯ä»¥æ ¹æ®è‡ªå·±çš„éœ€æ±‚ï¼Œå¯¹ AI è¿›è¡Œå®šåˆ¶å’Œä¼˜åŒ–ï¼Œä½¿å…¶æ›´å¥½åœ°é€‚åº”æ‚¨çš„çˆ¬è™«å·¥ä½œã€‚æ— è®ºæ˜¯è°ƒæ•´ AI çš„åˆ†æç­–ç•¥ã€ä¼˜åŒ–é€‰æ‹©å™¨çš„ç”Ÿæˆç®—æ³•è¿˜æ˜¯æ·»åŠ æ–°çš„åŠŸèƒ½æ¨¡å—ï¼Œæ‚¨éƒ½å¯ä»¥é€šè¿‡ç®€å•çš„æ“ä½œå®ç°ï¼Œè®© AI æ›´åŠ ç¬¦åˆæ‚¨çš„ä½¿ç”¨ä¹ æƒ¯å’Œå·¥ä½œæµç¨‹ã€‚
- crawlFile API å‚æ•°æ–°å¢ string å’Œ (string | CrawlFileDetailTargetConfig)[] , ç›¸å½“äºè·Ÿ crawlPage crawlHTML crawlData ä¸€æ ·æ‹¥æœ‰å››ç§å†™æ³•ã€‚ CrawlFileAdvancedConfig é…ç½®çš„ onBeforeSaveItemFile å›è°ƒå‡½æ•°ä¸å†å¼ºåˆ¶è¿”å›ä¸€ä¸ªç»“æœæ˜¯ Buffer çš„ Promise , å¯ä»¥æ˜¯ Promise<Buffer | void> | Buffer | void ã€‚
- ä½¿ç”¨ VitePress é‡æ„æ–‡æ¡£ï¼Œæ–°ç‰ˆæ–‡æ¡£åœ¨ï¼šhttps://coder-hxl.github.io/x-crawl/cn ã€‚

### ğŸš¨ é‡å¤§æ”¹å˜

- ä¸å†æ”¯æŒ CJS ï¼Œåªå¯¼å‡º ESM ã€‚
- xCrawl æ›´åä¸º createCrawl , å¹¶ä¸”å…¶ crawlPage.puppeteerLaunch é€‰é¡¹æ›´åä¸º puppeteerLaunchOptions ã€‚
- å¯¼å‡ºæ–¹å¼æ”¹å˜, ä¸å†ä½¿ç”¨é»˜è®¤å¯¼å‡º, è€Œæ˜¯æ”¹ä¸ºç›´æ¥å¯¼å‡º createCrawl(åŸåxCrawl) å’Œ createCrawlOpenAI è¿™ä¸¤ä¸ªå‡½æ•°ã€‚
- åˆ é™¤ startPolling API
- å–æ¶ˆ crawlPage crawlHTML crawlData crawlFile è¿™å››ä¸ª API çš„ç¬¬äºŒå‚æ•° (å›è°ƒå‡½æ•°)
- ç±»å‹:
  - XCrawlConfig æ›´åä¸º CreateCrawlConfig
  - XCrawlInstance æ›´åä¸º CrawlApp

### â›“ï¸ ä¾èµ–å…³ç³»

- chalk ä» 4.1.2 å‡è‡³ 5.3.0

# [v9.0.0](https://github.com/coder-hxl/x-crawl/compare/v8.3.1..v9.0.0) (2024-03-16)

### ğŸš¨ Breaking Changes

- The enableRandomFingerprint attribute of XCrawlConfig configuration is changed to false by default
- Drop support for Node16

### â›“ï¸ Dependencies

- puppeteer upgraded from 21.6.1 to 22.5.0
- https-proxy-agent upgraded from 7.0.1 to 7.0.4

---

### ğŸš¨ é‡å¤§æ”¹å˜

- XCrawlConfig é…ç½®çš„ enableRandomFingerprint å±æ€§é»˜è®¤æ”¹ä¸º false
- æ”¾å¼ƒå¯¹ Node16 çš„æ”¯æŒ

### â›“ï¸ ä¾èµ–å…³ç³»

- puppeteer ä» 21.6.1 å‡è‡³ 22.5.0
- https-proxy-agent ä» 7.0.1 å‡è‡³ 7.0.4

# [v8.3.1](https://github.com/coder-hxl/x-crawl/compare/v8.3.0..v8.3.1) (2023-12-26)

### ğŸš€ Features

- The document adds a solution to the problem of program crash caused by using crawlPage API.
- puppeteer upgraded from 21.1.0 to 21.6.1.

---

### ğŸš€ ç‰¹å¾

- æ–‡æ¡£æ–°å¢ ä½¿ç”¨ crawlPage API é€ æˆç¨‹åºå´©æºƒ çš„è§£å†³æ–¹æ¡ˆã€‚
- puppeteer ä» 21.1.0 å‡è‡³ 21.6.1 ã€‚

# [v8.3.0](https://github.com/coder-hxl/x-crawl/compare/v8.2.0..v8.3.0) (2023-11-09)

### ğŸš€ Features

- Added log option to control printing information in the terminal.
- The terminal printing information has been upgraded to make it easier to distinguish the source of the information.

---

### ğŸš€ ç‰¹å¾

- æ–°å¢ log é€‰é¡¹ï¼Œç”¨äºæ§åˆ¶åœ¨ç»ˆç«¯çš„æ‰“å°ä¿¡æ¯ã€‚
- ç»ˆç«¯æ‰“å°ä¿¡æ¯å‡çº§ï¼Œæ›´å®¹æ˜“åŒºåˆ†ä¿¡æ¯æ¥æºã€‚

# [v8.2.0](https://github.com/coder-hxl/x-crawl/compare/v8.1.1...v8.2.0) (2023-09-07)

### ğŸš€ Features

- Added crawlHTML API for crawling static HTML pages.

---

### ğŸš€ ç‰¹å¾

- æ–°å¢ crawlHTML API ï¼Œç”¨äºçˆ¬å–é™æ€ HTML é¡µé¢ã€‚

# [v8.1.1](https://github.com/coder-hxl/x-crawl/compare/v8.1.0...v8.1.1) (2023-09-01)

### ğŸ Bug fixes

- default export type.

---

### ğŸ æ¼æ´ä¿®å¤

- é»˜è®¤å¯¼å‡ºçš„ç±»å‹ã€‚

# [v8.1.0](https://github.com/coder-hxl/x-crawl/compare/v8.0.0...v8.1.0) (2023-09-01)

### ğŸš€ Features

- Limit Node.JS versions to 16.0.0 and above.
- Expose the corresponding puppeteer version type.
- Reduce package size and support ESM and cjs by packaging output a CJS file.

---

### ğŸš€ ç‰¹å¾

- å¯¹ Node.JS ç‰ˆæœ¬è¿›è¡Œé™åˆ¶ï¼Œåªæœ‰ 16.0.0 ç‰ˆæœ¬ä»¥ä¸Šæ‰èƒ½ä½¿ç”¨ã€‚
- å°†å¯¹åº”çš„ puppeteer ç‰ˆæœ¬ç±»å‹æš´éœ²å‡ºæ¥ã€‚
- å‡å°‘åŒ…ä½“ç§¯ï¼Œé€šè¿‡æ‰“åŒ…è¾“å‡ºä¸€ä¸ª cjs æ–‡ä»¶æ”¯æŒ ESM å’Œ CJS ã€‚

# [v8.0.0](https://github.com/coder-hxl/x-crawl/compare/v7.1.3...v8.0.0) (2023-08-22)

### ğŸš¨ Breaking Changes

- update dependencies

  - puppeteer from 19.10.0 to 21.1.0.
  - https-proxy-agent upgraded from 5.0.1 to 7.0.1.

- XCrawlConfig.crawlPage's launchBrowser option renamed to puppeteerLaunch .

---

### ğŸš¨ é‡å¤§æ”¹å˜

- æ›´æ–°ä¾èµ–

  - puppeteer ä» 19.10.0 å‡è‡³ 21.1.0 ã€‚
  - https-proxy-agent ä» 5.0.1 å‡è‡³ 7.0.1 ã€‚

- XCrawlConfig.crawlPage çš„ launchBrowser é€‰é¡¹æ›´åä¸º puppeteerLaunch ã€‚

# [v7.1.3](https://github.com/coder-hxl/x-crawl/compare/v7.1.2...v7.1.3) (2023-07-02)

### ğŸ Bug fixes

- The crawlData API writes the correct data to the request body and processes the response body.

---

### ğŸ æ¼æ´ä¿®å¤

- crawlData API å°†æ­£ç¡®çš„ data å†™å…¥è¯·æ±‚ä½“ä»¥åŠå¤„ç†å“åº”ä½“ã€‚

# [v7.1.2](https://github.com/coder-hxl/x-crawl/compare/v7.1.1...v7.1.2) (2023-06-25)

### ğŸ Bug fixes

- Data parameter option conversion issue for crawlData API.

---

### ğŸ æ¼æ´ä¿®å¤

- crawlData API çš„ data å‚æ•°é€‰é¡¹è½¬æ¢é—®é¢˜ã€‚

# [v7.1.1](https://github.com/coder-hxl/x-crawl/compare/v7.1.0...v7.1.1) (2023-06-21)

### ğŸ Bug fixes

- Correctly handle the header of the post method configured by the crawlData API.

---

### ğŸ æ¼æ´ä¿®å¤

- æ­£ç¡®å¤„ç† crawlData API é…ç½® post æ–¹æ³•çš„ header ã€‚

# [v7.1.0](https://github.com/coder-hxl/x-crawl/compare/v7.0.1...v7.1.0) (2023-05-15)

### ğŸš€ Features

- The flexibility of crawlFile API has been upgraded again, mainly adjusting fileName, storeDir, and extension.
  - The storeDir and extension of the advanced writing method (CrawlFileAdvancedConfig) are changed to storeDirs and extensions respectively, and the type is string or (string | null)[], and the fileNames option is added, and the type is (string | null)[] . If it is an array, it will be assigned to the crawling targets in order.
  - The fileName of the detailed target notation (CrawlFileDetailTargetConfig) adds a null type, which is used to use the default file name instead of the fileName corresponding to the advanced notation (CrawlFileAdvancedConfig) fileNames.

---

### ğŸš€ ç‰¹å¾

- crawlFile API çµæ´»åº¦å†æ¬¡å‡çº§ï¼Œä¸»è¦å¯¹ fileNameã€storeDirã€extension è¿›è¡Œè°ƒæ•´ã€‚
  - è¿›é˜¶å†™æ³• (CrawlFileAdvancedConfig) çš„ storeDir å’Œ extension åˆ†åˆ«æ›´æ”¹ä¸º storeDirs å’Œ extensions ï¼Œç±»å‹ä¸º string æˆ–è€… (string | null)[]ï¼ŒåŒæ—¶æ–°å¢ fileNames é€‰é¡¹ï¼Œç±»å‹ä¸º (string | null)[] ã€‚å¦‚æœæ˜¯æ•°ç»„åˆ™ä¼šæŒ‰é¡ºåºåˆ†é…ç»™çˆ¬å–ç›®æ ‡ã€‚
  - è¯¦ç»†ç›®æ ‡å†™æ³• (CrawlFileDetailTargetConfig) çš„ fileName æ–°å¢ null ç±»å‹ï¼Œç”¨äºä½¿ç”¨é»˜è®¤æ–‡ä»¶åï¼Œä¸ä½¿ç”¨è¿›é˜¶å†™æ³• (CrawlFileAdvancedConfig) fileNames å¯¹åº”çš„ fileName ã€‚

# [v7.0.1](https://github.com/coder-hxl/x-crawl/compare/v7.0.0...v7.0.1) (2023-05-04)

### ğŸ Bug fixes

- The params configuration option for the crawlData API is not working.

---

### ğŸ æ¼æ´ä¿®å¤

- crawlData API çš„ params é…ç½®é€‰é¡¹ä¸èµ·ä½œç”¨ã€‚

# [v7.0.0](https://github.com/coder-hxl/x-crawl/compare/v6.0.1...v7.0.0) (2023-04-26)

### ğŸš¨ Breaking Changes

- Fingerprint upgrade:
  - The fingerprint of the advanced writing method is renamed to fingerprints, which is an array writing method, which stores objects of the DetailTargetFingerprintCommon type, which is convenient for customization. Internally, the objects inside will be randomly assigned to the target.
  - Adjustment of crawlPage fingerprint options: the maximum width and height of the fingerprint configuration of advanced writing and detailed target writing are changed to optional.
- Proxy upgrade: create a crawler instance, change the proxy of the advanced writing method and the detailed target writing method to the object writing method, with three attributes: urls, switchByHttpStatus and switchByErrorCount, urls can set multiple proxy URLs, and the internal default uses the first one first, switchByHttpStatus Set which non-compliant response status codes need to switch the proxy, and switchByErrorCount sets how many times the proxy needs to be switched when errors such as timeouts arrive. The proxy rotation feature needs to be used with error retries.
- Return value type adjustment: CrawlCommonRes, CrawlPageSingleRes, CrawlDataSingleRes and CrawlFileSingleRes are renamed to CrawlCommonResult, CrawlPageSingleResult, CrawlDataSingleResult and CrawlFileSingleResult respectively

### ğŸš€ Features

- It is possible to cancel the configuration of the upper-level unified setting by setting null in the option.
- The userAgent option in DetailTargetFingerprintCommon overrides the object notation and allows customization of the maximum and minimum values of the major version, minor version, and revision number inside. Each crawl target gets a new userAgent .
- A new proxyDetails property is added to the crawling results to record the proxy status.
- Added 'random' attribute value to mobile option of fingerprint configuration, allowing internal randomization.
- Terminal prompts are simplified and color adjusted.

### ğŸ Bug fixes

- Unable to create multiple levels of non-existent folders on linux systems.

---

### ğŸš¨ é‡å¤§æ”¹å˜

- æŒ‡çº¹å‡çº§ï¼š
  - è¿›é˜¶å†™æ³•çš„ fingerprint æ”¹åä¸º fingerprints ï¼Œä¸ºæ•°ç»„å†™æ³•ï¼Œé‡Œé¢å­˜æ”¾ DetailTargetFingerprintCommon ç±»å‹çš„å¯¹è±¡ï¼Œæ–¹ä¾¿å®šåˆ¶ã€‚å†…éƒ¨ä¼šå°†é‡Œé¢çš„å¯¹è±¡éšæœºåˆ†é…ç»™ç›®æ ‡ã€‚
  - crawlPage çš„æŒ‡çº¹é€‰é¡¹è°ƒæ•´ï¼šè¿›é˜¶å†™æ³•å’Œè¯¦ç»†ç›®æ ‡å†™æ³•çš„æŒ‡çº¹é…ç½®çš„æœ€å¤§å®½é«˜æ”¹ä¸ºå¯é€‰é¡¹ã€‚
- ä»£ç†å‡çº§ï¼šåˆ›å»ºçˆ¬è™«å®ä¾‹ã€è¿›é˜¶å†™æ³•ä»¥åŠè¯¦ç»†ç›®æ ‡å†™æ³•çš„ proxy æ›´æ”¹ä¸ºå¯¹è±¡å†™æ³•, æ‹¥æœ‰ urlsã€switchByHttpStatus ä»¥åŠ switchByErrorCount è¿™ä¸‰ä¸ªå±æ€§ï¼Œurls å¯ä»¥è®¾ç½®å¤šä¸ªä»£ç† URL ï¼Œå†…éƒ¨é»˜è®¤å…ˆé‡‡ç”¨ç¬¬ä¸€ä¸ªï¼ŒswitchByHttpStatus è®¾ç½®é‡åˆ°å“ªäº›ä¸ç¬¦åˆçš„å“åº”çŠ¶æ€ç éœ€è¦åˆ‡æ¢ä»£ç†ï¼ŒswitchByErrorCount è®¾ç½®åƒè¶…æ—¶ç­‰é”™è¯¯æ—¶åˆ°è¾¾å¤šå°‘æ¬¡éœ€è¦åˆ‡æ¢ä»£ç†ã€‚è¯¥ä»£ç†è½®æ¢åŠŸèƒ½éœ€è¦é…åˆé”™è¯¯é‡è¯•æ‰èƒ½ä½¿ç”¨ã€‚
- è¿”å›å€¼ç±»å‹è°ƒæ•´ï¼šCrawlCommonResã€CrawlPageSingleResã€CrawlDataSingleRes ä»¥åŠ CrawlFileSingleRes åˆ†åˆ«æ›´åä¸º CrawlCommonResultã€CrawlPageSingleResultã€CrawlDataSingleResult ä»¥åŠ CrawlFileSingleResult

### ğŸš€ ç‰¹å¾

- å¯ä»¥é€šè¿‡åœ¨é€‰é¡¹è®¾ç½®ä¸º null å–æ¶ˆä¸Šçº§ç»Ÿä¸€è®¾ç½®çš„é…ç½®ã€‚
- DetailTargetFingerprintCommon é‡Œçš„ userAgent é€‰é¡¹æ”¹å†™å¯¹è±¡å†™æ³•ï¼Œå¹¶å…è®¸å®šåˆ¶é‡Œé¢çš„ä¸»ç‰ˆæœ¬ã€æ¬¡ç‰ˆæœ¬ä»¥åŠä¿®è®¢å·çš„æœ€å¤§å€¼å’Œæœ€å°å€¼ã€‚æ¯ä¸ªçˆ¬å–ç›®æ ‡éƒ½ä¼šè·å–ä¸€ä¸ªæ–°çš„ userAgent ã€‚
- çˆ¬å–ç»“æœæ–°å¢ proxyDetails å±æ€§ï¼Œè®°å½•ä»£ç†çŠ¶æ€ã€‚
- æŒ‡çº¹é…ç½®çš„ mobile é€‰é¡¹æ·»åŠ  'random' å±æ€§å€¼ï¼Œå…è®¸ç”±å†…éƒ¨éšæœºå†³å®šã€‚
- ç»ˆç«¯æç¤ºä¿¡æ¯è¿›è¡Œç®€åŒ–ä»¥åŠé¢œè‰²è°ƒæ•´ã€‚

### ğŸ æ¼æ´ä¿®å¤

- åœ¨ linux ç³»ç»Ÿä¸Šæ— æ³•åˆ›å»ºå¤šçº§ä¸å­˜åœ¨çš„æ–‡ä»¶å¤¹ã€‚

# [v6.0.1](https://github.com/coder-hxl/x-crawl/compare/v6.0.0...v6.0.1) (2023-04-21)

### ğŸš€ Features

- Perfect documentation.

---

### ğŸš€ ç‰¹å¾

- å®Œå–„æ–‡æ¡£ã€‚

# [v6.0.0](https://github.com/coder-hxl/x-crawl/compare/v5.1.0...v6.0.0) (2023-04-19)

### ğŸš¨ Breaking Changes

- About the result processing of each crawling target: it will start processing after a single target is completed, saving time and improving performance. Originally, it waited for all targets to be completed before processing, and there would be free time during the crawling process.
- About the execution timing of the second parameter callback function of the crawlPage, crawlData, and crawlFile APIs: it will be executed at the end, and the result obtained is the same as the result of the Promise method.
- About the type: PageRequestConfig, DataRequestConfig and FileRequestConfig are changed to CrawlPageDetailTargetConfig, CrawlDataDetailTargetConfig and CrawlFileDetailTargetConfig respectively, the purpose is to not only add the configuration of the request, but also expand more, called detailed target usage. CrawlPageConfigObject, CrawlDataConfigObject, and CrawlFileConfigObject changed to CrawlPageAdvancedConfig, CrawlDataAdvancedConfig, and CrawlFileAdvancedConfig respectively, named Advanced Usage.
- Configuration options in fileConfig of crawlFile: can be set directly in the root object configuration. The beforeSave lifecycle function changed to onBeforeSaveItemFile.
- About the object results of crawlPage, crawlData and crawlFile: remove the crawlCount attribute, and get the number of times by retryCount + 1. errorQueue was renamed to crawlErrorQueue.

### ğŸš€ Features

- Added device fingerprint to avoid identifying and tracking us from different locations through fingerprint recognition. You can use the default with a switch, and if you need to specify it, you can set it uniformly for all crawling targets in the advanced usage, or you can specify the settings through the detailed target usage.
- Adding multiple attributes for each advanced usage can be configured in an advanced way to set the object uniformly, without having to set it repeatedly for each target configuration. The new onCrawlItemComplete lifecycle function will be executed after each crawling goal is completed, and the result of the crawling goal will be passed to the callback function.
- Added crawlPage in the configuration of creating a crawler application, you can set the configuration of creating a browser in the crawlPage.launchBrowser option (type is PuppeteerLaunchOptions from Puppeteer).
- crawlPage adds viewport option, which is used to set the viewport of the page.

---

### ğŸš¨ é‡å¤§æ”¹å˜

- å…³äºå¯¹æ¯ä¸ªçˆ¬å–ç›®æ ‡çš„ç»“æœå¤„ç†ï¼šå°†ä¼šåœ¨å•ä¸ªç›®æ ‡å®Œæˆåå°±å¼€å§‹è¿›è¡Œå¤„ç†ï¼ŒèŠ‚çœæ—¶é—´ï¼Œæé«˜æ€§èƒ½ã€‚åŸå…ˆæ˜¯ç­‰æ‰€æœ‰ç›®æ ‡å®Œæˆå†å¤„ç†ï¼Œåœ¨çˆ¬è¿‡ç¨‹ä¸­ä¼šæœ‰ç©ºé—²æ—¶é—´ã€‚
- å…³äº crawlPageã€crawlData ä»¥åŠ crawlFile è¿™ä¸‰ä¸ª API çš„ç¬¬äºŒä¸ªå‚æ•°å›è°ƒå‡½æ•°çš„æ‰§è¡Œæ—¶æœºï¼šå°†ç§»åˆ°æœ€åæ‰§è¡Œï¼Œè·å–çš„ç»“æœè·Ÿ Promise æ–¹å¼çš„ç»“æœç›¸åŒã€‚
- å…³äºç±»å‹ï¼šPageRequestConfigã€DataRequestConfig ä»¥åŠ FileRequestConfig åˆ†åˆ«æ›´æ”¹ä¸º CrawlPageDetailTargetConfigã€CrawlDataDetailTargetConfig ä»¥åŠ CrawlFileDetailTargetConfig ï¼Œç›®çš„æ˜¯ä¸ºäº†ä¸å•å•å¯ä»¥åŠ è¯·æ±‚çš„é…ç½®ï¼Œä¹Ÿå¯ä»¥æ‰©å±•æ›´å¤šï¼Œåä¸ºè¯¦ç»†ç›®æ ‡ç”¨æ³•ã€‚CrawlPageConfigObjectã€ CrawlDataConfigObject ä»¥åŠ CrawlFileConfigObject åˆ†åˆ«æ›´æ”¹ä¸º CrawlPageAdvancedConfigã€CrawlDataAdvancedConfig ä»¥åŠ CrawlFileAdvancedConfig ï¼Œåä¸ºè¿›é˜¶ç”¨æ³•ã€‚
- å…³äº crawlFile çš„ fileConfig é‡Œé¢çš„é…ç½®é€‰é¡¹ï¼šå¯ä»¥ç›´æ¥åœ¨æ ¹å¯¹è±¡é…ç½®ä¸­è®¾ç½®ã€‚beforeSave ç”Ÿå‘½å‘¨æœŸå‡½æ•°æ›´æ”¹ä¸º onBeforeSaveItemFileã€‚
- å…³äº crawlPageã€crawlData ä»¥åŠ crawlFile çš„å¯¹è±¡ç»“æœï¼šç§»é™¤ crawlCount å±æ€§ï¼Œå¯é€šè¿‡ retryCount + 1 è·å–æ¬¡æ•°ã€‚errorQueue æ›´åä¸º crawlErrorQueueã€‚

### ğŸš€ ç‰¹å¾

- æ–°å¢è®¾å¤‡æŒ‡çº¹ï¼Œå¯é¿å…é€šè¿‡æŒ‡çº¹è¯†åˆ«ä»ä¸åŒä½ç½®è¯†åˆ«å¹¶è·Ÿè¸ªæˆ‘ä»¬ã€‚å¯ä»¥é€šè¿‡ä¸€ä¸ªå¼€å…³ä½¿ç”¨é»˜è®¤çš„ï¼Œå¦‚æœéœ€æŒ‡å®šåˆ™å¯åœ¨è¿›é˜¶ç”¨æ³•ä¸­ä¸ºæ‰€æœ‰çˆ¬å–ç›®æ ‡ç»Ÿä¸€è®¾ç½®ï¼Œä¹Ÿå¯ä»¥é€šè¿‡è¯¦ç»†ç›®æ ‡ç”¨æ³•æŒ‡å®šè®¾ç½®ã€‚
- æ¯ä¸ªè¿›é˜¶ç”¨æ³•æ–°å¢å¤šä¸ªå±æ€§å¯ä»¥åœ¨è¿›é˜¶æ–¹å¼é…ç½®å¯¹è±¡ç»Ÿä¸€è®¾ç½®ï¼Œä¸å¿…ä¸ºæ¯ä¸ªç›®æ ‡é…ç½®é‡å¤è®¾ç½®ä¸€éã€‚æ–°å¢ onCrawlItemComplete ç”Ÿå‘½å‘¨æœŸå‡½æ•°ï¼Œå°†åœ¨æ¯ä¸ªçˆ¬å–ç›®æ ‡å®Œæˆåæ‰§è¡Œï¼Œå¹¶ä¸”æŠŠçˆ¬å–ç›®æ ‡çš„ç»“æœä¼ å…¥å›è°ƒå‡½æ•°ã€‚
- åœ¨åˆ›å»ºçˆ¬è™«åº”ç”¨çš„é…ç½®æ–°å¢ crawlPage ï¼Œå¯ä»¥åœ¨ crawlPage.launchBrowser é€‰é¡¹ä¸­è®¾ç½®åˆ›å»ºæµè§ˆå™¨çš„é…ç½®ï¼ˆç±»å‹ä¸º PuppeteerLaunchOptions æ¥è‡ª Puppeteerï¼‰ã€‚
- crawlPage æ–°å¢ viewport é€‰é¡¹ï¼Œç”¨äºè®¾ç½®é¡µé¢çš„è§†å£ã€‚

# [v5.1.0](https://github.com/coder-hxl/x-crawl/compare/v5.0.2...v5.1.0) (2023-04-12)

### ğŸš¨ Breaking Changes

- The beforeSave lifecycle function of crawlFile needs to return a Promise and resolve is a Buffer .

### ğŸš€ Features

- The description, characteristics and type of the document change.

### ğŸ Bug Fixes

- Incorrect type hints and type restrictions, using overloaded functions instead.

---

### ğŸš¨ é‡å¤§æ”¹å˜

- crawlFile çš„ beforeSave ç”Ÿå‘½å‘¨æœŸå‡½æ•°éœ€è¦è¿”å›ä¸€ä¸ª Promise å¹¶ä¸” resolve æ˜¯ Buffer ã€‚

### ğŸš€ ç‰¹å¾

- æ–‡æ¡£çš„æè¿°ã€ç‰¹å¾å’Œç±»å‹å‘ç”Ÿå˜åŒ–ã€‚

### ğŸ æ¼æ´ä¿®å¤

- é”™è¯¯çš„ç±»å‹æç¤ºå’Œç±»å‹é™åˆ¶ï¼Œæ”¹ç”¨é‡è½½å‡½æ•°ã€‚

# [v5.0.2](https://github.com/coder-hxl/x-crawl/compare/v5.0.1...v5.0.2) (2023-04-10)

### ğŸš€ Features

- When a retry is added, the number of retry batches is displayed in print.

---

### ğŸš€ ç‰¹å¾

- æ–°å¢é‡è¯•æ—¶ï¼Œé‡è¯•æ‰¹æ¬¡æ•°å°†æ˜¾ç¤ºåœ¨æ‰“å°ä¸­ã€‚

# [v5.0.1](https://github.com/coder-hxl/x-crawl/compare/v5.0.0...v5.0.1) (2023-04-08)

### ğŸš€ Features

- New adjustments to the document.

---

### ğŸš€ ç‰¹å¾

- æ–‡æ¡£æ–°çš„è°ƒæ•´ã€‚

# [v5.0.0](https://github.com/coder-hxl/x-crawl/compare/v4.0.1...v5.0.0) (2023-04-06)

### ğŸš¨ Breaking Changes

- For configuration, major changes have been made to each crawling API configuration, and the same API supports more crawling configuration methods, each of which has its own significance.
- For the result, the result of each request will be wrapped in an object, which provides information about the result of this request, such as: id, result, success, maximum retry, number of retries, collected error information, etc. . Automatically determine whether the return value is wrapped in an array according to the configuration method you choose, and the type is perfectly matched in TS.
- For obtaining results through the callback function, the callback is no longer executed after a single request is completed like the v4.x version, but will be executed sequentially after the crawling is completed, which will not block subsequent crawling.

### ğŸš€ Features

- Added a retry mechanism, which can be set for all crawling requests, for a single crawling request, and for a single request.
- A new priority queue is added to use priority crawling according to the priority of a single request.
- For more configurations that may be reused, you can set the baseConfig settings passed in when requesting configuration, API crawling configuration, and generating crawler instances, such as: timeout, proxy, intervalTime, etc., and the weight is: requestConfig > APIConfig > baseConfig.
- For crawlFile API, file path, name, suffix and other information can be set individually for each file. Added the beforeSave life cycle function before saving the file. You can get the file data of the Buffer type, and you can perform operations such as compression on the data in the callback. The returned new Buffer data will replace the original data and write it into the file.
- Update the output of crawling on the console, and collect the error information generated by crawling into an error queue. After the crawling is completed, you can get the error message queue through the return value.

---

### ğŸš¨ é‡å¤§æ”¹å˜

- å¯¹äºé…ç½®ï¼Œæ¯ä¸ªçˆ¬å– API é…ç½®å‘ç”Ÿé‡å¤§æ”¹å˜ï¼ŒåŒä¸€ä¸ª API æ”¯æŒæ›´å¤šçˆ¬å–é…ç½®æ–¹å¼ï¼Œæ¯ç§æ–¹å¼éƒ½æœ‰å…¶å­˜åœ¨çš„æ„ä¹‰ã€‚
- å¯¹äºç»“æœï¼Œæ¯ä¸ªè¯·æ±‚çš„ç»“æœå°†ç»Ÿä¸€ä½¿ç”¨å¯¹è±¡åŒ…è£¹ç€ï¼Œè¯¥å¯¹è±¡æä¾›äº†å…³äºè¿™æ¬¡è¯·æ±‚ç»“æœçš„ä¿¡æ¯ï¼Œæ¯”å¦‚ï¼šidã€ç»“æœã€æ˜¯å¦æˆåŠŸã€æœ€å¤§é‡è¯•ã€é‡è¯•æ¬¡æ•°ã€æ”¶é›†åˆ°é”™è¯¯ä¿¡æ¯ç­‰ã€‚è‡ªåŠ¨æ ¹æ®ä½ é€‰ç”¨çš„é…ç½®æ–¹å¼å†³å®šè¿”å›å€¼æ˜¯å¦åŒ…è£¹åœ¨ä¸€ä¸ªæ•°ç»„ä¸­ï¼Œåœ¨ TS ä¸­ç±»å‹å®Œç¾é€‚é…ã€‚
- å¯¹äºé€šè¿‡å›è°ƒå‡½æ•°æ–¹å¼è·å–ç»“æœï¼Œè¯¥å›è°ƒä¸å†åƒ v4.x ç‰ˆæœ¬åœ¨å•ä¸ªè¯·æ±‚å®Œæˆåæ‰§è¡Œï¼Œè€Œæ˜¯å°†ä¼šåœ¨çˆ¬å–å®ŒæˆåæŒ‰é¡ºåºæ‰§è¡Œï¼Œè¿™å°†ä¸ä¼šé˜»å¡åç»­çš„çˆ¬å–ã€‚

### ğŸš€ ç‰¹å¾

- æ–°å¢å¤±è´¥é‡è¯•ï¼Œå¯é’ˆå¯¹æ‰€æœ‰çˆ¬å–çš„è¯·æ±‚è®¾ç½®ï¼Œé’ˆå¯¹å•æ¬¡çˆ¬å–çš„è¯·æ±‚è®¾ç½®ï¼Œé’ˆå¯¹å•ä¸ªè¯·æ±‚è®¾ç½®è¿›è¡Œå¤±è´¥é‡è¯•ã€‚
- æ–°å¢ä¼˜å…ˆé˜Ÿåˆ—ï¼Œæ ¹æ®å•ä¸ªè¯·æ±‚çš„ä¼˜å…ˆçº§ä½¿ç”¨ä¼˜å…ˆçˆ¬å–ã€‚
- å¯¹æ›´å¤šå¯èƒ½å¤ç”¨çš„é…ç½®å¯ä»¥åœ¨è¯·æ±‚é…ç½®ã€API çˆ¬å–é…ç½®ã€ç”Ÿæˆçˆ¬è™«å®ä¾‹æ—¶ä¼ å…¥çš„ baseConfig è®¾ç½®ï¼Œæ¯”å¦‚ï¼štimeoutã€proxyã€intervalTime ç­‰ï¼Œæƒé‡ä¸ºï¼šrequestConfig > APIConfig > baseConfigã€‚
- å¯¹ crawlFile API å¯å•ç‹¬ä¸ºæ¯ä¸ªæ–‡ä»¶è®¾ç½®æ–‡ä»¶è·¯å¾„ã€åå­—ã€åç¼€ç­‰ä¿¡æ¯ã€‚æ–°å¢ beforeSave æ–‡ä»¶ä¿å­˜å‰ç”Ÿå‘½å‘¨æœŸå‡½æ•°ï¼Œå¯æ‹¿åˆ° Buffer ç±»å‹çš„æ–‡ä»¶æ•°æ®ï¼Œå¯åœ¨å›è°ƒå†…å¯¹æ•°æ®è¿›è¡Œå‹ç¼©ç­‰æ“ä½œï¼Œè¿”å›æ–°çš„ Buffer æ•°æ®ä¼šæ›¿ä»£åŸå…ˆçš„æ•°æ®å†™å…¥æ–‡ä»¶ä¸­ã€‚
- å¯¹çˆ¬å–åœ¨æ§åˆ¶å°çš„è¾“å‡ºæ›´æ–°ï¼Œå¯¹çˆ¬å–äº§ç”Ÿçš„æŠ¥é”™ä¿¡æ¯åˆ†åˆ«æ”¶é›†åˆ°ä¸€ä¸ªçš„é”™è¯¯é˜Ÿåˆ—ä¸­ï¼Œçˆ¬å–å®Œæˆåå¯é€šè¿‡è¿”å›å€¼æ‹¿åˆ°è¯¥é”™è¯¯ä¿¡æ¯é˜Ÿåˆ—ã€‚

# [v4.0.1](https://github.com/coder-hxl/x-crawl/compare/v4.0.0...v4.0.1) (2023-03-30)

### ğŸ Bug Fixes

- The page is not closed when there is an error in the crawlPage API

# [v4.0.0](https://github.com/coder-hxl/x-crawl/compare/v3.3.0...v4.0.0) (2023-03-27)

### ğŸš¨ Breaking Changes

- The crawlPage API can add batch requests.
- The crawlPage API remove JSDOM.

### ğŸš€ Features

- Document updates.

# [v3.3.0](https://github.com/coder-hxl/x-crawl/compare/v3.2.12...v3.3.0) (2023-03-24)

### ğŸš€ Features

- The crawlerPage API crawling page allows to carry Cookies (for login and other operations).

# [v3.2.12](https://github.com/coder-hxl/x-crawl/compare/v3.2.11...v3.2.12) (2023-03-23)

### ğŸ Bug Fixes

- Document jump fix

# [v3.2.11](https://github.com/coder-hxl/x-crawl/compare/v3.2.10...v3.2.11) (2023-03-22)

### ğŸš€ Features

- Test updates, unit test all APIs

### ğŸ Bug Fixes

- Fix crawlPage API internal error

# [v3.2.10](https://github.com/coder-hxl/x-crawl/compare/v3.2.9...v3.2.10) (2023-03-21)

### ğŸš€ Features

- Update documents

# [v3.2.9](https://github.com/coder-hxl/x-crawl/compare/v3.2.8...v3.2.9) (2023-03-20)

### ğŸš€ Features

- Update dependency

# [v3.2.8](https://github.com/coder-hxl/x-crawl/compare/v3.2.7...v3.2.8) (2023-02-19)

### ğŸ Bug Fixes

- Internal type adjustment.
- Catch crawlPage API errors.

# [v3.2.7](https://github.com/coder-hxl/x-crawl/compare/v3.2.6...v3.2.7) (2023-03-14)

### ğŸš€ Features

- Update documents

# [v3.2.6](https://github.com/coder-hxl/x-crawl/compare/v3.2.5...v3.2.6) (2023-03-14)

### ğŸš€ Features

- Update documents

# [v3.2.5](https://github.com/coder-hxl/x-crawl/compare/v3.2.4...v3.2.5) (2023-03-12)

### ğŸš€ Features

- Update documents

# [v3.2.4](https://github.com/coder-hxl/x-crawl/compare/v3.2.3...v3.2.4) (2023-03-09)

### ğŸš€ Features

- Update documents

# [v3.2.3](https://github.com/coder-hxl/x-crawl/compare/v3.2.2...v3.2.3) (2023-03-08)

### ğŸš€ Features

- Update documents

# [v3.2.2](https://github.com/coder-hxl/x-crawl/compare/v3.2.1...v3.2.2) (2023-03-07)

### ğŸš€ Features

- Update documents

# [v3.2.1](https://github.com/coder-hxl/x-crawl/compare/v3.2.0...v3.2.1) (2023-03-07)

### ğŸš€ Features

- Update documents

# [v3.2.0](https://github.com/coder-hxl/x-crawl/compare/v3.1.1...v3.2.0) (2023-03-06)

### ğŸš€ Features

- crawlPage API return value update

### ğŸ Bug Fixes

- The result page of crawlPage API reported an error. Expose the browser and let the user decide to close the browser

# [v3.1.1](https://github.com/coder-hxl/x-crawl/compare/v3.1.0...v3.1.1) (2023-02-05)

### ğŸ Bug Fixes

- publish type is missing

# [v3.1.0](https://github.com/coder-hxl/x-crawl/compare/v3.0.0...v3.1.0) (2023-03-05)

### ğŸš€ Features

- The callback function adds a stopPolling parameter, which can be called to stop subsequent polling operations. The stop polling of the startPolling API is determined by the user

- Update documents

# [v3.0.0](https://github.com/coder-hxl/x-crawl/compare/v2.4.2...v3.0.0) (2023-03-04)

### ğŸš¨ Breaking Changes

- The three APIs fetchPage, fetchData, and fetchFile are renamed to crawlPage, crawlData, and crawlFile respectively

### ğŸš€ Features

- Multiple ways of writing requestConfig options

- All types are exposed

# [v2.4.2](https://github.com/coder-hxl/x-crawl/compare/v2.4.1...v2.4.2) (2023-03-04)

### ğŸš€ Features

- Update documents

# [v2.4.1](https://github.com/coder-hxl/x-crawl/compare/v2.4.0...v2.4.1) (2023-03-04)

### ğŸ Bug Fixes

- Interval time doesn't work

# [v2.4.0](https://github.com/coder-hxl/x-crawl/compare/v2.3.0...v2.4.0) (2023-03-03)

### ğŸš€ Features

- Update documents

# [v2.3.0](https://github.com/coder-hxl/x-crawl/compare/v2.2.1...v2.3.0) (2023-03-02)

### ğŸš¨ Breaking Changes

- fetchHTML API rename fetchPage

# [v2.2.1](https://github.com/coder-hxl/x-crawl/compare/v2.2.0...v2.2.1) (2023-03-01)

### ğŸš€ Features

- Update documents

# [v2.2.0](https://github.com/coder-hxl/x-crawl/compare/v2.1.0...v2.2.0) (2023-02-28)

### ğŸš€ Features

- Parameter config name correction
- Update documents

# [v2.1.0](https://github.com/coder-hxl/x-crawl/compare/v2.0.0...v2.1.0) (2023-02-28)

### ğŸš€ Features

- The fetchHTML API results remove content options
- The fetchHTML API cancels the incoming header attribute
- The running mode of crawling is highlighted

# [v2.0.0](https://github.com/coder-hxl/x-crawl/compare/v1.1.1...v2.0.0) (2023-02-27)

### ğŸš¨ Breaking Changes

- Create a crawler method, created by calling
- The fetchHTML API uses puppeteer to crawl HTML
- The fetchPolling API renamed to startPolling, removed year and month

# [v1.1.1](https://github.com/coder-hxl/x-crawl/compare/v1.1.0...v1.1.1) (2023-02-22)

### ğŸš€ Features

- Add jump to a detailed type

# [v1.1.0](https://github.com/coder-hxl/x-crawl/compare/v1.0.1...v1.1.0) (2023-02-21)

### ğŸš€ Features

- The fetchFile API uses async for save file operations and sorts errors
- The fetchFile API fileConfig can pass in non-existing path

# [v1.0.1](https://github.com/coder-hxl/x-crawl/compare/v1.0.0...v1.0.1) (2023-02-20)

### ğŸš€ Features

- Sorting of error messages and fetchData/fetchFile API results

# [v1.0.0](https://github.com/coder-hxl/x-crawl/compare/v0.4.0...v1.0.0) (2023-02-17)

### ğŸš¨ Breaking Changes

- Added the method of getting the request result through the callback function, The result of each request can be obtained through the callback function, and the total result can be obtained through PromIse
- API internal refactoring

# [v0.4.0](https://github.com/coder-hxl/x-crawl/compare/v0.3.1...v0.4.0) (2023-02-16)

### ğŸš€ Features

- The fetchFile API config can provide the extension of the downloaded file

# [v0.3.1](https://github.com/coder-hxl/x-crawl/compare/v0.3.0...v0.3.1) (2023-02-10)

### ğŸš€ Features

- Update documents

# [v0.3.0](https://github.com/coder-hxl/x-crawl/compare/v0.2.0...v0.3.0) (2023-02-10)

### ğŸš¨ Breaking Changes

- Rename the data object raw of fetchHTML return value to html

### ğŸš€ Features

- Add proxy option

# [v0.2.0](https://github.com/coder-hxl/x-crawl/compare/v0.1.5...v0.2.0) (2023-02-09)

### ğŸš€ Features

- Add polling function

# [v0.1.5](https://github.com/coder-hxl/x-crawl/compare/v0.1.4...v0.1.5) (2023-02-05)

### ğŸ Bug Fixes

- Fix fetchFile API file save is lost

# [v0.1.4](https://github.com/coder-hxl/x-crawl/compare/v0.1.3...v0.1.4) (2023-02-05)

### ğŸš€ Features

- Add chalk library

# [v0.1.3](https://github.com/coder-hxl/x-crawl/compare/v0.1.2...v0.1.3) (2023-02-05)

### ğŸš€ Features

- fetchHTML API exposes more content

# [v0.1.2](https://github.com/coder-hxl/x-crawl/compare/v0.1.1...v0.1.2) (2023-02-02)

### ğŸš€ Features

- Add requst mode option: async/sync
- Document adjustment

# [v0.1.1](https://github.com/coder-hxl/x-crawl/compare/v0.1.0...v0.1.1) (2023-01-31)

### ğŸš€ Features

- fetchHTML API parameter can be Object type

# [v0.1.0](https://github.com/coder-hxl/x-crawl/compare/v0.0.3...v0.1.0) (2023-01-30)

### ğŸš€ Features

- fetch API renamed to fetchData API
- fetchData and fetchFile request handling

# [v0.0.3](https://github.com/coder-hxl/x-crawl/compare/v0.0.2...v0.0.3) (2023-01-29)

### ğŸš€ Features

- Request Protocol
- Use jest test

# [v0.0.2](https://github.com/coder-hxl/x-crawl/compare/v0.0.1...v0.0.2) (2023-01-28)

### ğŸ Bug Fixes

- Add jsdom type

- Combined configuration when the basic configuration is not undefined will be processed

# v0.0.1 (2023-01-28)

### ğŸš€ Features

- Featï¼šFirst release of x-crawl
